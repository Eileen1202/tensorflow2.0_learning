{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_customized_layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression_customized_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "outputId": "407c6783-ff3d-4709-ae26-6edb611321c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.2\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "125ec2cf-6c84-4e5d-e2d7-46f2ff8cba75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "83543280-bb51-48cb-ff47-90955d8b481b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGNhsZWrxVeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e0466f27-3ceb-4e6b-96f7-04d03146f25c"
      },
      "source": [
        "# tf.nn.softplus: log(1+e^x)\n",
        "customized_softplus = keras.layers.Lambda(lambda x: tf.nn.softplus(x))\n",
        "print(customized_softplus([-10., -5., 0., 5., 10.]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([4.5417706e-05 6.7153489e-03 6.9314718e-01 5.0067153e+00 1.0000046e+01], shape=(5,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "outputId": "ae4ab44a-0e72-4889-e74d-dd67abc28a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# customized dense layer\n",
        "class CustomizedDenseLayer(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        self.units = units\n",
        "        self.activation = keras.layers.Activation(activation)\n",
        "        super(CustomizedDenseLayer, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"构建所需要的参数\"\"\"\n",
        "        self.kernel = self.add_weight(name = \"kernel\",\n",
        "                                      shape = (input_shape[1], self.units),\n",
        "                                      initializer = 'uniform',\n",
        "                                      trainable = True)\n",
        "        self.bias = self.add_weight(name = \"bias\",\n",
        "                                    shape = (self.units,),\n",
        "                                    initializer = 'zeros',\n",
        "                                    trainable = True)\n",
        "        super(CustomizedDenseLayer, self).build(input_shape)\n",
        "    \n",
        "    def call(self, x):\n",
        "        return self.activation(x @ self.kernel + self.bias)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    CustomizedDenseLayer(30, activation='relu',\n",
        "                       input_shape=x_train.shape[1:]),\n",
        "    CustomizedDenseLayer(1),\n",
        "    customized_softplus,\n",
        "    # keras.layers.Dense(1, activation=\"softplus\"),\n",
        "    # keras.layers.Dense(1), keras.layers.Activation(\"softplus\"),\n",
        "])\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer = \"sgd\")\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "customized_dense_layer_4 (Cu (None, 30)                270       \n",
            "_________________________________________________________________\n",
            "customized_dense_layer_5 (Cu (None, 1)                 31        \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g9RQd287SJ",
        "colab_type": "code",
        "outputId": "9f92a667-0e51-4e66-b7f6-1200c2cd3023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        }
      },
      "source": [
        "history = model.fit(x_train_scaled, y_train,\n",
        "                   validation_data = (x_valid_scaled, y_valid),\n",
        "                   epochs = 100,\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: 2.7886 - val_loss: 2.5886\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 2.0985 - val_loss: 1.9169\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 1.5352 - val_loss: 1.3846\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 1.1036 - val_loss: 0.9833\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.8304 - val_loss: 0.7897\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.7216 - val_loss: 0.7299\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6819 - val_loss: 0.7056\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6606 - val_loss: 0.6902\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.6454 - val_loss: 0.6783\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6331 - val_loss: 0.6676\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6223 - val_loss: 0.6578\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.6123 - val_loss: 0.6484\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6030 - val_loss: 0.6392\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5940 - val_loss: 0.6300\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5853 - val_loss: 0.6210\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5770 - val_loss: 0.6122\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5688 - val_loss: 0.6036\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5609 - val_loss: 0.5952\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5532 - val_loss: 0.5872\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5458 - val_loss: 0.5792\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5386 - val_loss: 0.5713\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5319 - val_loss: 0.5637\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5253 - val_loss: 0.5565\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5192 - val_loss: 0.5501\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5134 - val_loss: 0.5437\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.5078 - val_loss: 0.5374\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5027 - val_loss: 0.5315\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4978 - val_loss: 0.5259\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4933 - val_loss: 0.5211\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4889 - val_loss: 0.5166\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4849 - val_loss: 0.5120\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4811 - val_loss: 0.5079\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4776 - val_loss: 0.5039\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4744 - val_loss: 0.5004\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4716 - val_loss: 0.4971\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4687 - val_loss: 0.4939\n",
            "Epoch 37/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4661 - val_loss: 0.4911\n",
            "Epoch 38/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4637 - val_loss: 0.4883\n",
            "Epoch 39/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4614 - val_loss: 0.4850\n",
            "Epoch 40/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4592 - val_loss: 0.4831\n",
            "Epoch 41/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4574 - val_loss: 0.4805\n",
            "Epoch 42/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4554 - val_loss: 0.4782\n",
            "Epoch 43/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4536 - val_loss: 0.4760\n",
            "Epoch 44/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4520 - val_loss: 0.4742\n",
            "Epoch 45/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4501 - val_loss: 0.4720\n",
            "Epoch 46/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4489 - val_loss: 0.4708\n",
            "Epoch 47/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4472 - val_loss: 0.4687\n",
            "Epoch 48/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4459 - val_loss: 0.4667\n",
            "Epoch 49/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4444 - val_loss: 0.4649\n",
            "Epoch 50/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4430 - val_loss: 0.4631\n",
            "Epoch 51/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4420 - val_loss: 0.4628\n",
            "Epoch 52/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4406 - val_loss: 0.4602\n",
            "Epoch 53/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4393 - val_loss: 0.4596\n",
            "Epoch 54/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4377 - val_loss: 0.4572\n",
            "Epoch 55/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4367 - val_loss: 0.4552\n",
            "Epoch 56/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4361 - val_loss: 0.4550\n",
            "Epoch 57/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4344 - val_loss: 0.4532\n",
            "Epoch 58/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4338 - val_loss: 0.4528\n",
            "Epoch 59/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4322 - val_loss: 0.4513\n",
            "Epoch 60/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4314 - val_loss: 0.4504\n",
            "Epoch 61/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4302 - val_loss: 0.4481\n",
            "Epoch 62/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4291 - val_loss: 0.4476\n",
            "Epoch 63/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4284 - val_loss: 0.4462\n",
            "Epoch 64/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4271 - val_loss: 0.4445\n",
            "Epoch 65/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4265 - val_loss: 0.4454\n",
            "Epoch 66/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4252 - val_loss: 0.4425\n",
            "Epoch 67/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4245 - val_loss: 0.4415\n",
            "Epoch 68/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4236 - val_loss: 0.4414\n",
            "Epoch 69/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4228 - val_loss: 0.4397\n",
            "Epoch 70/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4218 - val_loss: 0.4390\n",
            "Epoch 71/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4209 - val_loss: 0.4374\n",
            "Epoch 72/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4200 - val_loss: 0.4365\n",
            "Epoch 73/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4195 - val_loss: 0.4360\n",
            "Epoch 74/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4183 - val_loss: 0.4345\n",
            "Epoch 75/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4178 - val_loss: 0.4337\n",
            "Epoch 76/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4171 - val_loss: 0.4328\n",
            "Epoch 77/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4160 - val_loss: 0.4319\n",
            "Epoch 78/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4155 - val_loss: 0.4317\n",
            "Epoch 79/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4147 - val_loss: 0.4301\n",
            "Epoch 80/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4138 - val_loss: 0.4304\n",
            "Epoch 81/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4132 - val_loss: 0.4285\n",
            "Epoch 82/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4125 - val_loss: 0.4282\n",
            "Epoch 83/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4116 - val_loss: 0.4288\n",
            "Epoch 84/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4110 - val_loss: 0.4263\n",
            "Epoch 85/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4104 - val_loss: 0.4254\n",
            "Epoch 86/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4097 - val_loss: 0.4254\n",
            "Epoch 87/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4089 - val_loss: 0.4235\n",
            "Epoch 88/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4085 - val_loss: 0.4234\n",
            "Epoch 89/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4077 - val_loss: 0.4229\n",
            "Epoch 90/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4071 - val_loss: 0.4216\n",
            "Epoch 91/100\n",
            "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4063 - val_loss: 0.4205\n",
            "Epoch 92/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4061 - val_loss: 0.4203\n",
            "Epoch 93/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4052 - val_loss: 0.4195\n",
            "Epoch 94/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4046 - val_loss: 0.4195\n",
            "Epoch 95/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4039 - val_loss: 0.4194\n",
            "Epoch 96/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4034 - val_loss: 0.4178\n",
            "Epoch 97/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4027 - val_loss: 0.4165\n",
            "Epoch 98/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4022 - val_loss: 0.4167\n",
            "Epoch 99/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4014 - val_loss: 0.4144\n",
            "Epoch 100/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4008 - val_loss: 0.4143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "outputId": "f0dbdc7a-303b-4ca0-e4ee-4fccd884eb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7LY8Sa9iX4",
        "colab_type": "code",
        "outputId": "c2191eca-d6d6-4c74-8d38-acd32031de38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 18us/sample - loss: 0.4167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4167179967081824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIxnZqD9o3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}