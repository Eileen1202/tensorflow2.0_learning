{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_wide_deep_multi_input.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression_wide_deep_multi_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUoJrGPpbb-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "outputId": "0738a118-c760-49d5-d6fb-b65761cd2776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.1\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "5f5ae34a-da30-4fe9-c55c-eb1c0eb0d253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "15eeb91c-1764-42b4-d365-56f3f6462a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "outputId": "e37671f9-1cd0-44df-c7f5-a7b83d375d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# 多输入\n",
        "input_wide = keras.layers.Input(shape=[5])\n",
        "input_deep = keras.layers.Input(shape=[6])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_wide, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs = [input_wide, input_deep],\n",
        "                          outputs = [output])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer = \"sgd\")\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 30)           210         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 30)           930         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 35)           0           input_5[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            36          concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g9RQd287SJ",
        "colab_type": "code",
        "outputId": "f97bbfb2-5b15-4cde-a907-9caf7e473028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        }
      },
      "source": [
        "x_train_scaled_wide = x_train_scaled[:, :5]\n",
        "x_train_scaled_deep = x_train_scaled[:, 2:]\n",
        "x_valid_scaled_wide = x_valid_scaled[:, :5]\n",
        "x_valid_scaled_deep = x_valid_scaled[:, 2:]\n",
        "x_test_scaled_wide = x_test_scaled[:, :5]\n",
        "x_test_scaled_deep = x_test_scaled[:, 2:]\n",
        "\n",
        "history = model.fit([x_train_scaled_wide, x_train_scaled_deep], y_train,\n",
        "                   validation_data = ([x_valid_scaled_wide, x_valid_scaled_deep], y_valid),\n",
        "                   epochs = 100,\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 1.4866 - val_loss: 0.9208\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.7761 - val_loss: 0.8010\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6999 - val_loss: 0.7343\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6525 - val_loss: 0.6917\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6150 - val_loss: 0.6551\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5852 - val_loss: 0.6200\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5602 - val_loss: 0.5952\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5399 - val_loss: 0.5737\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5234 - val_loss: 0.5553\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5093 - val_loss: 0.5402\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4980 - val_loss: 0.5298\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4893 - val_loss: 0.5223\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4818 - val_loss: 0.5123\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4755 - val_loss: 0.5067\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4703 - val_loss: 0.4987\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4651 - val_loss: 0.4949\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4610 - val_loss: 0.4894\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4567 - val_loss: 0.4839\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4529 - val_loss: 0.4812\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4495 - val_loss: 0.4772\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4460 - val_loss: 0.4734\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4432 - val_loss: 0.4707\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4402 - val_loss: 0.4660\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4377 - val_loss: 0.4634\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4351 - val_loss: 0.4623\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4328 - val_loss: 0.4590\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4305 - val_loss: 0.4561\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4281 - val_loss: 0.4563\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4267 - val_loss: 0.4534\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4247 - val_loss: 0.4499\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4227 - val_loss: 0.4503\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4212 - val_loss: 0.4454\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4197 - val_loss: 0.4453\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4183 - val_loss: 0.4422\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4166 - val_loss: 0.4401\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4150 - val_loss: 0.4404\n",
            "Epoch 37/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4141 - val_loss: 0.4383\n",
            "Epoch 38/100\n",
            "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4126 - val_loss: 0.4393\n",
            "Epoch 39/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4115 - val_loss: 0.4366\n",
            "Epoch 40/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4102 - val_loss: 0.4348\n",
            "Epoch 41/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4091 - val_loss: 0.4339\n",
            "Epoch 42/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4081 - val_loss: 0.4311\n",
            "Epoch 43/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4068 - val_loss: 0.4302\n",
            "Epoch 44/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4056 - val_loss: 0.4299\n",
            "Epoch 45/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4048 - val_loss: 0.4287\n",
            "Epoch 46/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4038 - val_loss: 0.4272\n",
            "Epoch 47/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4024 - val_loss: 0.4259\n",
            "Epoch 48/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4014 - val_loss: 0.4251\n",
            "Epoch 49/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4006 - val_loss: 0.4244\n",
            "Epoch 50/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3995 - val_loss: 0.4240\n",
            "Epoch 51/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3988 - val_loss: 0.4224\n",
            "Epoch 52/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3978 - val_loss: 0.4212\n",
            "Epoch 53/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3968 - val_loss: 0.4210\n",
            "Epoch 54/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3960 - val_loss: 0.4190\n",
            "Epoch 55/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3951 - val_loss: 0.4186\n",
            "Epoch 56/100\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3944 - val_loss: 0.4180\n",
            "Epoch 57/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3934 - val_loss: 0.4161\n",
            "Epoch 58/100\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3923 - val_loss: 0.4153\n",
            "Epoch 59/100\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3920 - val_loss: 0.4154\n",
            "Epoch 60/100\n",
            "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3912 - val_loss: 0.4139\n",
            "Epoch 61/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3905 - val_loss: 0.4135\n",
            "Epoch 62/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3895 - val_loss: 0.4146\n",
            "Epoch 63/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3887 - val_loss: 0.4110\n",
            "Epoch 64/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3880 - val_loss: 0.4113\n",
            "Epoch 65/100\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3874 - val_loss: 0.4116\n",
            "Epoch 66/100\n",
            "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3868 - val_loss: 0.4099\n",
            "Epoch 67/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3859 - val_loss: 0.4094\n",
            "Epoch 68/100\n",
            "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3853 - val_loss: 0.4082\n",
            "Epoch 69/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3846 - val_loss: 0.4077\n",
            "Epoch 70/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3838 - val_loss: 0.4063\n",
            "Epoch 71/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3832 - val_loss: 0.4054\n",
            "Epoch 72/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3823 - val_loss: 0.4064\n",
            "Epoch 73/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3819 - val_loss: 0.4054\n",
            "Epoch 74/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3812 - val_loss: 0.4043\n",
            "Epoch 75/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3806 - val_loss: 0.4023\n",
            "Epoch 76/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3798 - val_loss: 0.4019\n",
            "Epoch 77/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3789 - val_loss: 0.4015\n",
            "Epoch 78/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3786 - val_loss: 0.4006\n",
            "Epoch 79/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3777 - val_loss: 0.4004\n",
            "Epoch 80/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3771 - val_loss: 0.3993\n",
            "Epoch 81/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3765 - val_loss: 0.3981\n",
            "Epoch 82/100\n",
            "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3757 - val_loss: 0.3980\n",
            "Epoch 83/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3751 - val_loss: 0.3974\n",
            "Epoch 84/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3743 - val_loss: 0.3961\n",
            "Epoch 85/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3737 - val_loss: 0.3961\n",
            "Epoch 86/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3731 - val_loss: 0.3944\n",
            "Epoch 87/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3724 - val_loss: 0.3945\n",
            "Epoch 88/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3717 - val_loss: 0.3935\n",
            "Epoch 89/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3709 - val_loss: 0.3933\n",
            "Epoch 90/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3705 - val_loss: 0.3927\n",
            "Epoch 91/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3697 - val_loss: 0.3924\n",
            "Epoch 92/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3688 - val_loss: 0.3913\n",
            "Epoch 93/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3683 - val_loss: 0.3906\n",
            "Epoch 94/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3675 - val_loss: 0.3900\n",
            "Epoch 95/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3672 - val_loss: 0.3895\n",
            "Epoch 96/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3660 - val_loss: 0.3870\n",
            "Epoch 97/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3656 - val_loss: 0.3868\n",
            "Epoch 98/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3648 - val_loss: 0.3858\n",
            "Epoch 99/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3641 - val_loss: 0.3853\n",
            "Epoch 100/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3635 - val_loss: 0.3844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "outputId": "d93a81b9-0615-48ce-9214-c924f33287b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYXFWB9/Hvqb33Ld2dpDsrhM4O\nAcIq2AKyKuCogwgKqGTGBXRc3sHBl1FnU3ln1HEYEUVZBgVEVBScsEhkh4RAQhYIIWtnT2frrfbz\n/nFuLwmddHXS3XXT/fs8z32q6t5bt0/dp5JfneWea6y1iIiIiH8E8l0AERER2Z/CWURExGcUziIi\nIj6jcBYREfEZhbOIiIjPKJxFRER8ps9wNsb83Biz3Riz7CDbjTHmP40xq40xS40xJw58MUVEREaO\nXGrOdwEXHmL7RcAUb5kH/PjIiyUiIjJy9RnO1tpngF2H2OUy4B7rvASUG2PGDFQBRURERpqB6HOu\nAzb2eN3krRMREZHDEBrKP2aMmYdr+iYWi500fvx4muOWtpRlfInGpg2GbDZLIKBzO9h0noeOzvXQ\n0HkeeKtWrdppra3OZd+BCOdNwLger+u9de9irb0DuAOgoaHBvvXWW/zTH1fwwMKNLPvWBQNQFDnQ\nggULaGxszHcxhj2d56Gjcz00dJ4HnjFmfa77DsTPokeAT3qjtk8D9lprt+T65nAwQDKTHYBiiIiI\nDA991pyNMb8CGoFRxpgm4B+BMIC19nbgMeBiYDXQDlzXnwJEgoZUJou1FmNM/0ovIiIyDPUZztba\nK/vYboHPH24BwsEA1kImawkFFc4iIiJDOiCsN+GQa1lPZSyhYJ4LIyIiB5VKpWhqaiIej+e7KL4W\ni8Wor68nHA4f9jHyH85BF87JTJYClM4iIn7V1NRESUkJEydOVDfkQVhraW5upqmpiUmTJh32cfI+\nTj7iNWWnNChMRMTX4vE4VVVVCuZDMMZQVVV1xK0LeQ/nzpqzwllExP8UzH0biHPkn3BO2zyXRERE\n/K64uDjfRRgS+Q/nUHefs4iIiPggnNXnLCIi/WWt5Wtf+xozZ85k1qxZPPDAAwBs2bKFs88+mxNO\nOIGZM2fy7LPPkslkuPbaa7v2/f73v5/n0vfNN6O1Fc4iIpKrhx9+mNdff50lS5awc+dO5s6dy9ln\nn80vf/lLLrjgAm6++WYymQzt7e28/vrrbNq0iWXLlgGwZ8+ePJe+bwpnERHpt2/9YTkrNu8b0GNO\nH1vKP35wRk77Pvfcc1x55ZUEg0Fqa2t573vfy8KFC5k7dy6f+tSnSKVSXH755ZxwwglMnjyZNWvW\ncMMNN3DJJZdw/vnnD2i5B0Pem7W7rnPWgDARETlCZ599Ns888wx1dXVce+213HPPPVRUVLBkyRIa\nGxu5/fbb+cxnPpPvYvYp7zXnSEh9ziIiR5tca7iD5ayzzuInP/kJ11xzDbt27eKZZ57h1ltvZf36\n9dTX13P99deTSCRYvHgxF198MZFIhA9/+MM0NDRw9dVX57Xsuch7OKtZW0RE+utDH/oQL774Iscf\nfzzGGL73ve8xevRo7r77bm699VbC4TDFxcXcc889bNq0ieuuu45s1uXMv/3bv+W59H1TOIuIyFGj\ntbUVcBN93Hrrrdx66637bb/mmmu45ppr3vW+xYsXD0n5Bop/+pwz6nMWEREBH4RzpGuGMNWcRURE\nII/hHMwkAAhrQJiIiMh+8hbOsfg2QH3OIiIiB8pbOAdsGrJZ9TmLiIgcIH99zjYLrVu7+5xVcxYR\nEQHyPSBs11rCnTe+0IAwERERIO/hvIZgwGCMas4iIjLwDnX/53Xr1jFz5swhLE3u8hjOBnavxRhD\nOBhQn7OIiIgnb+GcDYRg1xrAXeusmrOIiPTlpptu4rbbbut6/c1vfpN//ud/5txzz+XEE09k1qxZ\n/P73v+/3cePxONdddx2zZs1izpw5PP300wAsX76cU045hRNOOIHZs2fz9ttv09bWxiWXXMLxxx/P\nzJkzu+4lPZDyNn1nNhCGXWsBCAeNwllE5Gjyp5tg6xsDe8zRs+Ci7xxylyuuuIIvfelLfP7znwfg\nwQcfZP78+dx4442Ulpayc+dOTjvtNC699FKMMTn/6dtuuw1jDG+88QZvvvkm559/PqtWreL222/n\ni1/8IldddRXJZJJMJsNjjz3G2LFjefTRRwHYu3fv4X/mg8hbzdkaL5ytJayas4iI5GDOnDls376d\nzZs3s2TJEioqKhg9ejT/8A//wOzZsznvvPPYtGkT27Zt69dxn3vuua67VU2dOpUJEyawatUqTj/9\ndP71X/+V7373u6xfv56CggJmzZrFE088wd///d/z7LPPUlZWNuCfM78158Re6Njt+px1P2cRkaNH\nHzXcwfTRj36Uhx56iK1bt3LFFVdw3333sWPHDl599VXC4TATJ04kHo8PyN/6+Mc/zqmnnsqjjz7K\nxRdfzE9+8hPOOeccFi9ezGOPPcY3vvENzj33XG655ZYB+Xud8hvOxGHXWiIh1ZxFRCQ3V1xxBddf\nfz07d+7kL3/5Cw8++CA1NTWEw2Gefvpp1q9f3+9jnnXWWdx3332cc845rFq1ig0bNtDQ0MCaNWuY\nPHkyN954Ixs2bGDp0qVMnTqVyspKrr76asrLy/nZz3424J8xz+EM7FpDOFijcBYRkZzMmDGDlpYW\n6urqGDNmDFdddRUf/OAHmTVrFieffDJTp07t9zE/97nP8dnPfpZZs2YRCoW46667iEajPPjgg9x7\n772Ew+Gu5vOFCxfyta99jUAgQDgc5sc//vGAf8a8hbPtDOfdawkHRyucRUQkZ2+80T0YbdSoUbz4\n4ou97td5/+feTJw4kWXLlgEQi8X4xS9+8a59brrpJm666ab91l1wwQVccMEFh1PsnOVvQBgGSuu8\nmrOucxYREemUt5ozABWTXJ9zMKDpO0VEZFC88cYbfOITn9hvXTQa5eWXX85TifqW33CunASr5hOu\nMCRSCmcRERl4s2bN4vXXX893Mfolv3NrV06Ctu0UmwSprJq1RUT8zlr9X92XgThH+Q3nikkAjM1u\nVbO2iIjPxWIxmpubFdCHYK2lubmZWCx2RMfJc7P2ZADGZLeQyozOa1FEROTQ6uvraWpqYseOHfku\niq/FYjHq6+uP6Bj573MGatNbSGWOz2tRRETk0MLhMJMmTcp3MUaE/DZrx8qgsIra9CZSupRKREQE\nyHc4A1RMYlRqM0lNQiIiIgL4IZwrJzMquUkzhImIiHh8EM6TKE1uh3Qi3yURERHxBR+E82QCZKnN\nbM93SURERHwh/+HsXes8xm7RtXMiIiL4IZy9y6kmmm2kNUuYiIiID8K5qJpksJAJZpsGhYmIiOCH\ncDaGloJ6F85p1ZxFRETyH85Aa9F4JphtutZZRESEHMPZGHOhMeYtY8xqY8xNvWwfb4x52hjzmjFm\nqTHm4v4Uor1oHPVmB6lUqj9vExERGZb6DGdjTBC4DbgImA5caYyZfsBu3wAetNbOAT4G/Hd/CtFR\nMoGoSZPdu6k/bxMRERmWcqk5nwKsttausdYmgfuByw7YxwKl3vMyYHN/ChEvmQCA2b2mP28TEREZ\nlnK5K1UdsLHH6ybg1AP2+SbwuDHmBqAIOK+3Axlj5gHzAKqrq1mwYAEAK7ZZzgC2LnqUt/cV9KP4\n0pfW1tau8yyDR+d56OhcDw2d5/waqFtGXgncZa39d2PM6cC9xpiZ1tr9RnhZa+8A7gBoaGiwjY2N\nAGTf3Mbqt8YyJdBEqbdOBsaCBQto1DkddDrPQ0fnemjoPOdXLs3am4BxPV7Xe+t6+jTwIIC19kUg\nBozKtRDhYICXstMo2rYQMulc3yYiIjIs5RLOC4EpxphJxpgIbsDXIwfsswE4F8AYMw0XzjtyLYQL\n5+kEU62wdUmubxMRERmW+gxna20a+AIwH1iJG5W93BjzbWPMpd5uXwGuN8YsAX4FXGv7MVF2OBjg\n5ew092Ld8/37BCIiIsNMTn3O1trHgMcOWHdLj+crgDMPtxCRYIAdlNNWMomidc/BmTce7qFERESO\ner6YISwcMgDsHHUKbHgRspk8l0hERCR/fBHOY8sLMAZWRmZBYh9sXZrvIomIiOSNL8K5NBbm2Opi\nHm871q1Y91x+CyQiIpJHvghngDnjy3l6cxBbdawGhYmIyIjmo3CuYHd7itbaU2H9C+p3FhGREctH\n4VwOwJsFsyGxF7a+kecSiYiI5IdvwnlKTQlFkSB/iTe4FevVtC0iIiOTb8I5GDDMri/nmW1hqJys\nQWEiIjJi+SacwTVtr9i8j/T4M71+52zfbxIRERlmfBXOJ4wrJ521bCg5EeJ7YNuyfBdJRERkyPkr\nnL1BYS91zbOtpm0RERl5fBXONSUx6isKeH57FComKZxFRGRE8lU4g7ve+bUNu+GY98GapyG+L99F\nEhERGVK+C+cTxpWzeW+c5ikfgVQ7LH8430USEREZUr4L587JSBYmJ0P1NFh8T55LJCIiMrR8F84z\nxpYSCQZ4rWkPnPhJ2PQqbFue72KJiIgMGd+FczQUZNrYUl7bsAdmXwHBCCy+N9/FEhERGTK+C2eA\nOePKeaNpL+lYBUy9BJbeD+lEvoslIiIyJPwZzuPL6UhleGtbi2va7tgNb/4x38USEREZEr4M5xPH\nVwC4pu1JjVA2XgPDRERkxPBlONdXFFBVFHHhHAjAnKthzQLYvS7fRRMRERl0vgxnYwxzxlfw8tpm\nrLUw5yrAwGv35btoIiIig86X4Qxw/oxamnZ3sKRpL5TVw7Hnwuv3QTaT76KJiIgMKt+G8wUzRhMJ\nBnjk9c1uxYmfhH2b4O0n8lswERGRQebbcC4rCPO+qdX8YelmMlkLx10EJWPhpdvyXTQREZFB5dtw\nBrjshDp2tCR4aU0zhCJw2t/C2mdg8+v5LpqIiMig8XU4nzO1huJoqLtp+6RrIVICL/wor+USEREZ\nTL4O51g4yPkzanls2RYS6QzEyuCka2D5b2HPhnwXT0REZFD4OpzBNW23xNMseGuHW3HaZ8EYeOn2\n/BZMRERkkPg+nM88poqqogiPLPGatsvqYcZfweK7oWNPfgsnIiIyCHwfzqFggEtmj+HJFdtoTaTd\nyjNugGQrvPqL/BZORERkEPg+nAEuO2EsiXSWx5dvdSvGzIbJja5pO53MZ9FEREQG3FERzieOr6Cu\nvKC7aRtc7bl1Kyx7KH8FExERGQRHRTgbY7j0hLE8+/ZOmlu9+zofcy7UzIDn/xOy2fwWUEREZAAd\nFeEMrmk7k7X89rVNboUxcOaNsGMlvD0/v4UTEREZQEdNOE8dXcopEyv5xfPrSGe8mvLMD7t7PT/7\nH2BtfgsoIiIyQI6acAb49FmT2LSng8dXbHMrgmFXe256BdY/n9/CiYiIDJCjKpzPm1bL+MpCfvbs\nmu6Vc66GompXexYRERkGjqpwDgYM1505kcUb9rB4w263MlzgZg175yndEENERIaFoyqcAT568jhK\nYiHufG5t98q5n4FoKTz/g/wVTEREZIAcdeFcHA1x5Snj+d9lW2na3e5Wxspg7qdhxe+h+Z38FlBE\nROQIHXXhDHDNGRMBuPuFdd0rT/scBMKqPYuIyFHvqAznuvICLpo5mvtf2dg933ZxjRsc9vqvYN/m\nQx9ARETEx47KcAb49Hsm0ZJI8+tFG7tXnnmjm5zkf7+ev4KJiIgcoaM2nOeMr+CkCRX87Nm1xFMZ\nt7JiIrz372HF72D5b/NaPhERkcOVUzgbYy40xrxljFltjLnpIPv8tTFmhTFmuTHmlwNbzN793XnH\nsWlPB/e8uK575ZlfgrFz4NGvQOuOoSiGiIjIgOoznI0xQeA24CJgOnClMWb6AftMAb4OnGmtnQF8\naRDK+i7vmTKK9zVU86M/r2Z3m3fryGAILv8xJFrg0S9rWk8RETnq5FJzPgVYba1dY61NAvcDlx2w\nz/XAbdba3QDW2u0DW8yD+/rF02hLpPnhU293r6yZBo1fh5WPwPKHh6ooIiIiAyKXcK4Deoy6oslb\n19NxwHHGmOeNMS8ZYy4cqAL25bjaEq6YO57/eWk9a3e2dW8440aoOwke/Sq0DtlvBRERkSMWGsDj\nTAEagXrgGWPMLGvtnp47GWPmAfMAqqurWbBgwYD88VOLsvzWWL5677PcMCfWtb5w7LWcvPnvaL7r\napbP+LobyT3CtLa2Dth5loPTeR46OtdDQ+c5v3IJ503AuB6v6711PTUBL1trU8BaY8wqXFgv7LmT\ntfYO4A6AhoYG29jYeJjFfreNobf59ydWUThhNqdMquzeULGX6se/QWNsJZz+uQH7e0eLBQsWMJDn\nWXqn8zx0dK6Hhs5zfuXSrL0QmGKMmWSMiQAfAx45YJ/f4WrNGGNG4Zq51zCEPnPWZEaXxviXR1eQ\nzfYYBHb6F2DqB+CJ/wvrXxzKIomIiByWPsPZWpsGvgDMB1YCD1prlxtjvm2MudTbbT7QbIxZATwN\nfM1a2zxYhe5NQSTIVy9oYEnTXh5+rUfF3hi4/L+hfDz8+lr1P4uIiO/ldJ2ztfYxa+1x1tpjrLX/\n4q27xVr7iPfcWmu/bK2dbq2dZa29fzALfTB/NaeOkydU8O0/LGf7vnj3hlgZ/PW9EN8LD30KMul8\nFE9ERCQnR+0MYb0JBAzf+8hsEuksN/9uGbbnNc6jZ8IHfwDrnoU//1P+CikiItKHYRXOAJOri/nK\n+cfxxIptPLLkgBtgHP8xOPlT7s5Vy3T9s4iI+NOwC2eAT79nMnPGl/OPjyxnR0ti/40XfgfGnw6/\n/RtY+0x+CigiInIIwzKcgwHDrR+ZTXsywy2/X7b/xlAUPvZLqJwM918FW9/ITyFFREQOYliGM8Cx\nNSV86bwp/GnZVh5dumX/jYWVcPVvIFoC//MR2L0+P4UUERHpxbANZ4B5Z01mdn0ZN//uDTY0t++/\nsazeBXS6A/7nw9A2pFd+iYiIHNSwDudQMMCPrpyDtfCZexbSmjjgEqqaaXDlA7B3I9z3YWjflZ+C\nioiI9DCswxlgQlUR/33Vibyzo40v3f/6/rOHAUw4HT56N2xbAT+/APZs7P1AIiIiQ2TYhzPAmceO\n4pYPTOfJldv4jydWvXuHhgvhE7+Flm1w5/mwfeXQF1JERMQzIsIZ4JOnT+DKU8bxX0+v5g8HXv8M\nMPFMuO4xsBlXg97w0tAXUkREhBEUzsYYvnXpTOZOrOCrv17C4g27373T6Jnw6cehcBTccxm8ehdk\ns0NeVhERGdlGTDgDREIBfnz1SdSWxrjmzld6D+iKiS6g6+fCH74Id10MO94a8rKKiMjINaLCGWBU\ncZT7551GZXGET975Cq+u7yWgi0bBNX+AS//L9T//+Ez4879AKv7ufUVERAbYiAtngLHlBdw/7zRG\nFUe45uev8Or6Xi6hMgZO/AR8YRHM+BA88z24bS68/BNItA59oUVEZMQYkeEMMKasgPvnnU51SZRP\n3vkKi9Yd5Brn4mr48E/hE7+DkjHwp/8D358OT34T9m3p/T0iIiJHYMSGM8Doshi/uv40akpjfOLO\nV5i/fOvBdz7mfa4v+tNPwKT3wvM/hB/Mgvk3Q6Jl6AotIiLD3ogOZ3AB/eDfnM5xo0v42/95lZ/8\n5Z397wN9oHGnwBX3wg2L3S0oX7wN/muuuwXlod4nIiKSoxEfzgDVJVEemHcaF88aw7/96U1u+s0b\nJNN9XEJVOQku+y/4zJNQVA0PXQf3Xq6R3SIicsQUzp5YOMiPPjaHG845lgcWbeSan7/C7rZk32+s\nPxnmLYCLboVNr8Ftp8BPz4EXfgR7Ngx2sUVEZBhSOPcQCBi+cn4D//7R41m0fhfn/+AZ/vzmthze\nGIRT58ENi+D934ZsBh7/huuT/um58PqvIJMa/A8gIiLDgsK5Fx8+qZ7fff5MKgsjfOquRdz0m6Xv\nvqNVb4pr4Mwvwt/8BW58Dc79R0i2wu/+Fn50Eiz6OaQTg/8BRETkqKZwPogZY8t45IYz+dv3HsOD\nizZy4Q+e4YV3duZ+gMrJcNaX4XMvwZX3u4lN/vh38MPj4Zn/BxtfUVCLiEivQvkugJ9FQ0Fuumgq\n759ew5cfXMLHf/oy72uo5ivnNzCzriy3gxgDDRfBcRfCmgUumP/8T25bMApj57gR4FPOhwlnuCZy\nEREZ0RTOOThpQiX/+8WzueuFddz+l3f4wI+e45LZY/jy+4/jmOri3A5ijLtW+pj3uVtTNr0CG192\nNeiXb4cX/hOKamD6pTD9cgW1iMgIpnDOUUEkyGcbj+Hjp47nzmfXcOdza/nTG1u4ZPZY5p01mVn1\nOdakAUpqYdoH3QKQbIO3H4flv4PX7oOFP1NQi4iMYArnfiorCPPl8xu45oyJ3PHMGn758gb+sGQz\np02uZN7Zk2k8roZAwPTvoJEiN3/3jA+5oF41H1YcENTTPgjjT4NRx7klUjg4H1BERPJO4XyYqoqj\nfP3iaXz+nGN54JWN/Pz5tXzqrkVMHlXEX88dx1/NqaOmNNb/A0eKYOZfuaVnjfr1X8KiO72dDJSP\ng5oZMOF0mHAmjDkeguEB/YwiIpIfCucjVBoLc/3Zk7n2zIn8celm7ntpA9/505vcOv8tGo+r5qMn\n1/O+qTVEQ4fRLN2zRp1OQPM7sPMt2LHKPW5ZAqv+5PYNF7qBZeNPd/eirj8ZYv1oahcREd9QOA+Q\ncDDAh+bU86E59byzo5WHXm3iN6828dSb2ymKBGmcWsMFM0bzvoZqSmKHUcMNRaF2ult6at0O61+A\n9c+7xwXfASxgoGY6DYExEF0O1Q1QPRVK69zgNBER8S2F8yA4prqYv79wKl95/3E8t3on85dv5YkV\n23h06RYiwQBnHFvF+6fX8v5ptYfX9N1TcQ3MuNwtAPF9sOlVNwq86RVGrXsZ5j/ZvX+kGMadCsee\nB1PeD1XHKqxFRHxG4TyIQsEAjQ01NDbU8M+XWxZv2M38ZVt5fMU2bv7tMm7+7TJOGFfO+6fXcvaU\naqaPLSXY38FkB4qVdl+yBTy/YAGNc2e6G3LseBO2r4S1f4H5X3dL+QSY/F6omQ6jpsCoBiirV2CL\niOSRwnmIBAOGuRMrmTuxkpsvmcaqba08scIF9a3z3+LW+W9REgsxd2Ilp06q5LTJVcysKzvysAY3\nO1nRKJh4Zve63etg9ZOw+ilY8Qgsvqd7W7jIXe4VK/OWcnfnrTGzYcwJUDNNg89ERAaRwjkPjDE0\njC6hYXQJXzhnCtv2xXlpTTMvrdnFy2ua+fOb2wEoiYU4dVIVZxxTxRnHVnFcTUn/L9M6mIqJMPcz\nbrEW2na6QWY7V8HOt6FtB3Tsgfhe2LcF9j0FC3/q3huMQu0MF9Y1M1w/eM10KKwcmLKJiIxwCmcf\nqC2NcdkJdVx2Qh0A2/fFeXFNMy+taeaFd5p5cqW7M1ZZQZgTx5dz8sRKTppQwfH15RREBmByEmOg\nuNotE9/T+z7ZLOxeC5tfgy2vw+bXYcXv4dW7uveJlXv7ZiCbBpuBktFQO9OFd+0MGD0LKo+BgKZ1\nFxE5GIWzD9UcENab9nTw4jvNLFq3i0Xrd/P0W28Brqn8uNoSZteVMau+jOPry2kYXUIkNAjBFwhA\n1TFumfURt85aaNkK25bD9uXu/tUmCIGQm9HMGNizEbavcBOr2Ix7X7TUzSledxLUnQgFFZBJQjrp\nHoMRd/22LgUTkRFK4XwUqCsv4CMn1fORk+oB2N2WZPGG3by2YQ9LN+3l8RVbeWDRRgAiwQDTx5Zy\nfH0Zx48rJ96aJZ3JEgoOQmAbA6Vj3DLlvEPvm4q7JvOtS2HTYjei/IX/dDXs3gRC7prt4y6AKRe4\nHwUmoIFqIjIiKJyPQhVFEc6dVsu502oBsNbStLuDpU17Wdq0h9c37uHXrzZx94vrAfjmi/M5pqaY\nqaNLOK62hKmjS5g2ppTa0ihmqMIuHPMGlM2GOVe7dak4bFvmZkILRV2NORiB+B43WG3V4/D4N9zS\nkwm4SVeqp7pm8tGzYPRsN9q8oHxoPo+IyCBSOA8DxhjGVRYyrrKQS2aPASCTtaze3sqvn3qJYEU9\nb25t4aU1zfz2tU1d7ysvDDNtdCkNo0uYNKqoaxlbXjAwo8T7Eo65mcx6M/E9cN43XVP56ifdgDWb\ndf3ZNguJFtdcvvxhePUX3e+LlkL5eLeUjHZN79l09xIr695ePh6KayHZ7o6X2OseY2XukrKS0aqp\ni0heKJyHqWDAjQh/T12YxsZpXev3dqR4a2sLb27dx8ot+1i5pYUHF22kPZnp2icSDDBxVCHHVBdz\nTHUxx9YUM7m6iImjiig9nNnNjkT5eDj5Uwffbi3s3Qhb34Bda1yY79kAu9e7W3J29oEHQ+55x25X\nM89FtAyqvRuNlNZ5Tfh1UDLGXZoWLXGXnWlwm4gMMIXzCFNWEOaUSZWcMqn7sidrLTtaEqzZ2ca6\nnW2s3dnGOzvaeHNrC4+v2EYma7v2rSqKMHFUEROqCplY5R7HVxYyoaqIisLw0DWTdzKmuxacq/je\n7hBv3e5mTYuWuAlcoiXQ3uzmL9/xpusnf+fPbuAbtpeDGYiWcKqJwcZZ7hrw6qnusazeC/BC1cBF\npF8UzoIxhprSGDWlMU6bXLXftkQ6w4bmdt7Z0cq65nbWN7vwfmF1Mw8v3rTfviWxEJNGFTGxqruJ\nfHRZjFHFEaqKopQVhAfuOu0jESvr7qs+mMmN+7/OpKF1G+zbDC2boX2X1xTuln1rl1PQtgMWPg/p\n+P7vNUEX0pFiN3lLMAwB7zFS5C5BKyj3HivclKzFtW4imOJaNwGMJn0RGVEUznJI0VCQKbUlTKkt\nede2eCrDxl3trG9uZ/2u7uBevGE3f1i6GXtARTMYMFQVRRhbXkBdeQF1FQWMLYtRV1HI2PIYdeUF\nlBXkofadi2AIyurc0ouVCxZQ29jo+sR3r3PTpLZu2y/ASbRANuUuF8uk3fNkm9t/yx436Uuqrfe/\nHy11k7wUVkFBJUSLXbBHSrzHQtfEHil0r8OF3QPsOn8QREtd8EdLVZMX8TmFsxy2WLjv4N7ekmBn\na4Lm1iS72pJsb4mzeU+clVum9DbAAAAUvElEQVT28eTKbSTS2f3eVxgJMrosRk1JlOoSV+uuLoky\nqjhKdbF7HFXiauKDcj33kQoEu68HPxzphGtqb93uwr11K7Q1u6b2rmWnC/RkGyRb3WKzfR66S6ig\nu3ZeWOlq6wXeY6TIfYZA5/XqYTcwrmyca6aPFB7e5xKRflE4y6A4VHB3stayszXJlr0dbN7TwaY9\ncTbv6WDL3g52tCRYtmkvO1oStCZ6vxa6NBZiVEmUUUVRqrwQrymJuib6kig1JTFqS6NUFEb80Zye\ni1AUyse5JVfWuqb0ZLureXc+ZtKulp5NuQleEvtc4Lds7Q7/fZth2wo3UC7Z0vffKvTmaQ+GvVp5\n1D0PF0Ao5mrs4Zhroi+rg9J6F+qlY113QmAAZrQTGQEUzpI3xhiqS6JUl0SZXX/w65Pbk2maW5Ps\naE2wsyXBztakVxtPsLMtSXNrgre3t/LCO83s7Ui96/2hgPs7NaUxKgrDFEVDlERD7jEWosqrlVeX\nRBhVHKWiKEJxJHT0BLoxLhzDBUBVn7sfVDoJqXbvkjXv0rN03IX5no1uVPzeja6/PesFfybpavvx\nPe669VSHO0Z8T+8TzIRiXjN8kQv2Az9HQYXrYy8aBUU1LtBD0e4fA4EQYzYvhudecwP74nvdMcee\n6C7Lq5ioJnsZFnIKZ2PMhcAPgSDwM2vtdw6y34eBh4C51tpFA1ZKGdEKIyEKK0OMq+y7STWeyrCj\nJcH2ljjb9iXYvi/O9paEe94SZ1dbkg272mmNp2lLpGnrcQlZT8ZASTREWWGY0liYyqIIFYURKovc\nUl4Ypqyge9nalqW5NUFJLOzP5vZchCJuOVDlZJjQz2NlM652vrcJ9jW5GnrCa4JPtrklkwB6BKnN\nuhr8rjXuMrj25l6b6xsAVuGa3GNl7ljp/3YbC0e5qWHDBd4c7ynIpPa/1j2TclPJFlS4y+KKa91j\nYZWr9YcK3A+CcIHrny+ocAP2QtF3lUVksPQZzsaYIHAb8H6gCVhojHnEWrvigP1KgC8CLw9GQUVy\nEQsHuyZkyUUqk2VXW5IdXt/4jpYEeztS7OtIsS+eZm9Hir0dKXa3u1Df1ZakJd57M/tNzz4JQEE4\nSGlBiPKCCBVFYSoKI1QURagodM/LCsKUF7rXJbEwRdEgxV5NPjwY06zmQyDYPbUrcw/vGNmMC/PO\n5vlMAjJpXnh1CWe87yIXnsa47dtXwKZF0LQItix1oRwIu3IEw17/eci9JxBys8y174INL7qWgUyy\n7/KEi9yo+1DE1daDURfYnSPsi6rdUljlDdgr7r6ULh133Qrxfe4xk3KX7nXekrXn7Vl7+4EkI04u\nNedTgNXW2jUAxpj7gcuAFQfs90/Ad4GvDWgJRQZROBigtjRGbWks5/ck09mu0O4M8hcXL6Vu4rFe\nqLv1e9rd8vb2Vva0J9ndntrvmvHeREIBSmMhSmJhSmKu2b28IEKVdzmae4zst73zeTQU8OdI98MV\nCPZ685NktGn/gWnBUPfUsIeasOZgrHU19o7dLkRTce+xw80a17HbjaTv2O2CNe39UEgnId3hbq+6\nfYV7zCXk+xIudCFdWOX668vHuQF55eNc2Ae9qW5Dke7nnc3+nTX+UEzN+0e5XMK5DtjY43UTcGrP\nHYwxJwLjrLWPGmMUzjKsRUKBrr7yTmZriMYzJh7yfdZaWhJp9ra7mvju9lRX83prwntMpmmJdy4u\n+Lfs3Udza7LX/vSeggFDUaS7Ft6z2b20IExpLERBJERhJEhBOEhhNNgV7KWxcNePglh4mIV8X4zx\nLlM7wvuRW+v6wDt2dTfhdz6GYt4kN6XuMRB2l9Z19pvH93TfP73zedsON1HO+ufdj4J+faagV3sv\ncT9kjDcC3wRcy0GkqLu5vvP6+p4j9wsrKWjf7LoYTMBbgi78Q1H3eQIh/QAYREc8IMwYEwD+A7g2\nh33nAfMAqqurWbBgwZH+eelDa2urzvMQONzzXOQtNeBGdBR4y7tESGfDtCYt+5KWjjR0pC3t3mNH\n2hJPQzxtiWfSdKRTtLW0s30XtKUs7d72Q9fbnaCBWAgKQ4ZYyFAQgljQEAtBNOi9DrnXsaChINS9\nLRp0j7EQFHjvDQzwf+BH13c6AnSGfhrY5S0H7lPjLUDUW8pxVSMgmG4jFt9BMNNBIJvC2DSBbIpA\nNt31vPMxmEkQzHR4S5xgJo6xWchkMdYtwbZmwtvXEUq3Ek61ELDv7qo5FeCVg38yS4B0qJBUuLRr\nSYeKsCZA51gCawKkQ8UkopUkI5UkopWkwiUYC+DKApZsIEI6VOTeH9CEO5BbOG8Cel7XUe+t61QC\nzAQWeL+2RwOPGGMuPXBQmLX2DuAOgIaGBtvY2Hj4JZecLFiwAJ3nwXc0nGdrLfFUlvZkmvZkhvZk\nhtZEin0dafbFXR97azxNayJFi/d8X9fAuTTNiTRt7RlXy0+m3jXJzMEURVwNvWctvqwgTHE0SDAQ\nIBQ0BAOGUMBQGAlRHAtRHA1SFAlRHA1REAm6QYGRIIWRIItfecH35/qoYq0bYd+x2/XDd+yGjl2s\nWLaE6VOnukF5nSP400nX5J9OYNJxwvG9hHtegx/f4o7nhW7XIL/+NPeHClytP+DNhx/oUWsPF7jt\nnU33wVD3bHuBoOvn7+y7Lyh3LRWRIre+a7KeQvfeUMy9z6e1/1zCeSEwxRgzCRfKHwM+3rnRWrsX\nGNX52hizAPiqRmuL+IsxhoJIkIJI8EguuAIgm7V0pFxQt8TTdCQzXaHflnSB3t087zXRe33xm/Z0\nsHLLPtqSaTIZSzpryWQtqWw258CPPPUnSmKdQe6a8YsiQQo7HyMhYuFgVxN+wQGPsf2eB7q2FR1N\nl9ANFGO6L28rq+9avX1HBdOPbzzy43f26bdscUv7bvc3TaC7qT0Vd835ca9pP9HSfQe6bMaNrk8n\nuscCxPdCeps3Et8bjZ9Ju5H7ib39+OwBL6ij3gA/rx+/uMbdgrZqirvxTeUk71K+YHcTf7jAhf4g\n3fimz3C21qaNMV8A5uMa3n5urV1ujPk2sMha+8iglExEfCsQMC4QoyFqSwfmmJ01+5ZEirZExqvF\np4mnMl5N34X/0pWrqB47npa4V8P3+ut3tiZp29VOW8L9WIinsiQz/Zg5zVMUCVIcc5+tM8g7Azwa\nDlLYGexeuBdFQhR6Nf1C74dBQSRANLT/PkXRIKHhMhq/P3r26dfOGPy/l824PvrOPvxUe/fle8lW\nF+7p+P6D/9KJHoP84u5HxIrfux8Vh/xsAW8cQZl7DMe6Q75zUp5oibf07x9KTn3O1trHgMcOWHfL\nQfZt7FcJRETYv2bPwSeWY0FyHY2NU3M6ZiqTJZ7K0JHM0JHylqRb4ukMHUlvu7e+tcfgvJZEmri3\nXzyVZXdbqntf7wdDMt2/8C8IB70fNUEiwQCRkLcEA921ey/8O38UxELe84j7YdA5eU5R1DX/F0fd\n5Xgjstbfm0DQG9hWceTHamuG5rfdLWizqf1r8p01+K5lnwv2TNI9z+zoca/4Fjeyvx80Q5iIDFvh\nYIBwMEDJIN2HPOM177d7E9q0JVztvjPEO2v9bYm0aw1IpGhNuFaAZDrrlkyWRMpdb9/5I6LzffFU\nhj6uvttPUcTV7oMBQzhgCHk/ADqDvGc/fs8WgZi3dHYDxCJB3tqVobJpj1sXCXW1GAy7S/YOpajK\nLeNPO/JjpZPwrdwnslE4i4gcpmDAUBx1gTcYrLWkMtarvWdoT2S6L7vrquV3h35rPE0qkyWdzZLK\nuL78RDpDa8L9QGhubacl7roKOn9AHDL8X3m+19WdoV7oNdcXeeegKBJy2yLBrmb9WChINBwgGnJN\n/T37+HsO9Cv0ugcKw8O0+b+fk8sonEVEfMoYQyRkvMlpwods7j8cneHfkcqQ6NFc357M8PKixUyZ\nNpP2ZHe/v6vVZ73X6f1aBVriabbtixNPZbtq//FUhlSmH1V/TyQU6BrY5wbqubCPhAKEg+58REPB\nrub8Qq9loDDSY4Cgt62reyDsav2dPxz8TuEsIjJC9Qx/CvZv+m9ZG6Rxeu0R/41M1pJMZ0mkMyTS\n2R4D/DJdo/w7ejT/d47470juPxAw4YX+vrjrDtivy+Agc+QfTDhouoK8IBIkFDCEgwHXHeBtK+8x\n3W5pQZhoj/EBkVBny0Gwa2BkUY9BggNR81c4i4jIoAkGegz0GyTZrKXd6/tv7bG0J9yAvkQq2zWw\nL+5dAuj2zdCRSpPKWNKZLOmsJZ2x7GlPsq65jT3t7hLAXC/x6xQOGne5Xo/R/rFw/z6/wllERI5q\ngR59/zUDfOxM1tIaT5PIZPYbxNfRNZFPmvakC/r4AVcFxLua992Pg/5QOIuIiBxEMGAoKwwDRz7i\n/+5+3JdlGA6JExERObopnEVERHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER\n8RmFs4iIiM8onEVERHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iI\niM8onEVERHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVE\nRHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVERHxG4Swi\nIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPpNTOBtjLjTGvGWMWW2MuamX7V82xqwwxiw1xjxl\njJkw8EUVEREZGfoMZ2NMELgNuAiYDlxpjJl+wG6vASdba2cDDwHfG+iCioiIjBS51JxPAVZba9dY\na5PA/cBlPXew1j5trW33Xr4E1A9sMUVEREaOUA771AEbe7xuAk49xP6fBv7U2wZjzDxgHkB1dTUL\nFizIrZRy2FpbW3Weh4DO89DRuR4aOs/5lUs458wYczVwMvDe3rZba+8A7gBoaGiwjY2NA/nnpRcL\nFixA53nw6TwPHZ3roaHznF+5hPMmYFyP1/Xeuv0YY84Dbgbea61NDEzxRERERp5c+pwXAlOMMZOM\nMRHgY8AjPXcwxswBfgJcaq3dPvDFFBERGTn6DGdrbRr4AjAfWAk8aK1dboz5tjHmUm+3W4Fi4NfG\nmNeNMY8c5HAiIiLSh5z6nK21jwGPHbDulh7PzxvgcomIiIxYmiFMRETEZxTOIiIiPqNwFhER8RmF\ns4iIiM8onEVERHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8o\nnEVERHxG4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVERHxG\n4SwiIuIzCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVERHxG4SwiIuIz\nCmcRERGfUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVERHxG4SwiIuIzCmcRERGf\nUTiLiIj4jMJZRETEZxTOIiIiPqNwFhER8RmFs4iIiM8onEVERHwmp3A2xlxojHnLGLPaGHNTL9uj\nxpgHvO0vG2MmDnRBRURERoo+w9kYEwRuAy4CpgNXGmOmH7Dbp4Hd1tpjge8D3x3ogoqIiIwUudSc\nTwFWW2vXWGuTwP3AZQfscxlwt/f8IeBcY4wZuGKKiIiMHLmEcx2wscfrJm9dr/tYa9PAXqBqIAoo\nIiIy0oSG8o8ZY+YB87yXCWPMsqH8+yPUKGBnvgsxAug8Dx2d66Gh8zzwJuS6Yy7hvAkY1+N1vbeu\nt32ajDEhoAxoPvBA1to7gDsAjDGLrLUn51pQOTw6z0ND53no6FwPDZ3n/MqlWXshMMUYM8kYEwE+\nBjxywD6PANd4zz8C/NlaaweumCIiIiNHnzVna23aGPMFYD4QBH5urV1ujPk2sMha+whwJ3CvMWY1\nsAsX4CIiInIYcupzttY+Bjx2wLpbejyPAx/t59++o5/7y+HReR4aOs9DR+d6aOg855FR67OIiIi/\naPpOERERn8lLOPc1HagcHmPMOGPM08aYFcaY5caYL3rrK40xTxhj3vYeK/Jd1uHAGBM0xrxmjPmj\n93qSN33tam8620i+y3i0M8aUG2MeMsa8aYxZaYw5Xd/ngWeM+Tvv/4xlxphfGWNi+j7n15CHc47T\ngcrhSQNfsdZOB04DPu+d25uAp6y1U4CnvNdy5L4IrOzx+rvA971pbHfjprWVI/ND4H+ttVOB43Hn\nW9/nAWSMqQNuBE621s7EDfz9GPo+51U+as65TAcqh8Fau8Vau9h73oL7j6yO/adXvRu4PD8lHD6M\nMfXAJcDPvNcGOAc3fS3oPB8xY0wZcDbuahCstUlr7R70fR4MIaDAm6eiENiCvs95lY9wzmU6UDlC\n3p3B5gAvA7XW2i3epq1AbZ6KNZz8APg/QNZ7XQXs8aavBX2vB8IkYAfwC6/74GfGmCL0fR5Q1tpN\nwP8DNuBCeS/wKvo+55UGhA1Dxphi4DfAl6y1+3pu8yaH0RD9I2CM+QCw3Vr7ar7LMsyFgBOBH1tr\n5wBtHNCEre/zkfP67C/D/RgaCxQBF+a1UJKXcM5lOlA5TMaYMC6Y77PWPuyt3maMGeNtHwNsz1f5\nhokzgUuNMetw3TLn4PpGy71mQdD3eiA0AU3W2pe91w/hwlrf54F1HrDWWrvDWpsCHsZ9x/V9zqN8\nhHMu04HKYfD6Pe8EVlpr/6PHpp7Tq14D/H6oyzacWGu/bq2tt9ZOxH1//2ytvQp4Gjd9Leg8HzFr\n7VZgozGmwVt1LrACfZ8H2gbgNGNMofd/SOd51vc5j/IyCYkx5mJcn13ndKD/MuSFGIaMMe8BngXe\noLsv9B9w/c4PAuOB9cBfW2t35aWQw4wxphH4qrX2A8aYybiadCXwGnC1tTaRz/Id7YwxJ+AG3UWA\nNcB1uEqFvs8DyBjzLeAK3BUfrwGfwfUx6/ucJ5ohTERExGc0IExERMRnFM4iIiI+o3AWERHxGYWz\niIiIzyicRUREfEbhLCIi4jMKZxEREZ9ROIuIiPjM/wcQXYRpZDb0IAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7LY8Sa9iX4",
        "colab_type": "code",
        "outputId": "6393b27c-f477-4b3e-9a7e-6c0af24f1f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.evaluate([x_test_scaled_wide, x_test_scaled_deep], y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 21us/sample - loss: 0.3740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37398104103960733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZAMB_v0kqDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}