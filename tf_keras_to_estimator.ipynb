{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_to_estimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_to_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIIGLXiwQZYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "fcd6d9d8-7a26-48bd-9ad5-21fa0210b2b0"
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.7.1)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.33.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
            "Collecting wrapt>=1.11.1 (from tensorflow==2.0.0-beta0)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.16.4)\n",
            "Collecting google-pasta>=0.1.6 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 20.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.8.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tb-nightly, wrapt, tf-estimator-nightly, google-pasta, tensorflow\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.7 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501 wrapt-1.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38e2hSJqQFMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5bb7eb70-d41d-4863-f938-fb387587ed04"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.4\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.2\n",
            "tensorflow 2.0.0-beta0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXDKINJkQ9tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPtSV1yyRPUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7454c6b6-1f76-4ae9-f9d2-84f0a80836ba"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1GiqsxRRAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2c01fa0b-55ad-4035-e98c-ed3dee6e671c"
      },
      "source": [
        "!wget -P /content/data https://storage.googleapis.com/tf-datasets/titanic/train.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-10 07:26:45--  https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30874 (30K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/train.csv’\n",
            "\n",
            "\rtrain.csv             0%[                    ]       0  --.-KB/s               \rtrain.csv           100%[===================>]  30.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-10 07:26:46 (85.7 MB/s) - ‘/content/data/train.csv’ saved [30874/30874]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22gDHDuUR7Xa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "f5dac666-76e7-48bb-e9fc-5b718356c938"
      },
      "source": [
        "!wget -P /content/data https://storage.googleapis.com/tf-datasets/titanic/eval.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-10 07:27:05--  https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13049 (13K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/eval.csv’\n",
            "\n",
            "\reval.csv              0%[                    ]       0  --.-KB/s               \reval.csv            100%[===================>]  12.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-10 07:27:05 (75.3 MB/s) - ‘/content/data/eval.csv’ saved [13049/13049]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fKkAqx8SC2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1f5faf56-5fc7-44ff-8d46-7bc69b19270c"
      },
      "source": [
        "train_file = \"./data/train.csv\"\n",
        "eval_file = \"./data/eval.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "eval_df = pd.read_csv(eval_file)\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  22.0  ...  unknown  Southampton      n\n",
            "1         1  female  38.0  ...        C    Cherbourg      n\n",
            "2         1  female  26.0  ...  unknown  Southampton      y\n",
            "3         1  female  35.0  ...        C  Southampton      n\n",
            "4         0    male  28.0  ...  unknown   Queenstown      y\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  35.0  ...  unknown  Southampton      y\n",
            "1         0    male  54.0  ...        E  Southampton      y\n",
            "2         1  female  58.0  ...        C  Southampton      y\n",
            "3         1  female  55.0  ...  unknown  Southampton      y\n",
            "4         1    male  34.0  ...        D  Southampton      y\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_g-XZWDSk0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "1ae54833-497e-410f-e3d8-331511f7eaca"
      },
      "source": [
        "y_train = train_df.pop('survived')\n",
        "y_eval = eval_df.pop('survived')\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())\n",
        "print(y_train.head())\n",
        "print(y_eval.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      sex   age  n_siblings_spouses  parch  ...  class     deck  embark_town alone\n",
            "0    male  22.0                   1      0  ...  Third  unknown  Southampton     n\n",
            "1  female  38.0                   1      0  ...  First        C    Cherbourg     n\n",
            "2  female  26.0                   0      0  ...  Third  unknown  Southampton     y\n",
            "3  female  35.0                   1      0  ...  First        C  Southampton     n\n",
            "4    male  28.0                   0      0  ...  Third  unknown   Queenstown     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "      sex   age  n_siblings_spouses  parch  ...   class     deck  embark_town alone\n",
            "0    male  35.0                   0      0  ...   Third  unknown  Southampton     y\n",
            "1    male  54.0                   0      0  ...   First        E  Southampton     y\n",
            "2  female  58.0                   0      0  ...   First        C  Southampton     y\n",
            "3  female  55.0                   0      0  ...  Second  unknown  Southampton     y\n",
            "4    male  34.0                   0      0  ...  Second        D  Southampton     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0UQL0B2S-r0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3be0eeef-4787-4f1b-db08-85c7ef8f9f1f"
      },
      "source": [
        "train_df.describe() # 计算统计量"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCfEaJfRTEph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26cae3d8-c960-4474-9c3d-ed8cb865bcef"
      },
      "source": [
        "print(train_df.shape, eval_df.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(627, 9) (264, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHkc1jefTPNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e58ec157-b50c-4260-ebcb-b253ac176dda"
      },
      "source": [
        "train_df.age.hist(bins = 20) # 直方图 20份 "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff14642a2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRS9JhbPoJalw/x8MqdwquVi2jAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wq8W3MbTZat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "84d1f15c-364f-41e9-963c-0313e59740a6"
      },
      "source": [
        "train_df.sex.value_counts().plot(kind = 'barh') # 横向barh 纵向barv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff143ac2780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntIQCgJZQANASCgBa/ws5zjf/WUrDRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MX3Fn-yTm7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "17bbdc7b-4cc3-4e7b-d744-3293a131bf46"
      },
      "source": [
        "train_df['class'].value_counts().plot(kind='barh')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff143a366a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gEq0LYLTxdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "922c8b32-9de0-48c4-ec46-0c02a6979a0e"
      },
      "source": [
        "# 男女获救比例\n",
        "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind='barh')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff143a07240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAD8CAYAAABKKbKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLf4Xk05X/eUioq0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl4BBtuEUDMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1a441039-b4b0-4ccc-b088-22b120d93ccb"
      },
      "source": [
        "# 离散特征\n",
        "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "# 连续特征\n",
        "numeric_columns = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique()\n",
        "    print(categorical_column, vocab)\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.indicator_column(\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "                categorical_column, vocab)))\n",
        "    \n",
        "for categorical_column in numeric_columns:\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.numeric_column(\n",
        "            categorical_column, dtype = tf.float32))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male' 'female']\n",
            "n_siblings_spouses [1 0 3 4 2 5 8]\n",
            "parch [0 1 2 5 3 4]\n",
            "class ['Third' 'First' 'Second']\n",
            "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
            "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
            "alone ['n' 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4eZ48whW2E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data_df, label_df, epochs=10, shuffle=True,\n",
        "                 batch_size=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-QWU3qgXI1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVFMctd0XKzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f58492d6-3780-4368-c85a-323f0faf89f4"
      },
      "source": [
        "for x, y in train_dataset.take(1):\n",
        "    print(x, y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sex': <tf.Tensor: id=597, shape=(5,), dtype=string, numpy=array([b'female', b'female', b'male', b'female', b'female'], dtype=object)>, 'age': <tf.Tensor: id=589, shape=(5,), dtype=float64, numpy=array([28., 63., 28., 30., 28.])>, 'n_siblings_spouses': <tf.Tensor: id=595, shape=(5,), dtype=int32, numpy=array([1, 0, 0, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: id=596, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0], dtype=int32)>, 'fare': <tf.Tensor: id=594, shape=(5,), dtype=float64, numpy=array([15.5   ,  9.5875,  7.8958, 56.9292,  7.7333])>, 'class': <tf.Tensor: id=591, shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'Third', b'First', b'Third'], dtype=object)>, 'deck': <tf.Tensor: id=592, shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'E', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: id=593, shape=(5,), dtype=string, numpy=\n",
            "array([b'Queenstown', b'Southampton', b'Southampton', b'Cherbourg',\n",
            "       b'Queenstown'], dtype=object)>, 'alone': <tf.Tensor: id=590, shape=(5,), dtype=string, numpy=array([b'n', b'y', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([1 1 0 1 1], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG-6OMqFXhoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8e6d733f-c69a-4a81-f166-6d3f81ac8c77"
      },
      "source": [
        "# keras.layers.DenseFeature\n",
        "for x, y in train_dataset.take(1):\n",
        "    age_column = feature_columns[7]\n",
        "    gender_column = feature_columns[0]\n",
        "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
        "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[28.]\n",
            " [63.]\n",
            " [28.]\n",
            " [30.]\n",
            " [28.]]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9TXkLkVX-a2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "17462a3d-89be-4282-e9a8-03ba2ba16284"
      },
      "source": [
        "for x, y in train_dataset.take(1):\n",
        "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[28.      1.      0.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
            "  15.5     1.      0.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      0.      1.    ]\n",
            " [63.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "   9.5875  0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      0.      1.    ]\n",
            " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
            "   7.8958  0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      1.      0.    ]\n",
            " [30.      0.      1.      0.      1.      0.      0.      0.      0.\n",
            "   0.      0.      0.      0.      1.      0.      1.      0.      0.\n",
            "  56.9292  0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      0.      1.    ]\n",
            " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
            "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
            "   7.7333  0.      1.      0.      0.      0.      0.      0.      1.\n",
            "   0.      0.      0.      0.      0.      0.      1.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hatYGmHjYG4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.DenseFeatures(feature_columns),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rru_VccmYk4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3420
        },
        "outputId": "2316b22f-2f1f-4464-c37b-95084bcac8a7"
      },
      "source": [
        "# 1. model.fit\n",
        "# 2. model -> estimator -> train\n",
        "\n",
        "train_dataset = make_dataset(train_df, y_train, epochs=100)\n",
        "eval_dataset = make_dataset(eval_df, y_eval, epochs=1, shuffle=False)\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data = eval_dataset,\n",
        "                    steps_per_epoch = 20,\n",
        "                    validation_steps = 8, \n",
        "                    epochs = 100)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 2s 88ms/step - loss: 1.7410 - accuracy: 0.5632 - val_loss: 0.6698 - val_accuracy: 0.6250\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.6251 - val_loss: 0.8322 - val_accuracy: 0.6016\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8207 - accuracy: 0.6895 - val_loss: 0.6088 - val_accuracy: 0.7109\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6871 - val_loss: 0.5928 - val_accuracy: 0.6914\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.6769 - val_loss: 0.5970 - val_accuracy: 0.6875\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.6679 - val_loss: 0.5932 - val_accuracy: 0.6992\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6785 - val_loss: 0.6538 - val_accuracy: 0.6719\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.6997 - val_loss: 0.5787 - val_accuracy: 0.6992\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6942 - val_loss: 0.5898 - val_accuracy: 0.6719\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.6982 - val_loss: 0.5757 - val_accuracy: 0.7031\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.6593 - val_loss: 0.5777 - val_accuracy: 0.6914\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.6924 - val_loss: 0.6003 - val_accuracy: 0.6602\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.7159 - val_loss: 0.5773 - val_accuracy: 0.6836\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.6754 - val_loss: 0.5680 - val_accuracy: 0.7188\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.6639 - val_loss: 0.5726 - val_accuracy: 0.7188\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.7288 - val_loss: 0.6188 - val_accuracy: 0.6836\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7118 - val_loss: 0.5654 - val_accuracy: 0.7148\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7209 - val_loss: 0.6011 - val_accuracy: 0.6797\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6961 - val_loss: 0.5612 - val_accuracy: 0.7070\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7281 - val_loss: 0.5637 - val_accuracy: 0.7070\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.6792 - val_loss: 0.5533 - val_accuracy: 0.7148\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.6841 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.7326 - val_loss: 0.5618 - val_accuracy: 0.6914\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7072 - val_loss: 0.5529 - val_accuracy: 0.6992\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.6949 - val_loss: 0.5558 - val_accuracy: 0.7148\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7211 - val_loss: 0.5639 - val_accuracy: 0.7148\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7360 - val_loss: 0.5492 - val_accuracy: 0.6953\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7507 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7172 - val_loss: 0.5656 - val_accuracy: 0.6758\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.7300 - val_loss: 0.5474 - val_accuracy: 0.7148\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7484 - val_loss: 0.6039 - val_accuracy: 0.6836\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7136 - val_loss: 0.5622 - val_accuracy: 0.6953\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7256 - val_loss: 0.5626 - val_accuracy: 0.7031\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7066 - val_loss: 0.6058 - val_accuracy: 0.7070\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7414 - val_loss: 0.5482 - val_accuracy: 0.6953\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7518 - val_loss: 0.5926 - val_accuracy: 0.6914\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7271 - val_loss: 0.5690 - val_accuracy: 0.7148\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5185 - accuracy: 0.6993 - val_loss: 0.5521 - val_accuracy: 0.7148\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7123 - val_loss: 0.5518 - val_accuracy: 0.7070\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7085 - val_loss: 0.5872 - val_accuracy: 0.7188\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7177 - val_loss: 0.5340 - val_accuracy: 0.7109\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7501 - val_loss: 0.6199 - val_accuracy: 0.7031\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7179 - val_loss: 0.5223 - val_accuracy: 0.7305\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7279 - val_loss: 0.5306 - val_accuracy: 0.7305\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.6983 - val_loss: 0.5351 - val_accuracy: 0.7227\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7410 - val_loss: 0.5253 - val_accuracy: 0.7227\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7250 - val_loss: 0.6258 - val_accuracy: 0.7109\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7475 - val_loss: 0.5129 - val_accuracy: 0.7539\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.7247 - val_loss: 0.5191 - val_accuracy: 0.7227\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.6971 - val_loss: 0.6443 - val_accuracy: 0.6719\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7283 - val_loss: 0.5566 - val_accuracy: 0.7109\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7444 - val_loss: 0.5150 - val_accuracy: 0.7305\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5835 - accuracy: 0.6680 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7436 - val_loss: 0.5687 - val_accuracy: 0.7109\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7394 - val_loss: 0.5487 - val_accuracy: 0.7305\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7621 - val_loss: 0.5473 - val_accuracy: 0.7148\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7467 - val_loss: 0.5120 - val_accuracy: 0.7305\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.7195 - val_loss: 0.6215 - val_accuracy: 0.7109\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.6932 - val_loss: 0.5530 - val_accuracy: 0.7148\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7459 - val_loss: 0.5516 - val_accuracy: 0.7148\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5674 - accuracy: 0.7403 - val_loss: 0.5104 - val_accuracy: 0.7578\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7575 - val_loss: 0.5027 - val_accuracy: 0.7422\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7741 - val_loss: 0.6571 - val_accuracy: 0.6602\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7112 - val_loss: 0.5532 - val_accuracy: 0.7539\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7823 - val_loss: 0.5425 - val_accuracy: 0.7109\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7491 - val_loss: 0.5453 - val_accuracy: 0.7070\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7000 - val_loss: 0.5156 - val_accuracy: 0.7461\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7471 - val_loss: 0.5940 - val_accuracy: 0.7148\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7492 - val_loss: 0.5045 - val_accuracy: 0.7344\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7323 - val_loss: 0.5517 - val_accuracy: 0.7148\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7610 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7620 - val_loss: 0.5215 - val_accuracy: 0.7305\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7646 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7772 - val_loss: 0.5276 - val_accuracy: 0.7344\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7707 - val_loss: 0.4991 - val_accuracy: 0.7812\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7703 - val_loss: 0.5808 - val_accuracy: 0.7305\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7346 - val_loss: 0.5083 - val_accuracy: 0.7539\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7835 - val_loss: 0.5048 - val_accuracy: 0.7305\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7548 - val_loss: 0.4979 - val_accuracy: 0.7539\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7203 - val_loss: 0.5140 - val_accuracy: 0.7461\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7432 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7462 - val_loss: 0.5330 - val_accuracy: 0.7305\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7447 - val_loss: 0.5049 - val_accuracy: 0.7383\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7635 - val_loss: 0.5019 - val_accuracy: 0.7461\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7432 - val_loss: 0.5393 - val_accuracy: 0.7305\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7525 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7352 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7235 - val_loss: 0.5132 - val_accuracy: 0.7461\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7551 - val_loss: 0.5238 - val_accuracy: 0.7266\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7902 - val_loss: 0.4920 - val_accuracy: 0.7812\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7878 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7201 - val_loss: 0.5429 - val_accuracy: 0.7305\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7465 - val_loss: 0.6413 - val_accuracy: 0.7070\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7510 - val_loss: 0.6561 - val_accuracy: 0.6836\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7739 - val_loss: 0.5014 - val_accuracy: 0.7461\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7329 - val_loss: 0.5059 - val_accuracy: 0.7461\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.8008 - val_loss: 0.5261 - val_accuracy: 0.7305\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.7824 - val_loss: 0.5776 - val_accuracy: 0.7305\n",
            "Epoch 99/100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0610 08:00:55.479759 140675161786240 training_generator.py:235] Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0/20 [..............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK1D1bLzY_SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "569cb105-2164-4c77-9496-e2f7b61964be"
      },
      "source": [
        "estimator = keras.estimator.model_to_estimator(model)\n",
        "\n",
        "# 1. function\n",
        "# 2. return a. (features, labels) b. dataset -> (feature, label)\n",
        "estimator.train(input_fn = lambda: make_dataset(train_df, y_train, epochs=100))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0610 08:04:12.682246 140675161786240 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpt2rwejgb\n",
            "W0610 08:04:12.694273 140675161786240 keras.py:564] You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
            "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
            "W0610 08:04:12.705795 140675161786240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-5bdc1a1a69c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2. return a. (features, labels) b. dataset -> (feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1186\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1188\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1189\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m   input_tensors, target_tensors, sample_weight_tensors = (\n\u001b[0;32m--> 207\u001b[0;31m       _convert_estimator_io_to_keras(keras_model, features, labels))\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0mcompile_clone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_convert_estimator_io_to_keras\u001b[0;34m(keras_model, features, labels)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   input_tensors = _to_ordered_tensor_list(\n\u001b[0;32m--> 163\u001b[0;31m       features, input_names, 'features', 'inputs')\n\u001b[0m\u001b[1;32m    164\u001b[0m   target_tensors = _to_ordered_tensor_list(\n\u001b[1;32m    165\u001b[0m       labels, output_names, 'labels', 'outputs')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_to_ordered_tensor_list\u001b[0;34m(obj, key_order, obj_name, order_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0morder_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mobj_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 different_keys=different_keys))\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"The dictionary passed into features does not have the expected inputs keys defined in the keras model.\\n\\tExpected keys: {'input_6', 'input_9', 'input_4', 'input_1', 'input_7', 'input_8', 'input_3', 'input_5', 'input_2'}\\n\\tfeatures keys: {'class', 'parch', 'deck', 'embark_town', 'sex', 'n_siblings_spouses', 'alone', 'fare', 'age'}\\n\\tDifference: {'input_6', 'class', 'parch', 'deck', 'embark_town', 'input_9', 'input_4', 'input_1', 'input_7', 'input_8', 'sex', 'input_3', 'n_siblings_spouses', 'alone', 'input_5', 'input_2', 'fare', 'age'}\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvT_r-dVajRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow框架bug 待修复"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}