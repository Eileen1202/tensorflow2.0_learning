{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/seq2seq_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQbsJ94qaww5",
        "colab_type": "code",
        "outputId": "67f27457-1832-4adc-c461-8809996cd6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 58kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQgOAiCseWJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "224dc9dd-bea1-4068-b8b9-24087adb0393"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n",
            "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.4\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.3\n",
            "tensorflow 2.0.0-beta1\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM_lulOEo6hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. preprocessing data\n",
        "# 2. build model\n",
        "#   2.1 encoder\n",
        "#   2.2 attention\n",
        "#   2.3 decoder\n",
        "# 3. evaluation\n",
        "#   3.1 given sentence, return translated results\n",
        "#   3.2 visualize results (attention)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doq5CTNaau6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCa0tj9Dez1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \n",
        "                   if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfnZMIySgiOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re ## 正则表达式\n",
        "def preprocess_sentence(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    \n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s) # 标点符号前后加空格\n",
        "    s = re.sub(r'[\" \"]+', \" \", s) # 空格去重\n",
        "    \n",
        "    s = re.sub(r'[^a-zA-Z?.!,¿]', \" \", s) # 除了标点符号和字母外都是空格\n",
        "    s = s.rstrip().strip() # 去掉前后空格\n",
        "    \n",
        "    s = '<start> ' + s + ' <end>'\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-Oflzlhq5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "59a5a267-253f-42e5-c9c9-4aa1918ae8cf"
      },
      "source": [
        "def parse_data(filename):\n",
        "    lines = open(filename, encoding='UTF-8').read().strip().split('\\n')\n",
        "    sentence_pairs = [line.split('\\t') for line in lines]\n",
        "    preprocessed_sentence_pairs = [\n",
        "        (preprocess_sentence(en), preprocess_sentence(sp)) for en, sp in sentence_pairs\n",
        "    ]\n",
        "    return zip(*preprocessed_sentence_pairs)\n",
        "\n",
        "en_dataset, sp_dataset = parse_data(path_to_file)\n",
        "print(en_dataset[-1])\n",
        "print(sp_dataset[-1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXFrAVQMjuss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "045cc416-b915-43fe-9290-c5cd8c7b10ab"
      },
      "source": [
        "## zip + 解包操作，先把每个元素解开，再zip\n",
        "a = [(1, 2), (3, 4), (5, 6)]\n",
        "c, d = zip(*a)\n",
        "print(c, d)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 5) (2, 4, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_92TvnSkY5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c98a6eeb-bd80-4be4-b766-15fc98d5fcec"
      },
      "source": [
        "# 文本式数据转成id式\n",
        "def tokenizer(lang):\n",
        "    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "        num_words=None, filters='', split=' ')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "input_tensor, input_tokenizer = tokenizer(sp_dataset[0:30000])\n",
        "output_tensor, output_tokenizer = tokenizer(en_dataset[0:30000])\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "max_length_input = max_length(input_tensor)\n",
        "max_length_output = max_length(output_tensor)\n",
        "print(max_length_input, max_length_output)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_hU9vIJm3GP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97d5974f-da79-48df-e1a4-6ddca64ca928"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_train, input_eval, output_train, output_eval = train_test_split(\n",
        "    input_tensor, output_tensor, test_size=0.2)\n",
        "\n",
        "len(input_train), len(input_eval), len(output_train), len(output_eval)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 6000, 24000, 6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebMcN-Aonwi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0f64855c-98f9-499b-f71d-fb22b0ef2006"
      },
      "source": [
        "def convert(example, tokenizer):\n",
        "    for t in example:\n",
        "        if t != 0:\n",
        "            print('%d --> %s' % (t, tokenizer.index_word[t]))\n",
        "            \n",
        "convert(input_train[0], input_tokenizer)\n",
        "print()\n",
        "convert(output_train[0], output_tokenizer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 --> <start>\n",
            "85 --> ese\n",
            "95 --> libro\n",
            "7 --> es\n",
            "14 --> de\n",
            "54 --> ellos\n",
            "3 --> .\n",
            "2 --> <end>\n",
            "\n",
            "1 --> <start>\n",
            "20 --> that\n",
            "113 --> book\n",
            "8 --> is\n",
            "979 --> theirs\n",
            "3 --> .\n",
            "2 --> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYImCB2toAtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(input_tensor, output_tensor, batch_size, epochs, shuffle):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (input_tensor, output_tensor))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(30000)\n",
        "    dataset = dataset.repeat(epochs).batch(\n",
        "        batch_size, drop_remainder = True)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "train_dataset = make_dataset(input_train, output_train, batch_size, epochs, True)\n",
        "eval_dataset = make_dataset(input_eval, output_eval, batch_size, 1, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6dVPJHonFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa2b85a8-2a99-43c7-dc2c-5213760b7cb8"
      },
      "source": [
        "for x,y in train_dataset.take(1):\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    print(x)\n",
        "    print(y)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 16)\n",
            "(64, 11)\n",
            "tf.Tensor(\n",
            "[[   1 1733   13 ...    0    0    0]\n",
            " [   1 1684   44 ...    0    0    0]\n",
            " [   1  293   10 ...    0    0    0]\n",
            " ...\n",
            " [   1    9   16 ...    0    0    0]\n",
            " [   1   13  327 ...    0    0    0]\n",
            " [   1  407  349 ...    0    0    0]], shape=(64, 16), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[   1    4  769 2255    3    2    0    0    0    0    0]\n",
            " [   1  317   33 1353    3    2    0    0    0    0    0]\n",
            " [   1   36   15   31  165   37    2    0    0    0    0]\n",
            " [   1   19    8   13  278 1353    3    2    0    0    0]\n",
            " [   1    5    8    9 1717    3    2    0    0    0    0]\n",
            " [   1   27 1278  204    3    2    0    0    0    0    0]\n",
            " [   1   16   23 1698    3    2    0    0    0    0    0]\n",
            " [   1   14  145   39  131    3    2    0    0    0    0]\n",
            " [   1    6  108   73   68    3    2    0    0    0    0]\n",
            " [   1   16   67   29 1479    3    2    0    0    0    0]\n",
            " [   1    4   43   68    3    2    0    0    0    0    0]\n",
            " [   1   28  331   10    3    2    0    0    0    0    0]\n",
            " [   1   25    6   36   80   81    7    2    0    0    0]\n",
            " [   1   14   26  152   57    3    2    0    0    0    0]\n",
            " [   1    4   30   12   35  705    3    2    0    0    0]\n",
            " [   1    4   26   70  341    3    2    0    0    0    0]\n",
            " [   1   22    6   29  365  610    7    2    0    0    0]\n",
            " [   1    4  108   64   10 1002    3    2    0    0    0]\n",
            " [   1    5 1678   17   15   53    3    2    0    0    0]\n",
            " [   1   14  180   13  115    3    2    0    0    0    0]\n",
            " [   1    6   23    9  757  974    3    2    0    0    0]\n",
            " [   1  102  685    3    2    0    0    0    0    0    0]\n",
            " [   1   27 1234   61  449    3    2    0    0    0    0]\n",
            " [   1    4   47  504  833    3    2    0    0    0    0]\n",
            " [   1    4   62   34   33    9  281    3    2    0    0]\n",
            " [   1    4  161 3299    3    2    0    0    0    0    0]\n",
            " [   1    5   26   33    9  539    3    2    0    0    0]\n",
            " [   1   16  100   13 1853    3    2    0    0    0    0]\n",
            " [   1   24    6  252    7    2    0    0    0    0    0]\n",
            " [   1  188  276    3    2    0    0    0    0    0    0]\n",
            " [   1   27  896   44   68  565    3    2    0    0    0]\n",
            " [   1    4   95   84    3    2    0    0    0    0    0]\n",
            " [   1   14 2367   61  774    3    2    0    0    0    0]\n",
            " [   1    4   65   76  985    3    2    0    0    0    0]\n",
            " [   1    4  256    6    3    2    0    0    0    0    0]\n",
            " [   1  120   39   80   81    3    2    0    0    0    0]\n",
            " [   1   21  418   76 1209    3    2    0    0    0    0]\n",
            " [   1   14    8  617 4073    3    2    0    0    0    0]\n",
            " [   1    6   63  115    3    2    0    0    0    0    0]\n",
            " [   1   10  164   12 4754    3    2    0    0    0    0]\n",
            " [   1    4  106   76  503    3    2    0    0    0    0]\n",
            " [   1   21  768    8  193    3    2    0    0    0    0]\n",
            " [   1   31  226    8  340    3    2    0    0    0    0]\n",
            " [   1   14  145   91  284    3    2    0    0    0    0]\n",
            " [   1   66   84   75   40  502    3    2    0    0    0]\n",
            " [   1    4  455    6    3    2    0    0    0    0    0]\n",
            " [   1    6   23  955    3    2    0    0    0    0    0]\n",
            " [   1   28   23   91    3    2    0    0    0    0    0]\n",
            " [   1  379  307   54    6    3    2    0    0    0    0]\n",
            " [   1 2135   31 1614    3    2    0    0    0    0    0]\n",
            " [   1   10   38  106  406    3    2    0    0    0    0]\n",
            " [   1   27    8  453    3    2    0    0    0    0    0]\n",
            " [   1   30   12   46   13  229   74    3    2    0    0]\n",
            " [   1    4   25   12 1043   20    3    2    0    0    0]\n",
            " [   1   13  165    8  220    3    2    0    0    0    0]\n",
            " [   1    5  764  777    3    2    0    0    0    0    0]\n",
            " [   1    4   43    5    8  192    3    2    0    0    0]\n",
            " [   1   13 4826   26 4827    3    2    0    0    0    0]\n",
            " [   1   27  274  721    3    2    0    0    0    0    0]\n",
            " [   1    4   18  404  260    3    2    0    0    0    0]\n",
            " [   1   16   23 2125    3    2    0    0    0    0    0]\n",
            " [   1   14   11 2916   21  418    3    2    0    0    0]\n",
            " [   1  329   24   85  273    3    2    0    0    0    0]\n",
            " [   1    6   36  285    3    2    0    0    0    0    0]], shape=(64, 11), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmStZyrgoziE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}