{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/seq2seq_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQbsJ94qaww5",
        "colab_type": "code",
        "outputId": "67f27457-1832-4adc-c461-8809996cd6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 58kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQgOAiCseWJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "224dc9dd-bea1-4068-b8b9-24087adb0393"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n",
            "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.4\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.3\n",
            "tensorflow 2.0.0-beta1\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM_lulOEo6hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. preprocessing data\n",
        "# 2. build model\n",
        "#   2.1 encoder\n",
        "#   2.2 attention\n",
        "#   2.3 decoder\n",
        "#   2.4 loss & optimizer\n",
        "#   2.5 train\n",
        "# 3. evaluation\n",
        "#   3.1 given sentence, return translated results\n",
        "#   3.2 visualize results (attention)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doq5CTNaau6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCa0tj9Dez1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \n",
        "                   if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfnZMIySgiOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re ## 正则表达式\n",
        "def preprocess_sentence(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    \n",
        "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s) # 标点符号前后加空格\n",
        "    s = re.sub(r'[\" \"]+', \" \", s) # 空格去重\n",
        "    \n",
        "    s = re.sub(r'[^a-zA-Z?.!,¿]', \" \", s) # 除了标点符号和字母外都是空格\n",
        "    s = s.rstrip().strip() # 去掉前后空格\n",
        "    \n",
        "    s = '<start> ' + s + ' <end>'\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-Oflzlhq5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "59a5a267-253f-42e5-c9c9-4aa1918ae8cf"
      },
      "source": [
        "def parse_data(filename):\n",
        "    lines = open(filename, encoding='UTF-8').read().strip().split('\\n')\n",
        "    sentence_pairs = [line.split('\\t') for line in lines]\n",
        "    preprocessed_sentence_pairs = [\n",
        "        (preprocess_sentence(en), preprocess_sentence(sp)) for en, sp in sentence_pairs\n",
        "    ]\n",
        "    return zip(*preprocessed_sentence_pairs)\n",
        "\n",
        "en_dataset, sp_dataset = parse_data(path_to_file)\n",
        "print(en_dataset[-1])\n",
        "print(sp_dataset[-1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXFrAVQMjuss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "045cc416-b915-43fe-9290-c5cd8c7b10ab"
      },
      "source": [
        "## zip + 解包操作，先把每个元素解开，再zip\n",
        "a = [(1, 2), (3, 4), (5, 6)]\n",
        "c, d = zip(*a)\n",
        "print(c, d)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 5) (2, 4, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_92TvnSkY5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c98a6eeb-bd80-4be4-b766-15fc98d5fcec"
      },
      "source": [
        "# 文本式数据转成id式\n",
        "def tokenizer(lang):\n",
        "    lang_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "        num_words=None, filters='', split=' ')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "input_tensor, input_tokenizer = tokenizer(sp_dataset[0:30000])\n",
        "output_tensor, output_tokenizer = tokenizer(en_dataset[0:30000])\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "max_length_input = max_length(input_tensor)\n",
        "max_length_output = max_length(output_tensor)\n",
        "print(max_length_input, max_length_output)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_hU9vIJm3GP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97d5974f-da79-48df-e1a4-6ddca64ca928"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_train, input_eval, output_train, output_eval = train_test_split(\n",
        "    input_tensor, output_tensor, test_size=0.2)\n",
        "\n",
        "len(input_train), len(input_eval), len(output_train), len(output_eval)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 6000, 24000, 6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebMcN-Aonwi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0f64855c-98f9-499b-f71d-fb22b0ef2006"
      },
      "source": [
        "def convert(example, tokenizer):\n",
        "    for t in example:\n",
        "        if t != 0:\n",
        "            print('%d --> %s' % (t, tokenizer.index_word[t]))\n",
        "            \n",
        "convert(input_train[0], input_tokenizer)\n",
        "print()\n",
        "convert(output_train[0], output_tokenizer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 --> <start>\n",
            "85 --> ese\n",
            "95 --> libro\n",
            "7 --> es\n",
            "14 --> de\n",
            "54 --> ellos\n",
            "3 --> .\n",
            "2 --> <end>\n",
            "\n",
            "1 --> <start>\n",
            "20 --> that\n",
            "113 --> book\n",
            "8 --> is\n",
            "979 --> theirs\n",
            "3 --> .\n",
            "2 --> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYImCB2toAtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(input_tensor, output_tensor, batch_size, epochs, shuffle):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (input_tensor, output_tensor))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(30000)\n",
        "    dataset = dataset.repeat(epochs).batch(\n",
        "        batch_size, drop_remainder = True)\n",
        "    return dataset\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "train_dataset = make_dataset(input_train, output_train, batch_size, epochs, True)\n",
        "eval_dataset = make_dataset(input_eval, output_eval, batch_size, 1, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6dVPJHonFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa2b85a8-2a99-43c7-dc2c-5213760b7cb8"
      },
      "source": [
        "for x,y in train_dataset.take(1):\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    print(x)\n",
        "    print(y)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 16)\n",
            "(64, 11)\n",
            "tf.Tensor(\n",
            "[[   1 1733   13 ...    0    0    0]\n",
            " [   1 1684   44 ...    0    0    0]\n",
            " [   1  293   10 ...    0    0    0]\n",
            " ...\n",
            " [   1    9   16 ...    0    0    0]\n",
            " [   1   13  327 ...    0    0    0]\n",
            " [   1  407  349 ...    0    0    0]], shape=(64, 16), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[   1    4  769 2255    3    2    0    0    0    0    0]\n",
            " [   1  317   33 1353    3    2    0    0    0    0    0]\n",
            " [   1   36   15   31  165   37    2    0    0    0    0]\n",
            " [   1   19    8   13  278 1353    3    2    0    0    0]\n",
            " [   1    5    8    9 1717    3    2    0    0    0    0]\n",
            " [   1   27 1278  204    3    2    0    0    0    0    0]\n",
            " [   1   16   23 1698    3    2    0    0    0    0    0]\n",
            " [   1   14  145   39  131    3    2    0    0    0    0]\n",
            " [   1    6  108   73   68    3    2    0    0    0    0]\n",
            " [   1   16   67   29 1479    3    2    0    0    0    0]\n",
            " [   1    4   43   68    3    2    0    0    0    0    0]\n",
            " [   1   28  331   10    3    2    0    0    0    0    0]\n",
            " [   1   25    6   36   80   81    7    2    0    0    0]\n",
            " [   1   14   26  152   57    3    2    0    0    0    0]\n",
            " [   1    4   30   12   35  705    3    2    0    0    0]\n",
            " [   1    4   26   70  341    3    2    0    0    0    0]\n",
            " [   1   22    6   29  365  610    7    2    0    0    0]\n",
            " [   1    4  108   64   10 1002    3    2    0    0    0]\n",
            " [   1    5 1678   17   15   53    3    2    0    0    0]\n",
            " [   1   14  180   13  115    3    2    0    0    0    0]\n",
            " [   1    6   23    9  757  974    3    2    0    0    0]\n",
            " [   1  102  685    3    2    0    0    0    0    0    0]\n",
            " [   1   27 1234   61  449    3    2    0    0    0    0]\n",
            " [   1    4   47  504  833    3    2    0    0    0    0]\n",
            " [   1    4   62   34   33    9  281    3    2    0    0]\n",
            " [   1    4  161 3299    3    2    0    0    0    0    0]\n",
            " [   1    5   26   33    9  539    3    2    0    0    0]\n",
            " [   1   16  100   13 1853    3    2    0    0    0    0]\n",
            " [   1   24    6  252    7    2    0    0    0    0    0]\n",
            " [   1  188  276    3    2    0    0    0    0    0    0]\n",
            " [   1   27  896   44   68  565    3    2    0    0    0]\n",
            " [   1    4   95   84    3    2    0    0    0    0    0]\n",
            " [   1   14 2367   61  774    3    2    0    0    0    0]\n",
            " [   1    4   65   76  985    3    2    0    0    0    0]\n",
            " [   1    4  256    6    3    2    0    0    0    0    0]\n",
            " [   1  120   39   80   81    3    2    0    0    0    0]\n",
            " [   1   21  418   76 1209    3    2    0    0    0    0]\n",
            " [   1   14    8  617 4073    3    2    0    0    0    0]\n",
            " [   1    6   63  115    3    2    0    0    0    0    0]\n",
            " [   1   10  164   12 4754    3    2    0    0    0    0]\n",
            " [   1    4  106   76  503    3    2    0    0    0    0]\n",
            " [   1   21  768    8  193    3    2    0    0    0    0]\n",
            " [   1   31  226    8  340    3    2    0    0    0    0]\n",
            " [   1   14  145   91  284    3    2    0    0    0    0]\n",
            " [   1   66   84   75   40  502    3    2    0    0    0]\n",
            " [   1    4  455    6    3    2    0    0    0    0    0]\n",
            " [   1    6   23  955    3    2    0    0    0    0    0]\n",
            " [   1   28   23   91    3    2    0    0    0    0    0]\n",
            " [   1  379  307   54    6    3    2    0    0    0    0]\n",
            " [   1 2135   31 1614    3    2    0    0    0    0    0]\n",
            " [   1   10   38  106  406    3    2    0    0    0    0]\n",
            " [   1   27    8  453    3    2    0    0    0    0    0]\n",
            " [   1   30   12   46   13  229   74    3    2    0    0]\n",
            " [   1    4   25   12 1043   20    3    2    0    0    0]\n",
            " [   1   13  165    8  220    3    2    0    0    0    0]\n",
            " [   1    5  764  777    3    2    0    0    0    0    0]\n",
            " [   1    4   43    5    8  192    3    2    0    0    0]\n",
            " [   1   13 4826   26 4827    3    2    0    0    0    0]\n",
            " [   1   27  274  721    3    2    0    0    0    0    0]\n",
            " [   1    4   18  404  260    3    2    0    0    0    0]\n",
            " [   1   16   23 2125    3    2    0    0    0    0    0]\n",
            " [   1   14   11 2916   21  418    3    2    0    0    0]\n",
            " [   1  329   24   85  273    3    2    0    0    0    0]\n",
            " [   1    6   36  285    3    2    0    0    0    0    0]], shape=(64, 11), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmStZyrgoziE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_units = 256\n",
        "units = 1024\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "output_vocab_size = len(output_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCz9Fn0pkbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "738b2e03-feaa-4734-a7cb-87eda54fe670"
      },
      "source": [
        "class Encoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.encoding_units = encoding_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
        "        self.gru = keras.layers.GRU(self.encoding_units,\n",
        "                                    return_sequences = True,\n",
        "                                    return_state = True,\n",
        "                                    recurrent_initializer = 'glorot_uniform')\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.encoding_units))\n",
        "    \n",
        "encoder = Encoder(input_vocab_size, embedding_units, units, batch_size)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
        "\n",
        "print(\"sample_output.shape: \", sample_output.shape)\n",
        "print(\"sample_hidden.shape: \", sample_hidden.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_output.shape:  (64, 16, 1024)\n",
            "sample_hidden.shape:  (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SPS9807q4ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9720393-9abb-487e-8f13-2f4b0deea4cb"
      },
      "source": [
        "# 实现attention机制\n",
        "class BahdanauAttention(keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, decoder_hidden, encoder_outputs):\n",
        "        # decoder_hidden.shape: (batch_size, units)\n",
        "        # encoder_outputs.shape: (batch_size, length, units)\n",
        "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
        "        \n",
        "        # before:V (batch_size, length, units)\n",
        "        # after: V (batch_size, length, 1)\n",
        "        score = self.V(\n",
        "            tf.nn.tanh(\n",
        "                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
        "        \n",
        "        # shape: (batch_size, length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector.shape: (batch_size, length, units)\n",
        "        context_vector = attention_weights * encoder_outputs\n",
        "        \n",
        "        # context_vector.shape: (batch_size, units)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "attention_model = BahdanauAttention(units = 10)\n",
        "attention_results, attention_weights = attention_model(\n",
        "    sample_hidden, sample_output)\n",
        "\n",
        "print(\"attention_results.shape: \", attention_results.shape)\n",
        "print(\"attention_weights.shape: \", attention_weights.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_results.shape:  (64, 1024)\n",
            "attention_weights.shape:  (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h42JTyLtMXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "988af2dd-5b1c-4402-e977-ece1608f33a4"
      },
      "source": [
        "# Decoder的实现\n",
        "class Decoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.decoding_units = decoding_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
        "        self.gru = keras.layers.GRU(self.decoding_units,\n",
        "                                    return_sequences = True,\n",
        "                                    return_state = True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        self.attention = BahdanauAttention(self.decoding_units)\n",
        "    \n",
        "    def call(self, x, hidden, encoding_outputs):\n",
        "        # context_vector.shape: (batch_size, units)\n",
        "        context_vector, attention_weights = self.attention(hidden, encoding_outputs)\n",
        "    \n",
        "        # before embedding: x.shape: (batch_size, 1)\n",
        "        # after embedding : x.shape: (batch_size, 1 ,embedding_units)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        combined_x = tf.concat([tf.expand_dims(context_vector, 1)], axis=-1)\n",
        "        \n",
        "        # output.shape: [batch_size, 1, decoding_units]\n",
        "        # state.shape : [batch_size, decoding_units]\n",
        "        output, state = self.gru(combined_x)\n",
        "        \n",
        "        # output.shape: [batch_size, decoding_units]\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output.shape: [batch_size, vocab_size]\n",
        "        output = self.fc(output)\n",
        "        \n",
        "        return output, state, attention_weights\n",
        "    \n",
        "decoder = Decoder(output_vocab_size, embedding_units, units, batch_size)\n",
        "\n",
        "outputs = decoder(tf.random.uniform((batch_size, 1)),\n",
        "                  sample_hidden,\n",
        "                  sample_output)\n",
        "\n",
        "decoder_output, decoder_hidden, decoder_aw = outputs\n",
        "\n",
        "print(\"decoder_output.shape: \", decoder_output.shape)\n",
        "print(\"decoder_hidden.shape: \", decoder_hidden.shape)\n",
        "print(\"decoder_attention_weights.shape: \",decoder_aw.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decoder_output.shape:  (64, 4935)\n",
            "decoder_hidden.shape:  (64, 1024)\n",
            "decoder_attention_weights.shape:  (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRC8pkEL1doI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss func\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction = 'none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcIqO7FY2ndc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, encoding_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n",
        "        \n",
        "        decoding_hidden = encoding_hidden\n",
        "        \n",
        "        # eg: <start> I am here <end>\n",
        "        # 1. <start> -> I\n",
        "        # 2. I -> am\n",
        "        # 3. am -> here\n",
        "        # 4. here -> <end>\n",
        "        for t in range(0, targ.shape[1] - 1):\n",
        "            decoding_input = tf.expand_dims(targ[:, t], 1)\n",
        "            \n",
        "            predictions, decoding_hidden, _ = decoder(\n",
        "                decoding_input, decoding_hidden, encoding_outputs)\n",
        "            \n",
        "            loss += loss_function(targ[:, t+1], predictions)\n",
        "            \n",
        "    batch_loss = loss / int(targ.shape[0])\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvMAUhHy33FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = len(input_tensor) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoding_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "                epoch+1, batch, batch_loss.numpy()))\n",
        "            \n",
        "    print(\"Epoch {} Loss {:.4f}\".format(epoch+1, total_loss / steps_per_epoch))\n",
        "    print(\"Time take for 1 epoch {} sec\\n\".format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdVftS2e7ODV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(input_sentence):\n",
        "    attention_matrix = np.zeros((max_length_output, max_length_input))\n",
        "    input_sentence = preprocess_sentence(input_sentence)\n",
        "    \n",
        "    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n",
        "    inputs = keras.preprocessing.sequence.pad_sequences(\n",
        "        [inputs], maxlen=max_length_input, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    results = ''\n",
        "    encoding_hidden = tf.zeros((1, units))\n",
        "    \n",
        "    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden)\n",
        "    decoding_hidden = encoding_hidden\n",
        "    \n",
        "    # eg: <start> -> A\n",
        "    # A -> B -> C -> D\n",
        "    decoding_input = tf.expand_dims(output_tokenizer.word_index['<start>'], 0)\n",
        "    \n",
        "    for t in range(max_length_output):\n",
        "        predictions, decoding_hidden, attention_weights = decoder(\n",
        "            decoding_input, decoding_hidden, encoding_outputs)\n",
        "        \n",
        "        # attention_weights.shape: (batch_size, input_length, 1) (1, 16, 1)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_matrix[t] = attention_weights.numpy()\n",
        "        \n",
        "        # predictions.shape: (batch_size, vocab_size) (1, 4935)\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        \n",
        "        results += output_tokenizer.index_word[predicted_id] + ' '\n",
        "        \n",
        "        if output_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return results, input_sentence, attention_matrix\n",
        "        \n",
        "        decoding_input = tf.expand_dims([predicted_id], 0)\n",
        "    \n",
        "    return results, input_setence, attention_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxAQBpd9Ju2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention_matrix, input_sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention_matrix, cmap='viridis')\n",
        "    \n",
        "    font_dict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + input_sentence, fontdict = font_dict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=font_dict, )\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "def translate(input_sentence):\n",
        "    results, input_sentence, attention_matrix = evaluate(input_sentence)\n",
        "    \n",
        "    print(\"Input: %s\" % (input_sentence))\n",
        "    print(\"Predicted translation: %s\" % (results))\n",
        "    \n",
        "    attention_matrix = attention_matrix[:len(results.split(' ')),\n",
        "                                        :len(input_sentence.split(' '))]\n",
        "    \n",
        "    plot_attention(attention_matrix, input_sentence.split(' '),\n",
        "                   results.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u1ByCjG-bTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "dc0f245a-68f2-4f4a-9f20-ac6c31d64d45"
      },
      "source": [
        "translate(u'Hace frio aqui.')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace frio aqui . <end>\n",
            "Predicted translation: it s cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAJwCAYAAADCyLhdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncP8fer9xaqT/GLAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}