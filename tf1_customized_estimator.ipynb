{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf1_customized_estimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf1_customized_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIIGLXiwQZYK",
        "colab_type": "code",
        "outputId": "42b217dc-7799-423a-c4ed-93c662743cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (3.0.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.15.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38e2hSJqQFMA",
        "colab_type": "code",
        "outputId": "f1fa6894-8b4e-4198-c8c3-caadf84a95b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.4\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.2\n",
            "tensorflow 1.13.1\n",
            "tensorflow._api.v1.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXDKINJkQ9tL",
        "colab_type": "code",
        "outputId": "6f781c0b-1e53-420c-c563-294b5b8c0e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPtSV1yyRPUQ",
        "colab_type": "code",
        "outputId": "f17496fa-2345-4448-d469-c2f7b1ac5d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1GiqsxRRAV",
        "colab_type": "code",
        "outputId": "1abe039b-8a17-43ef-b2c9-ca06e2d9a079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -P /content/data https://storage.googleapis.com/tf-datasets/titanic/train.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-16 07:56:23--  https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 2607:f8b0:4001:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30874 (30K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/train.csv’\n",
            "\n",
            "\rtrain.csv             0%[                    ]       0  --.-KB/s               \rtrain.csv           100%[===================>]  30.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-16 07:56:23 (90.9 MB/s) - ‘/content/data/train.csv’ saved [30874/30874]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22gDHDuUR7Xa",
        "colab_type": "code",
        "outputId": "e67b1ce8-26b9-408c-e6ed-03c1d470ca52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -P /content/data https://storage.googleapis.com/tf-datasets/titanic/eval.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-16 07:56:25--  https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13049 (13K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/eval.csv’\n",
            "\n",
            "\reval.csv              0%[                    ]       0  --.-KB/s               \reval.csv            100%[===================>]  12.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-16 07:56:25 (58.4 MB/s) - ‘/content/data/eval.csv’ saved [13049/13049]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fKkAqx8SC2f",
        "colab_type": "code",
        "outputId": "fccecde0-1e19-48aa-d3f9-152c917acf6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train_file = \"./data/train.csv\"\n",
        "eval_file = \"./data/eval.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "eval_df = pd.read_csv(eval_file)\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  22.0  ...  unknown  Southampton      n\n",
            "1         1  female  38.0  ...        C    Cherbourg      n\n",
            "2         1  female  26.0  ...  unknown  Southampton      y\n",
            "3         1  female  35.0  ...        C  Southampton      n\n",
            "4         0    male  28.0  ...  unknown   Queenstown      y\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "   survived     sex   age  ...     deck  embark_town  alone\n",
            "0         0    male  35.0  ...  unknown  Southampton      y\n",
            "1         0    male  54.0  ...        E  Southampton      y\n",
            "2         1  female  58.0  ...        C  Southampton      y\n",
            "3         1  female  55.0  ...  unknown  Southampton      y\n",
            "4         1    male  34.0  ...        D  Southampton      y\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_g-XZWDSk0s",
        "colab_type": "code",
        "outputId": "e153107e-1dc9-48b4-d2c4-d2a9c7447e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "y_train = train_df.pop('survived')\n",
        "y_eval = eval_df.pop('survived')\n",
        "\n",
        "print(train_df.head())\n",
        "print(eval_df.head())\n",
        "print(y_train.head())\n",
        "print(y_eval.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      sex   age  n_siblings_spouses  parch  ...  class     deck  embark_town alone\n",
            "0    male  22.0                   1      0  ...  Third  unknown  Southampton     n\n",
            "1  female  38.0                   1      0  ...  First        C    Cherbourg     n\n",
            "2  female  26.0                   0      0  ...  Third  unknown  Southampton     y\n",
            "3  female  35.0                   1      0  ...  First        C  Southampton     n\n",
            "4    male  28.0                   0      0  ...  Third  unknown   Queenstown     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "      sex   age  n_siblings_spouses  parch  ...   class     deck  embark_town alone\n",
            "0    male  35.0                   0      0  ...   Third  unknown  Southampton     y\n",
            "1    male  54.0                   0      0  ...   First        E  Southampton     y\n",
            "2  female  58.0                   0      0  ...   First        C  Southampton     y\n",
            "3  female  55.0                   0      0  ...  Second  unknown  Southampton     y\n",
            "4    male  34.0                   0      0  ...  Second        D  Southampton     y\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: survived, dtype: int64\n",
            "0    0\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: survived, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1g_MJyMcBMs",
        "colab_type": "code",
        "outputId": "41ce769e-ef48-4cec-b1b6-1b35e8a325db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl4BBtuEUDMl",
        "colab_type": "code",
        "outputId": "7cfc8b95-298d-4d1c-e511-8ba5249c18ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 离散特征\n",
        "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "# 连续特征\n",
        "numeric_columns = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for categorical_column in categorical_columns:\n",
        "    vocab = train_df[categorical_column].unique()\n",
        "    print(categorical_column, vocab)\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.indicator_column(\n",
        "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "                categorical_column, vocab)))\n",
        "    \n",
        "for categorical_column in numeric_columns:\n",
        "    feature_columns.append(\n",
        "        tf.feature_column.numeric_column(\n",
        "            categorical_column, dtype = tf.float32))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male' 'female']\n",
            "n_siblings_spouses [1 0 3 4 2 5 8]\n",
            "parch [0 1 2 5 3 4]\n",
            "class ['Third' 'First' 'Second']\n",
            "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
            "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
            "alone ['n' 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4eZ48whW2E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data_df, label_df, epochs=10, shuffle=True,\n",
        "                 batch_size=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsmukrN7_434",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1788
        },
        "outputId": "0d14fa89-be76-401a-df7d-40cc6054cef3"
      },
      "source": [
        "output_dir = \"customized_estimator\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    \n",
        "def model_fn(features, labels, mode, params):\n",
        "    # model runtime state: Train, Eval, Predict\n",
        "    input_for_next_layer = tf.feature_column.input_layer(\n",
        "        features, params['feature_columns'])\n",
        "    for n_unit in params['hidden_units']:\n",
        "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
        "                                               units = n_unit,\n",
        "                                               activation = tf.nn.relu)\n",
        "    logits = tf.layers.dense(input_for_next_layer,\n",
        "                             params['n_classes'],\n",
        "                             activation = None)\n",
        "    predicted_classes = tf.argmax(logits, 1)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {\n",
        "            \"class_ids\":predicted_classes[:, tf.newaxis],\n",
        "            \"probabilities\": tf.nn.softmax(logits),\n",
        "            \"logits\": logits\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(mode, \n",
        "                                          predictions = predictions)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels,\n",
        "                                                  logits = logits)\n",
        "    accuracy = tf.metrics.accuracy(labels = labels,\n",
        "                                   predictions = predicted_classes,\n",
        "                                   name = \"acc_op\")\n",
        "    metrics = {\"accuracy\": accuracy}\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
        "                                          eval_metric_ops = metrics)\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    train_op = optimizer.minimize(loss, \n",
        "                                  global_step = tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode, loss = loss,\n",
        "                                          train_op = train_op)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn = model_fn,\n",
        "    model_dir = output_dir,\n",
        "    params = {\n",
        "        \"feature_columns\": feature_columns,\n",
        "        \"hidden_units\": [100, 100],\n",
        "        \"n_classes\": 2\n",
        "    })\n",
        "\n",
        "estimator.train(input_fn = lambda: make_dataset(train_df, y_train,\n",
        "                                                epochs = 100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1f5d980748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-26391defd59c>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-1960\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.28231102, step = 1961\n",
            "INFO:tensorflow:global_step/sec: 450.006\n",
            "INFO:tensorflow:loss = 0.27294195, step = 2061 (0.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.096\n",
            "INFO:tensorflow:loss = 0.3245359, step = 2161 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.599\n",
            "INFO:tensorflow:loss = 0.22300163, step = 2261 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.849\n",
            "INFO:tensorflow:loss = 0.27212507, step = 2361 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.153\n",
            "INFO:tensorflow:loss = 0.15355025, step = 2461 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.074\n",
            "INFO:tensorflow:loss = 0.35370448, step = 2561 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.705\n",
            "INFO:tensorflow:loss = 0.50376046, step = 2661 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.416\n",
            "INFO:tensorflow:loss = 0.42223513, step = 2761 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.048\n",
            "INFO:tensorflow:loss = 0.5278131, step = 2861 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.227\n",
            "INFO:tensorflow:loss = 0.625767, step = 2961 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.526\n",
            "INFO:tensorflow:loss = 0.42615736, step = 3061 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.71\n",
            "INFO:tensorflow:loss = 0.20651048, step = 3161 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.203\n",
            "INFO:tensorflow:loss = 0.26092252, step = 3261 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.891\n",
            "INFO:tensorflow:loss = 0.35046506, step = 3361 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.898\n",
            "INFO:tensorflow:loss = 0.38604045, step = 3461 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.446\n",
            "INFO:tensorflow:loss = 0.19524625, step = 3561 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.95\n",
            "INFO:tensorflow:loss = 0.31848815, step = 3661 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.124\n",
            "INFO:tensorflow:loss = 0.35437065, step = 3761 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.157\n",
            "INFO:tensorflow:loss = 0.17965305, step = 3861 (0.146 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3920 into customized_estimator/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.20682728.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f1f5d980320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BpT5KNYSPOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "26cb82e1-cb7e-4f0d-812c-5493ed4c831f"
      },
      "source": [
        "estimator.evaluate(lambda: make_dataset(\n",
        "    eval_df, y_eval, epochs = 1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-06-16T08:00:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-3920\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-06-16-08:00:58\n",
            "INFO:tensorflow:Saving dict for global step 3920: accuracy = 0.8219697, global_step = 3920, loss = 0.535476\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3920: customized_estimator/model.ckpt-3920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8219697, 'global_step': 3920, 'loss': 0.535476}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeaX920STamy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}