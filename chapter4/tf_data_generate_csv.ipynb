{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_data_generate_csv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_data_generate_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "outputId": "7a22dde6-0618-48ae-a630-4dca39d7e4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.4\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.2\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "abbba06e-ce0b-43d0-c31f-174d5e90f7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "I0603 12:20:12.404407 139827194967936 california_housing.py:114] Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "8e867337-ca06-4510-a36e-18f62ca11e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIxnZqD9o3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = \"generate_csv\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    \n",
        "def save_to_csv(output_dir, data, name_prefix, \n",
        "                header=None, n_parts=10):\n",
        "    path_format = os.path.join(output_dir, \"{}_{:02d}.csv\")\n",
        "    filenames = []\n",
        "    \n",
        "    for file_idx, row_indices in enumerate(\n",
        "        np.array_split(np.arange(len(data)), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filenames.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header + \"\\n\")\n",
        "            for row_index in row_indices:\n",
        "                f.write(\",\".join(\n",
        "                    [repr(col) for col in data[row_index]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filenames\n",
        "\n",
        "train_data = np.c_[x_train_scaled, y_train]\n",
        "valid_data = np.c_[x_valid_scaled, y_valid]\n",
        "test_data = np.c_[x_test_scaled, y_test]\n",
        "\n",
        "header_cols = housing.feature_names + [\"MidianHouseValue\"]\n",
        "header_str = \",\".join(header_cols)\n",
        "\n",
        "train_filenames = save_to_csv(output_dir, train_data, \"train\", \n",
        "                              header_str, n_parts=20)\n",
        "valid_filenames = save_to_csv(output_dir, valid_data, \"valid\",\n",
        "                              header_str, n_parts=10)\n",
        "test_filenames = save_to_csv(output_dir, test_data, \"test\",\n",
        "                              header_str, n_parts=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2qwBsnpSuaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cf4bb5f-ac4a-4565-fa74-b286a04a28c4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generate_csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7ZqD-FOUzaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b5644665-1601-428b-a5f2-0b0a7ed6515d"
      },
      "source": [
        "!ls generate_csv/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_00.csv  test_08.csv   train_06.csv  train_14.csv  valid_02.csv\n",
            "test_01.csv  test_09.csv   train_07.csv  train_15.csv  valid_03.csv\n",
            "test_02.csv  train_00.csv  train_08.csv  train_16.csv  valid_04.csv\n",
            "test_03.csv  train_01.csv  train_09.csv  train_17.csv  valid_05.csv\n",
            "test_04.csv  train_02.csv  train_10.csv  train_18.csv  valid_06.csv\n",
            "test_05.csv  train_03.csv  train_11.csv  train_19.csv  valid_07.csv\n",
            "test_06.csv  train_04.csv  train_12.csv  valid_00.csv  valid_08.csv\n",
            "test_07.csv  train_05.csv  train_13.csv  valid_01.csv  valid_09.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NnZMrb8U6Lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "a1284a0b-e50a-431a-9a3b-a6596dac91f0"
      },
      "source": [
        "import pprint\n",
        "\n",
        "print(\"train filenames:\")\n",
        "pprint.pprint(train_filenames)\n",
        "print(\"valid filenames:\")\n",
        "pprint.pprint(valid_filenames)\n",
        "print(\"test filenames:\")\n",
        "pprint.pprint(test_filenames)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train filenames:\n",
            "['generate_csv/train_00.csv',\n",
            " 'generate_csv/train_01.csv',\n",
            " 'generate_csv/train_02.csv',\n",
            " 'generate_csv/train_03.csv',\n",
            " 'generate_csv/train_04.csv',\n",
            " 'generate_csv/train_05.csv',\n",
            " 'generate_csv/train_06.csv',\n",
            " 'generate_csv/train_07.csv',\n",
            " 'generate_csv/train_08.csv',\n",
            " 'generate_csv/train_09.csv',\n",
            " 'generate_csv/train_10.csv',\n",
            " 'generate_csv/train_11.csv',\n",
            " 'generate_csv/train_12.csv',\n",
            " 'generate_csv/train_13.csv',\n",
            " 'generate_csv/train_14.csv',\n",
            " 'generate_csv/train_15.csv',\n",
            " 'generate_csv/train_16.csv',\n",
            " 'generate_csv/train_17.csv',\n",
            " 'generate_csv/train_18.csv',\n",
            " 'generate_csv/train_19.csv']\n",
            "valid filenames:\n",
            "['generate_csv/valid_00.csv',\n",
            " 'generate_csv/valid_01.csv',\n",
            " 'generate_csv/valid_02.csv',\n",
            " 'generate_csv/valid_03.csv',\n",
            " 'generate_csv/valid_04.csv',\n",
            " 'generate_csv/valid_05.csv',\n",
            " 'generate_csv/valid_06.csv',\n",
            " 'generate_csv/valid_07.csv',\n",
            " 'generate_csv/valid_08.csv',\n",
            " 'generate_csv/valid_09.csv']\n",
            "test filenames:\n",
            "['generate_csv/test_00.csv',\n",
            " 'generate_csv/test_01.csv',\n",
            " 'generate_csv/test_02.csv',\n",
            " 'generate_csv/test_03.csv',\n",
            " 'generate_csv/test_04.csv',\n",
            " 'generate_csv/test_05.csv',\n",
            " 'generate_csv/test_06.csv',\n",
            " 'generate_csv/test_07.csv',\n",
            " 'generate_csv/test_08.csv',\n",
            " 'generate_csv/test_09.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo0vjpLXVccj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "11b1d819-443f-497b-f484-7760e1684b2e"
      },
      "source": [
        "# 读取csv 生成dataset\n",
        "# 1. filename -> dataset\n",
        "# 2. read file -> dataset -> datasets -> merge\n",
        "# 3. parse csv\n",
        "\n",
        "filename_dataset = tf.data.Dataset.list_files(train_filenames)\n",
        "for filename in filename_dataset:\n",
        "    print(filename)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'generate_csv/train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_08.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'generate_csv/train_14.csv', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssAa4rsOV03A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "0796d143-8622-465d-bf65-4ec0c0e3e9ca"
      },
      "source": [
        "n_readers = 5\n",
        "dataset = filename_dataset.interleave(\n",
        "    # skip(1) 跳过header行\n",
        "    lambda filename: tf.data.TextLineDataset(filename).skip(1), # 按行读取文本 生成dataset\n",
        "    cycle_length = n_readers\n",
        ")\n",
        "\n",
        "for line in dataset.take(15):\n",
        "    print(line.numpy())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'0.4853051504718848,-0.8492418886278699,-0.06530126513877861,-0.023379656040017353,1.4974350551260218,-0.07790657783453239,-0.9023632702857819,0.7814514907892068,2.956'\n",
            "b'-1.0591781535672364,1.393564736946074,-0.026331968874673636,-0.11006759528831847,-0.6138198966579805,-0.09695934953589447,0.3247131133362288,-0.037477245413977976,0.672'\n",
            "b'0.6363646332204844,-1.0895425985107923,0.09260902815633619,-0.20538124656801682,1.2025670451003232,-0.03630122549633783,-0.6784101660505877,0.182235342347858,2.429'\n",
            "b'0.8115083791797953,-0.04823952235146133,0.5187339067174729,-0.029386394873127775,-0.034064024638222286,-0.05081594842905086,-0.7157356834231196,0.9162751241885168,2.147'\n",
            "b'-0.32652634129448693,0.43236189741438374,-0.09345459539684739,-0.08402991822890092,0.8460035745154013,-0.0266316482653991,-0.5617679242614233,0.1422875991184281,2.431'\n",
            "b'-0.7432054083470616,0.9129633171802288,-0.644320243857189,-0.1479096959813185,0.7398510909061499,0.11427691039226903,-0.7950524078397521,0.6815821327156534,1.438'\n",
            "b'-0.2223565745313433,1.393564736946074,0.02991299565857307,0.0801452044790158,-0.509481985418118,-0.06238599304952824,-0.86503775291325,0.8613469772480595,2.0'\n",
            "b'-1.0635474225567902,1.874166156711919,-0.49344892844525906,-0.06962612737313081,-0.273587577397559,-0.13419514417565354,1.0338979434143465,-1.3457658361775973,1.982'\n",
            "b'-0.6906143291679195,-0.1283397589791022,7.0201810347470595,5.624287386169439,-0.2663292879200034,-0.03662080416157129,-0.6457503383496215,1.2058962626018372,1.352'\n",
            "b'2.2754266257529974,-1.249743071766074,1.0294788075585177,-0.17124431895714504,-0.45413752815175606,0.10527151658164971,-0.9023632702857819,0.9012947204774823,3.798'\n",
            "b'-0.8246762898717912,-0.04823952235146133,-0.3448658166118309,-0.08477587145199328,0.5012348243315076,-0.034699996532417135,0.5300034588851571,-0.08741192445075467,0.717'\n",
            "b'0.199384450496934,1.0731637904355105,-0.19840853933562783,-0.29328906965393414,-0.07852104768825069,0.018804888420646343,0.8006134598360177,-1.1510205879341566,1.99'\n",
            "b'-0.9974222662636643,1.2333642636907922,-0.7577192870888144,-0.011109251557751528,-0.23003784053222506,0.05487422342718872,-0.757726890467217,0.7065494722340417,1.739'\n",
            "b'-0.9868720801669367,0.832863080552588,-0.18684708416901633,-0.14888949288707784,-0.4532302419670616,-0.11504995754593579,1.6730974284189664,-0.7465496877362412,1.138'\n",
            "b'-0.4394346460367383,0.1920611875314612,-0.39172440230167493,-0.06233787211356993,0.682692061270399,-0.012080008421921133,0.935918460311448,-1.2458964781040367,1.618'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1OkJLDLWWpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eda2dd8c-4687-49d1-dc74-b41c3a963256"
      },
      "source": [
        "# tf.io.decode_csv(str, record_defaults)\n",
        "\n",
        "sample_str = '1, 2, 3, 4, 5'\n",
        "record_defaults = [tf.constant(0, dtype=tf.int32),\n",
        "                   0,\n",
        "                   np.nan,\n",
        "                   \"hello\",\n",
        "                   tf.constant([])\n",
        "]\n",
        "parsed_fields = tf.io.decode_csv(sample_str, record_defaults)\n",
        "print(parsed_fields)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: id=182, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=183, shape=(), dtype=int32, numpy=2>, <tf.Tensor: id=184, shape=(), dtype=float32, numpy=3.0>, <tf.Tensor: id=185, shape=(), dtype=string, numpy=b' 4'>, <tf.Tensor: id=186, shape=(), dtype=float32, numpy=5.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUhyATIAXUNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d07dd1c3-8f32-4222-d2e1-cff99472a4a1"
      },
      "source": [
        "try:\n",
        "    parsed_fields = tf.io.decode_csv(',,,,', record_defaults)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Field 4 is required but missing in record 0! [Op:DecodeCSV]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMy40nnIX4aY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34e22175-4a86-4be8-e053-9c863f5ab481"
      },
      "source": [
        "try:\n",
        "    parsed_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}