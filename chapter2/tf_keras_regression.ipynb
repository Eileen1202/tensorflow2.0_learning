{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "05cf3f7e-0246-4e9f-f1c9-c0b5c5bbca32"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.1\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "f644918a-ce14-44bf-d663-f831e60b84cc"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-wf40jY60j9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8a171d83-2ffa-4a03-ebdb-687f492af2d9"
      },
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(housing.data[0:5])\n",
        "pprint.pprint(housing.target[0:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
            "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
            "         3.78800000e+01, -1.22230000e+02],\n",
            "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
            "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
            "         3.78600000e+01, -1.22220000e+02],\n",
            "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
            "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
            "         3.78500000e+01, -1.22240000e+02],\n",
            "       [ 5.64310000e+00,  5.20000000e+01,  5.81735160e+00,\n",
            "         1.07305936e+00,  5.58000000e+02,  2.54794521e+00,\n",
            "         3.78500000e+01, -1.22250000e+02],\n",
            "       [ 3.84620000e+00,  5.20000000e+01,  6.28185328e+00,\n",
            "         1.08108108e+00,  5.65000000e+02,  2.18146718e+00,\n",
            "         3.78500000e+01, -1.22250000e+02]])\n",
            "array([4.526, 3.585, 3.521, 3.413, 3.422])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "58725674-8ade-4946-fbd8-7a9aff849271"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2607a5bd-2c01-4505-de03-f5905d6b361f"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation='relu',\n",
        "                       input_shape=x_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer = \"sgd\")\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                270       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g9RQd287SJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        },
        "outputId": "cd8e40df-9e3b-4083-de8c-6f8fa29ed22e"
      },
      "source": [
        "history = model.fit(x_train_scaled, y_train,\n",
        "                   validation_data = (x_valid_scaled, y_valid),\n",
        "                   epochs = 100,\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 2.0536 - val_loss: 0.9696\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.7922 - val_loss: 0.7807\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.7054 - val_loss: 0.7327\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6666 - val_loss: 0.7030\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6370 - val_loss: 0.6741\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6141 - val_loss: 0.6527\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5936 - val_loss: 0.6313\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5764 - val_loss: 0.6141\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5608 - val_loss: 0.5970\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5470 - val_loss: 0.5829\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5351 - val_loss: 0.5687\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5249 - val_loss: 0.5575\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5149 - val_loss: 0.5483\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5063 - val_loss: 0.5386\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4984 - val_loss: 0.5306\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4911 - val_loss: 0.5220\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4849 - val_loss: 0.5144\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4791 - val_loss: 0.5092\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4740 - val_loss: 0.5041\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4698 - val_loss: 0.4979\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4656 - val_loss: 0.4929\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4621 - val_loss: 0.4899\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4586 - val_loss: 0.4851\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4563 - val_loss: 0.4814\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4531 - val_loss: 0.4791\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4506 - val_loss: 0.4756\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4481 - val_loss: 0.4733\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4453 - val_loss: 0.4692\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4435 - val_loss: 0.4667\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4408 - val_loss: 0.4643\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4387 - val_loss: 0.4622\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4366 - val_loss: 0.4597\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4346 - val_loss: 0.4574\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4328 - val_loss: 0.4552\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4309 - val_loss: 0.4534\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4293 - val_loss: 0.4523\n",
            "Epoch 37/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4274 - val_loss: 0.4509\n",
            "Epoch 38/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4263 - val_loss: 0.4483\n",
            "Epoch 39/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4245 - val_loss: 0.4466\n",
            "Epoch 40/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4232 - val_loss: 0.4453\n",
            "Epoch 41/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4218 - val_loss: 0.4442\n",
            "Epoch 42/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4203 - val_loss: 0.4424\n",
            "Epoch 43/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4190 - val_loss: 0.4404\n",
            "Epoch 44/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4177 - val_loss: 0.4395\n",
            "Epoch 45/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4162 - val_loss: 0.4379\n",
            "Epoch 46/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4151 - val_loss: 0.4367\n",
            "Epoch 47/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4140 - val_loss: 0.4354\n",
            "Epoch 48/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4127 - val_loss: 0.4331\n",
            "Epoch 49/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4116 - val_loss: 0.4335\n",
            "Epoch 50/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4105 - val_loss: 0.4316\n",
            "Epoch 51/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4095 - val_loss: 0.4303\n",
            "Epoch 52/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4084 - val_loss: 0.4289\n",
            "Epoch 53/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4073 - val_loss: 0.4279\n",
            "Epoch 54/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4062 - val_loss: 0.4273\n",
            "Epoch 55/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4052 - val_loss: 0.4256\n",
            "Epoch 56/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4044 - val_loss: 0.4250\n",
            "Epoch 57/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4032 - val_loss: 0.4238\n",
            "Epoch 58/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4024 - val_loss: 0.4223\n",
            "Epoch 59/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4014 - val_loss: 0.4218\n",
            "Epoch 60/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4007 - val_loss: 0.4202\n",
            "Epoch 61/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3998 - val_loss: 0.4199\n",
            "Epoch 62/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3989 - val_loss: 0.4190\n",
            "Epoch 63/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3981 - val_loss: 0.4179\n",
            "Epoch 64/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3973 - val_loss: 0.4166\n",
            "Epoch 65/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3965 - val_loss: 0.4164\n",
            "Epoch 66/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3957 - val_loss: 0.4149\n",
            "Epoch 67/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3950 - val_loss: 0.4144\n",
            "Epoch 68/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3940 - val_loss: 0.4142\n",
            "Epoch 69/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3936 - val_loss: 0.4128\n",
            "Epoch 70/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3927 - val_loss: 0.4118\n",
            "Epoch 71/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3919 - val_loss: 0.4108\n",
            "Epoch 72/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3912 - val_loss: 0.4101\n",
            "Epoch 73/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3906 - val_loss: 0.4091\n",
            "Epoch 74/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3899 - val_loss: 0.4092\n",
            "Epoch 75/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3892 - val_loss: 0.4074\n",
            "Epoch 76/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3886 - val_loss: 0.4069\n",
            "Epoch 77/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3878 - val_loss: 0.4062\n",
            "Epoch 78/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3872 - val_loss: 0.4056\n",
            "Epoch 79/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3867 - val_loss: 0.4054\n",
            "Epoch 80/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3862 - val_loss: 0.4039\n",
            "Epoch 81/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3855 - val_loss: 0.4031\n",
            "Epoch 82/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3850 - val_loss: 0.4022\n",
            "Epoch 83/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3843 - val_loss: 0.4019\n",
            "Epoch 84/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3837 - val_loss: 0.4019\n",
            "Epoch 85/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3832 - val_loss: 0.4015\n",
            "Epoch 86/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3827 - val_loss: 0.4004\n",
            "Epoch 87/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3820 - val_loss: 0.3992\n",
            "Epoch 88/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3814 - val_loss: 0.3998\n",
            "Epoch 89/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3809 - val_loss: 0.3996\n",
            "Epoch 90/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3807 - val_loss: 0.3984\n",
            "Epoch 91/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3801 - val_loss: 0.3976\n",
            "Epoch 92/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3795 - val_loss: 0.3967\n",
            "Epoch 93/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3791 - val_loss: 0.3962\n",
            "Epoch 94/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3786 - val_loss: 0.3958\n",
            "Epoch 95/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3782 - val_loss: 0.3957\n",
            "Epoch 96/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3777 - val_loss: 0.3958\n",
            "Epoch 97/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3773 - val_loss: 0.3941\n",
            "Epoch 98/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3767 - val_loss: 0.3947\n",
            "Epoch 99/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3764 - val_loss: 0.3936\n",
            "Epoch 100/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3760 - val_loss: 0.3933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "999b413d-7cd5-4e2b-eeea-9cb825c55f62"
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7LY8Sa9iX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d5cc2f72-4e45-49aa-8f9f-1999fed0a57c"
      },
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 23us/sample - loss: 0.3925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3925278560135716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIxnZqD9o3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}