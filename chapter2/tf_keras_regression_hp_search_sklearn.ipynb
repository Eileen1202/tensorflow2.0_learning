{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_hp_search_sklearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression_hp_search_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "498db65b-0420-450b-9fd4-c443585b7d99",
        "id": "Q0VeST_kxB3k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.1\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "46cdaebb-3a88-411e-929f-21611ffd30d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "16af3786-bc16-46fc-b2a4-34afb13df2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "outputId": "3d885822-0bac-4289-f466-2d49fd4c1eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        }
      },
      "source": [
        "# RandomizedSearchCV\n",
        "# 1. 转化为sklearn的model\n",
        "# 2. 定义参数集合\n",
        "# 3. 搜索参数\n",
        "def build_model(hidden_layers = 1, \n",
        "                layer_size = 30, \n",
        "                learning_rate = 3e-3):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(layer_size, activation='relu',\n",
        "                                 input_shape=x_train.shape[1:]))\n",
        "    for _ in range(hidden_layers-1):\n",
        "        model.add(keras.layers.Dense(layer_size, activation='relu'))\n",
        "    \n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
        "\n",
        "history = sklearn_model.fit(x_train_scaled, y_train,\n",
        "                            epochs=100,\n",
        "                            validation_data = (x_valid_scaled, y_valid),\n",
        "                            callbacks = callbacks)\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 1.2424 - val_loss: 0.7345\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.6395 - val_loss: 0.6354\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5614 - val_loss: 0.5708\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5136 - val_loss: 0.5281\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4877 - val_loss: 0.5106\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4709 - val_loss: 0.4986\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4579 - val_loss: 0.4740\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4485 - val_loss: 0.4662\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4405 - val_loss: 0.4553\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4350 - val_loss: 0.4482\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4292 - val_loss: 0.4457\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4223 - val_loss: 0.4380\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4197 - val_loss: 0.4330\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4147 - val_loss: 0.4285\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4089 - val_loss: 0.4248\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4053 - val_loss: 0.4201\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4015 - val_loss: 0.4147\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3978 - val_loss: 0.4121\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3955 - val_loss: 0.4080\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3926 - val_loss: 0.4051\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3889 - val_loss: 0.4033\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3869 - val_loss: 0.3997\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3841 - val_loss: 0.3999\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3827 - val_loss: 0.3947\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3795 - val_loss: 0.3943\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3774 - val_loss: 0.3930\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3754 - val_loss: 0.3886\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3735 - val_loss: 0.3870\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3728 - val_loss: 0.3847\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3707 - val_loss: 0.3831\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3688 - val_loss: 0.3821\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3673 - val_loss: 0.3812\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3662 - val_loss: 0.3781\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3649 - val_loss: 0.3772\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3631 - val_loss: 0.3774\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3617 - val_loss: 0.3753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "outputId": "e618cca0-d16b-4313-b4a9-e7b7ac81af5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEzCAYAAAAVa/veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz0lgwsnzAk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49915
        },
        "outputId": "3db88ba7-ed24-47ec-b5cf-97738d5d70db"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "# 分布函数：f(x) = 1/(x*log(b/a)) a<=x<=b\n",
        "param_distribution = {\n",
        "    \"hidden_layers\": [1, 2, 3, 4],\n",
        "    \"layer_size\": np.arange(1, 100),\n",
        "    \"learning_rate\":reciprocal(1e-4, 1e-2),\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search_cv = RandomizedSearchCV(sklearn_model, \n",
        "                                      param_distribution,\n",
        "                                      n_iter = 10,\n",
        "                                      n_jobs = 1)\n",
        "\n",
        "\"\"\"\n",
        "cross_validation: 训练集分成n份，n-1份训练，最后一份验证\n",
        "默认cv = 3\n",
        "random_search_cv = RandomizedSearchCV(sklearn_model, \n",
        "                                      param_distribution,\n",
        "                                      n_iter = 10,\n",
        "                                      cv = 3,\n",
        "                                      n_jobs = 1)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "random_search_cv.fit(x_train_scaled, y_train,\n",
        "                            epochs=100,\n",
        "                            validation_data = (x_valid_scaled, y_valid),\n",
        "                            callbacks = callbacks)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 5.0586 - val_loss: 3.5980\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 2.5069 - val_loss: 1.9964\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 1.5469 - val_loss: 1.4144\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 1.2067 - val_loss: 1.2013\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.0727 - val_loss: 1.0996\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.0013 - val_loss: 1.0367\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.9521 - val_loss: 0.9890\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.9128 - val_loss: 0.9507\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.8805 - val_loss: 0.9192\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8539 - val_loss: 0.8928\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8315 - val_loss: 0.8706\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.8123 - val_loss: 0.8516\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7959 - val_loss: 0.8354\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7815 - val_loss: 0.8210\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7686 - val_loss: 0.8082\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7570 - val_loss: 0.7967\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7465 - val_loss: 0.7861\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7368 - val_loss: 0.7765\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7279 - val_loss: 0.7673\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7196 - val_loss: 0.7587\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7118 - val_loss: 0.7507\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7045 - val_loss: 0.7431\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6975 - val_loss: 0.7358\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6909 - val_loss: 0.7289\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6846 - val_loss: 0.7223\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6786 - val_loss: 0.7160\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6729 - val_loss: 0.7100\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6674 - val_loss: 0.7042\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6621 - val_loss: 0.6986\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6571 - val_loss: 0.6934\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6523 - val_loss: 0.6884\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6477 - val_loss: 0.6836\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6434 - val_loss: 0.6791\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6392 - val_loss: 0.6746\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6352 - val_loss: 0.6704\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6314 - val_loss: 0.6664\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6277 - val_loss: 0.6627\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6241 - val_loss: 0.6590\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6206 - val_loss: 0.6555\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6173 - val_loss: 0.6521\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6141 - val_loss: 0.6489\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6111 - val_loss: 0.6456\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6082 - val_loss: 0.6424\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6053 - val_loss: 0.6393\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6025 - val_loss: 0.6365\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5998 - val_loss: 0.6337\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5971 - val_loss: 0.6308\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5946 - val_loss: 0.6280\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5920 - val_loss: 0.6253\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5896 - val_loss: 0.6227\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5872 - val_loss: 0.6203\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5849 - val_loss: 0.6179\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5827 - val_loss: 0.6155\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5804 - val_loss: 0.6133\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5783 - val_loss: 0.6110\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5762 - val_loss: 0.6088\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5741 - val_loss: 0.6067\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5721 - val_loss: 0.6047\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5701 - val_loss: 0.6025\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5681 - val_loss: 0.6005\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5662 - val_loss: 0.5985\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5643 - val_loss: 0.5966\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5624 - val_loss: 0.5947\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5605 - val_loss: 0.5930\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5588 - val_loss: 0.5911\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5570 - val_loss: 0.5893\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5553 - val_loss: 0.5875\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5054\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 72us/sample - loss: 3.3197 - val_loss: 2.8518\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 2.3222 - val_loss: 2.1045\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 1.7745 - val_loss: 1.6558\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 1.4277 - val_loss: 1.3683\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 1.1931 - val_loss: 1.1751\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 1.0322 - val_loss: 1.0477\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9254 - val_loss: 0.9653\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8537 - val_loss: 0.9092\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.8054 - val_loss: 0.8692\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7720 - val_loss: 0.8402\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7473 - val_loss: 0.8177\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7280 - val_loss: 0.7987\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7125 - val_loss: 0.7826\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6995 - val_loss: 0.7685\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6881 - val_loss: 0.7561\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6781 - val_loss: 0.7447\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6690 - val_loss: 0.7344\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6606 - val_loss: 0.7242\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6528 - val_loss: 0.7153\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6455 - val_loss: 0.7068\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6387 - val_loss: 0.6991\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6323 - val_loss: 0.6916\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6263 - val_loss: 0.6848\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6205 - val_loss: 0.6782\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6152 - val_loss: 0.6723\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6100 - val_loss: 0.6664\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6051 - val_loss: 0.6609\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6004 - val_loss: 0.6561\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5960 - val_loss: 0.6510\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5918 - val_loss: 0.6462\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5877 - val_loss: 0.6418\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5838 - val_loss: 0.6377\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5800 - val_loss: 0.6331\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5764 - val_loss: 0.6292\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5730 - val_loss: 0.6254\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5697 - val_loss: 0.6216\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5665 - val_loss: 0.6177\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5635 - val_loss: 0.6143\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5605 - val_loss: 0.6108\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5577 - val_loss: 0.6078\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5549 - val_loss: 0.6045\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5524 - val_loss: 0.6017\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5497 - val_loss: 0.5987\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5473 - val_loss: 0.5960\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5448 - val_loss: 0.5929\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5426 - val_loss: 0.5903\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5403 - val_loss: 0.5874\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5381 - val_loss: 0.5848\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5360 - val_loss: 0.5825\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5339 - val_loss: 0.5802\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5319 - val_loss: 0.5778\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5299 - val_loss: 0.5757\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5280 - val_loss: 0.5734\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5262 - val_loss: 0.5713\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5244 - val_loss: 0.5693\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5225 - val_loss: 0.5669\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5209 - val_loss: 0.5651\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5192 - val_loss: 0.5632\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5175 - val_loss: 0.5608\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5159 - val_loss: 0.5589\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5144 - val_loss: 0.5570\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5128 - val_loss: 0.5552\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5113 - val_loss: 0.5535\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5098 - val_loss: 0.5517\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5097\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 4.5652 - val_loss: 3.8339\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 3.0667 - val_loss: 2.7854\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 2.3164 - val_loss: 2.2589\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 1.9084 - val_loss: 1.9391\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 1.6354 - val_loss: 1.6976\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 1.4220 - val_loss: 1.4985\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 1.2471 - val_loss: 1.3314\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 1.1033 - val_loss: 1.1937\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9876 - val_loss: 1.0819\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8962 - val_loss: 0.9916\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8252 - val_loss: 0.9212\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7716 - val_loss: 0.8671\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7316 - val_loss: 0.8257\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7018 - val_loss: 0.7937\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6796 - val_loss: 0.7688\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6627 - val_loss: 0.7497\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6499 - val_loss: 0.7346\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6398 - val_loss: 0.7224\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6317 - val_loss: 0.7125\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6249 - val_loss: 0.7040\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6189 - val_loss: 0.6966\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6136 - val_loss: 0.6901\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6088 - val_loss: 0.6843\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6044 - val_loss: 0.6790\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6003 - val_loss: 0.6742\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5964 - val_loss: 0.6695\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5927 - val_loss: 0.6651\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5892 - val_loss: 0.6609\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5858 - val_loss: 0.6570\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5826 - val_loss: 0.6533\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5795 - val_loss: 0.6496\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5765 - val_loss: 0.6462\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5736 - val_loss: 0.6430\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5708 - val_loss: 0.6398\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5681 - val_loss: 0.6366\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5654 - val_loss: 0.6336\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5628 - val_loss: 0.6307\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5603 - val_loss: 0.6278\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5579 - val_loss: 0.6251\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5555 - val_loss: 0.6224\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5531 - val_loss: 0.6199\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5508 - val_loss: 0.6174\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5485 - val_loss: 0.6150\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5463 - val_loss: 0.6125\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5442 - val_loss: 0.6101\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5421 - val_loss: 0.6078\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5400 - val_loss: 0.6055\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5380 - val_loss: 0.6033\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5360 - val_loss: 0.6011\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5341 - val_loss: 0.5989\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5321 - val_loss: 0.5969\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5302 - val_loss: 0.5949\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5285 - val_loss: 0.5927\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5266 - val_loss: 0.5907\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5249 - val_loss: 0.5887\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5231 - val_loss: 0.5868\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5214 - val_loss: 0.5849\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5198 - val_loss: 0.5831\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5181 - val_loss: 0.5812\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5165 - val_loss: 0.5794\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5149 - val_loss: 0.5777\n",
            "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5610\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 1.3337 - val_loss: 0.8633\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8221 - val_loss: 0.7457\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6580 - val_loss: 0.6495\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5962 - val_loss: 0.6052\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5588 - val_loss: 0.5725\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5341 - val_loss: 0.5513\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5185 - val_loss: 0.5374\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5051 - val_loss: 0.5201\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4922 - val_loss: 0.5095\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4818 - val_loss: 0.4981\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4730 - val_loss: 0.4905\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4709 - val_loss: 0.4863\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4633 - val_loss: 0.4790\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4607 - val_loss: 0.4796\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4565 - val_loss: 0.4732\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4647 - val_loss: 0.4775\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4537 - val_loss: 0.4647\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4496 - val_loss: 0.4639\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4425 - val_loss: 0.4550\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4431 - val_loss: 0.4532\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4348 - val_loss: 0.4472\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4347 - val_loss: 0.4469\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4286 - val_loss: 0.4410\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4271 - val_loss: 0.4373\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4211 - val_loss: 0.4352\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4190 - val_loss: 0.4368\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4158 - val_loss: 0.4286\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4137 - val_loss: 0.4268\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4112 - val_loss: 0.4242\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4095 - val_loss: 0.4197\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4080 - val_loss: 0.4222\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4057 - val_loss: 0.4162\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4041 - val_loss: 0.4157\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4006 - val_loss: 0.4119\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4010 - val_loss: 0.4122\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3987 - val_loss: 0.4091\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3977 - val_loss: 0.4069\n",
            "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3757\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 1.3359 - val_loss: 0.7632\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7358 - val_loss: 0.6104\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5523 - val_loss: 0.5589\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5136 - val_loss: 0.5269\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4886 - val_loss: 0.5107\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4735 - val_loss: 0.4952\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4623 - val_loss: 0.4822\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4534 - val_loss: 0.4735\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4488 - val_loss: 0.4713\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4410 - val_loss: 0.4637\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4357 - val_loss: 0.4540\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4363 - val_loss: 0.4487\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4255 - val_loss: 0.4450\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4253 - val_loss: 0.4434\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4192 - val_loss: 0.4394\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4191 - val_loss: 0.4378\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4190 - val_loss: 0.4331\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4110 - val_loss: 0.4275\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4063 - val_loss: 0.4256\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4068 - val_loss: 0.4260\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4062 - val_loss: 0.4197\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4024 - val_loss: 0.4197\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4048 - val_loss: 0.4203\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3977 - val_loss: 0.4273\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3961 - val_loss: 0.4291\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3943 - val_loss: 0.4117\n",
            "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3908\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 1.9062 - val_loss: 0.8194\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6829 - val_loss: 0.7189\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6146 - val_loss: 0.6655\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5670 - val_loss: 0.6144\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5310 - val_loss: 0.5786\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5047 - val_loss: 0.5537\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4858 - val_loss: 0.5309\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4711 - val_loss: 0.5175\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4607 - val_loss: 0.5060\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4530 - val_loss: 0.4924\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4455 - val_loss: 0.4893\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4406 - val_loss: 0.4759\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4372 - val_loss: 0.4779\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4328 - val_loss: 0.4645\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4290 - val_loss: 0.4614\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4246 - val_loss: 0.4550\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4204 - val_loss: 0.4532\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4166 - val_loss: 0.4491\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4144 - val_loss: 0.4417\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4100 - val_loss: 0.4427\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4078 - val_loss: 0.4350\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4052 - val_loss: 0.4338\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4024 - val_loss: 0.4308\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3995 - val_loss: 0.4332\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3976 - val_loss: 0.4252\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3955 - val_loss: 0.4237\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3937 - val_loss: 0.4216\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3909 - val_loss: 0.4208\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3897 - val_loss: 0.4195\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3875 - val_loss: 0.4150\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3858 - val_loss: 0.4153\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3840 - val_loss: 0.4135\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3830 - val_loss: 0.4094\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3804 - val_loss: 0.4116\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3797 - val_loss: 0.4098\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3785 - val_loss: 0.4070\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3768 - val_loss: 0.4035\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3758 - val_loss: 0.4060\n",
            "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4218\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 1.5944 - val_loss: 0.8674\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7707 - val_loss: 0.7375\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6780 - val_loss: 0.6935\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6399 - val_loss: 0.6592\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6088 - val_loss: 0.6275\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5844 - val_loss: 0.6058\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5637 - val_loss: 0.5843\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5459 - val_loss: 0.5667\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5312 - val_loss: 0.5527\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5190 - val_loss: 0.5396\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5086 - val_loss: 0.5288\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4991 - val_loss: 0.5201\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4912 - val_loss: 0.5125\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4839 - val_loss: 0.5027\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4779 - val_loss: 0.4973\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4724 - val_loss: 0.4991\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4672 - val_loss: 0.4861\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4630 - val_loss: 0.4820\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4595 - val_loss: 0.4767\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4550 - val_loss: 0.4728\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4518 - val_loss: 0.4693\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4489 - val_loss: 0.4662\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4455 - val_loss: 0.4650\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4426 - val_loss: 0.4603\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4395 - val_loss: 0.4577\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4371 - val_loss: 0.4539\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4355 - val_loss: 0.4519\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4324 - val_loss: 0.4479\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4303 - val_loss: 0.4465\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4282 - val_loss: 0.4441\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4263 - val_loss: 0.4417\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4241 - val_loss: 0.4391\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4218 - val_loss: 0.4374\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4202 - val_loss: 0.4353\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4183 - val_loss: 0.4331\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4165 - val_loss: 0.4322\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4152 - val_loss: 0.4291\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4135 - val_loss: 0.4275\n",
            "3870/3870 [==============================] - 0s 25us/sample - loss: 0.3954\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.9463 - val_loss: 0.8398\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6813 - val_loss: 0.6949\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6101 - val_loss: 0.6561\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5803 - val_loss: 0.6250\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5580 - val_loss: 0.6020\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5394 - val_loss: 0.5858\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5258 - val_loss: 0.5765\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5130 - val_loss: 0.5560\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5028 - val_loss: 0.5461\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4942 - val_loss: 0.5380\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4865 - val_loss: 0.5338\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4802 - val_loss: 0.5265\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4736 - val_loss: 0.5111\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4688 - val_loss: 0.5120\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4638 - val_loss: 0.5010\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4602 - val_loss: 0.5042\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4566 - val_loss: 0.4954\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4525 - val_loss: 0.4926\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4486 - val_loss: 0.4822\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4472 - val_loss: 0.4814\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4428 - val_loss: 0.4756\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4408 - val_loss: 0.4728\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4373 - val_loss: 0.4738\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4354 - val_loss: 0.4668\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4328 - val_loss: 0.4665\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4305 - val_loss: 0.4602\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4281 - val_loss: 0.4581\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4265 - val_loss: 0.4544\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4243 - val_loss: 0.4530\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4224 - val_loss: 0.4508\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4209 - val_loss: 0.4487\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4189 - val_loss: 0.4471\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4173 - val_loss: 0.4436\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4154 - val_loss: 0.4415\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4141 - val_loss: 0.4404\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4125 - val_loss: 0.4381\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4111 - val_loss: 0.4365\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4096 - val_loss: 0.4346\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4096\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 1.7638 - val_loss: 0.8620\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6988 - val_loss: 0.7425\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6452 - val_loss: 0.7015\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6126 - val_loss: 0.6725\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5854 - val_loss: 0.6430\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5667 - val_loss: 0.6196\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5452 - val_loss: 0.5998\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5278 - val_loss: 0.5806\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5177 - val_loss: 0.5662\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5034 - val_loss: 0.5539\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4932 - val_loss: 0.5419\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4847 - val_loss: 0.5320\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4780 - val_loss: 0.5238\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4712 - val_loss: 0.5173\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4651 - val_loss: 0.5102\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4598 - val_loss: 0.5043\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4567 - val_loss: 0.4979\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4524 - val_loss: 0.4939\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4476 - val_loss: 0.4893\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4438 - val_loss: 0.4836\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4410 - val_loss: 0.4803\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4365 - val_loss: 0.4766\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4355 - val_loss: 0.4723\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4311 - val_loss: 0.4695\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4292 - val_loss: 0.4659\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4254 - val_loss: 0.4640\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4235 - val_loss: 0.4597\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4219 - val_loss: 0.4578\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4184 - val_loss: 0.4551\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4162 - val_loss: 0.4515\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4149 - val_loss: 0.4496\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4126 - val_loss: 0.4472\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4117 - val_loss: 0.4450\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4080 - val_loss: 0.4433\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4063 - val_loss: 0.4399\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4049 - val_loss: 0.4385\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4024 - val_loss: 0.4364\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4004 - val_loss: 0.4346\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3990 - val_loss: 0.4321\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3983 - val_loss: 0.4308\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3960 - val_loss: 0.4288\n",
            "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4317\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 57us/sample - loss: 2.3572 - val_loss: 1.2292\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.9708 - val_loss: 0.8700\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7589 - val_loss: 0.7520\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6901 - val_loss: 0.7089\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6523 - val_loss: 0.6727\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6237 - val_loss: 0.6467\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6007 - val_loss: 0.6262\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5807 - val_loss: 0.6044\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5628 - val_loss: 0.5859\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5476 - val_loss: 0.5726\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5345 - val_loss: 0.5581\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5223 - val_loss: 0.5453\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5117 - val_loss: 0.5344\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5025 - val_loss: 0.5259\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4946 - val_loss: 0.5176\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4873 - val_loss: 0.5095\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4807 - val_loss: 0.5018\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4746 - val_loss: 0.4974\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4690 - val_loss: 0.4902\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4644 - val_loss: 0.4849\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4599 - val_loss: 0.4799\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4559 - val_loss: 0.4758\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4516 - val_loss: 0.4711\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4483 - val_loss: 0.4667\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4450 - val_loss: 0.4632\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4416 - val_loss: 0.4607\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4386 - val_loss: 0.4562\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4357 - val_loss: 0.4533\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4326 - val_loss: 0.4509\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4302 - val_loss: 0.4479\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4277 - val_loss: 0.4446\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4254 - val_loss: 0.4419\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4225 - val_loss: 0.4413\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4202 - val_loss: 0.4375\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4183 - val_loss: 0.4342\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4158 - val_loss: 0.4315\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4137 - val_loss: 0.4297\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4115 - val_loss: 0.4265\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4089 - val_loss: 0.4253\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4072 - val_loss: 0.4230\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4051 - val_loss: 0.4199\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4033 - val_loss: 0.4183\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4014 - val_loss: 0.4161\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3996 - val_loss: 0.4145\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3980 - val_loss: 0.4125\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3963 - val_loss: 0.4100\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3947 - val_loss: 0.4088\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3928 - val_loss: 0.4068\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3911 - val_loss: 0.4052\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3899 - val_loss: 0.4031\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3737\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 2.3189 - val_loss: 1.1070\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.8981 - val_loss: 0.8218\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7396 - val_loss: 0.7463\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6816 - val_loss: 0.7045\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6435 - val_loss: 0.6711\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6130 - val_loss: 0.6431\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5869 - val_loss: 0.6176\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5636 - val_loss: 0.5952\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5432 - val_loss: 0.5740\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5247 - val_loss: 0.5558\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5091 - val_loss: 0.5387\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4951 - val_loss: 0.5247\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4829 - val_loss: 0.5112\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4721 - val_loss: 0.4998\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4624 - val_loss: 0.4904\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4538 - val_loss: 0.4823\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4470 - val_loss: 0.4737\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4404 - val_loss: 0.4664\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4343 - val_loss: 0.4605\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4292 - val_loss: 0.4543\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4243 - val_loss: 0.4492\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4196 - val_loss: 0.4462\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4161 - val_loss: 0.4394\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4123 - val_loss: 0.4352\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4087 - val_loss: 0.4324\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4059 - val_loss: 0.4285\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4029 - val_loss: 0.4258\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4002 - val_loss: 0.4226\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3977 - val_loss: 0.4195\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3954 - val_loss: 0.4171\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3931 - val_loss: 0.4151\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3909 - val_loss: 0.4130\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3891 - val_loss: 0.4104\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3870 - val_loss: 0.4080\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3857 - val_loss: 0.4061\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3839 - val_loss: 0.4037\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3823 - val_loss: 0.4025\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3808 - val_loss: 0.4016\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3796 - val_loss: 0.4006\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3784 - val_loss: 0.3995\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3801\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 58us/sample - loss: 2.2090 - val_loss: 1.1732\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8819 - val_loss: 0.8090\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6963 - val_loss: 0.7305\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6446 - val_loss: 0.6990\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6178 - val_loss: 0.6765\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5974 - val_loss: 0.6571\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5802 - val_loss: 0.6393\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5646 - val_loss: 0.6237\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5510 - val_loss: 0.6086\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5385 - val_loss: 0.5947\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5266 - val_loss: 0.5829\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5161 - val_loss: 0.5702\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5056 - val_loss: 0.5609\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4966 - val_loss: 0.5492\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4877 - val_loss: 0.5397\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4797 - val_loss: 0.5307\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4722 - val_loss: 0.5228\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4654 - val_loss: 0.5141\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4583 - val_loss: 0.5071\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4525 - val_loss: 0.5010\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4472 - val_loss: 0.4949\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4416 - val_loss: 0.4883\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4368 - val_loss: 0.4827\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4321 - val_loss: 0.4777\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4277 - val_loss: 0.4728\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4234 - val_loss: 0.4678\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4196 - val_loss: 0.4639\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4157 - val_loss: 0.4595\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4120 - val_loss: 0.4550\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4087 - val_loss: 0.4515\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4052 - val_loss: 0.4479\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4021 - val_loss: 0.4444\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3991 - val_loss: 0.4416\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3961 - val_loss: 0.4373\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3936 - val_loss: 0.4354\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3907 - val_loss: 0.4314\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3884 - val_loss: 0.4288\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3858 - val_loss: 0.4266\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3835 - val_loss: 0.4239\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3814 - val_loss: 0.4211\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3789 - val_loss: 0.4207\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3771 - val_loss: 0.4164\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3750 - val_loss: 0.4140\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3730 - val_loss: 0.4115\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3712 - val_loss: 0.4105\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3695 - val_loss: 0.4084\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3676 - val_loss: 0.4056\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3664 - val_loss: 0.4053\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3645 - val_loss: 0.4021\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3633 - val_loss: 0.4013\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3617 - val_loss: 0.3997\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3602 - val_loss: 0.3980\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4034\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 3.3906 - val_loss: 2.2279\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 1.6717 - val_loss: 1.3201\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 1.1179 - val_loss: 0.9846\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8787 - val_loss: 0.8355\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7678 - val_loss: 0.7654\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7110 - val_loss: 0.7277\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6785 - val_loss: 0.7038\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6571 - val_loss: 0.6864\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6411 - val_loss: 0.6721\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6282 - val_loss: 0.6601\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6171 - val_loss: 0.6490\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6073 - val_loss: 0.6389\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5982 - val_loss: 0.6299\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5899 - val_loss: 0.6210\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5822 - val_loss: 0.6127\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5749 - val_loss: 0.6054\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5683 - val_loss: 0.5981\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5621 - val_loss: 0.5914\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5562 - val_loss: 0.5850\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5507 - val_loss: 0.5791\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5456 - val_loss: 0.5734\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5408 - val_loss: 0.5686\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5364 - val_loss: 0.5637\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5322 - val_loss: 0.5592\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5283 - val_loss: 0.5549\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5247 - val_loss: 0.5508\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5211 - val_loss: 0.5469\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5180 - val_loss: 0.5434\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5148 - val_loss: 0.5399\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5121 - val_loss: 0.5370\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5094 - val_loss: 0.5342\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5068 - val_loss: 0.5315\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5044 - val_loss: 0.5290\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5020 - val_loss: 0.5260\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4999 - val_loss: 0.5238\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4978 - val_loss: 0.5216\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4958 - val_loss: 0.5194\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4939 - val_loss: 0.5175\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4919 - val_loss: 0.5152\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4903 - val_loss: 0.5135\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4886 - val_loss: 0.5116\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4869 - val_loss: 0.5097\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4529\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 3.2250 - val_loss: 1.9584\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 1.4798 - val_loss: 1.1597\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.9772 - val_loss: 0.9174\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8002 - val_loss: 0.8274\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7317 - val_loss: 0.7845\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6991 - val_loss: 0.7580\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6787 - val_loss: 0.7383\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6634 - val_loss: 0.7223\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6504 - val_loss: 0.7084\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6388 - val_loss: 0.6958\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6284 - val_loss: 0.6844\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6185 - val_loss: 0.6740\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6096 - val_loss: 0.6643\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6012 - val_loss: 0.6554\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5933 - val_loss: 0.6469\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5859 - val_loss: 0.6385\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5790 - val_loss: 0.6312\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5725 - val_loss: 0.6242\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5663 - val_loss: 0.6176\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5605 - val_loss: 0.6113\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5551 - val_loss: 0.6054\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5498 - val_loss: 0.5994\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5449 - val_loss: 0.5939\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5401 - val_loss: 0.5885\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5358 - val_loss: 0.5834\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5316 - val_loss: 0.5786\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5276 - val_loss: 0.5743\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5238 - val_loss: 0.5695\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5202 - val_loss: 0.5655\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5168 - val_loss: 0.5614\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5136 - val_loss: 0.5577\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5105 - val_loss: 0.5540\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5075 - val_loss: 0.5506\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5047 - val_loss: 0.5471\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5020 - val_loss: 0.5437\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4994 - val_loss: 0.5408\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4968 - val_loss: 0.5378\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4945 - val_loss: 0.5352\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4921 - val_loss: 0.5322\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4900 - val_loss: 0.5297\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4879 - val_loss: 0.5271\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4859 - val_loss: 0.5244\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4840 - val_loss: 0.5221\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4822 - val_loss: 0.5200\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4803 - val_loss: 0.5180\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4786 - val_loss: 0.5159\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4769 - val_loss: 0.5139\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4753 - val_loss: 0.5120\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4737 - val_loss: 0.5099\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4723 - val_loss: 0.5081\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4708 - val_loss: 0.5065\n",
            "3870/3870 [==============================] - 0s 24us/sample - loss: 0.4776\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 3.3544 - val_loss: 2.0439\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 1.4806 - val_loss: 1.1380\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9290 - val_loss: 0.8716\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7439 - val_loss: 0.7760\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6785 - val_loss: 0.7363\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6500 - val_loss: 0.7145\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6337 - val_loss: 0.7000\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6217 - val_loss: 0.6878\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6120 - val_loss: 0.6782\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6035 - val_loss: 0.6692\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5955 - val_loss: 0.6605\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5881 - val_loss: 0.6526\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5810 - val_loss: 0.6441\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5745 - val_loss: 0.6369\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5683 - val_loss: 0.6304\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5624 - val_loss: 0.6238\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5567 - val_loss: 0.6171\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5514 - val_loss: 0.6109\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5462 - val_loss: 0.6046\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5414 - val_loss: 0.5988\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5367 - val_loss: 0.5937\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5322 - val_loss: 0.5884\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5278 - val_loss: 0.5834\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5237 - val_loss: 0.5786\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5197 - val_loss: 0.5740\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5158 - val_loss: 0.5696\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5121 - val_loss: 0.5653\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5085 - val_loss: 0.5613\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5053 - val_loss: 0.5574\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5021 - val_loss: 0.5537\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4991 - val_loss: 0.5501\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4961 - val_loss: 0.5468\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4933 - val_loss: 0.5434\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4906 - val_loss: 0.5405\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4881 - val_loss: 0.5372\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4856 - val_loss: 0.5344\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4833 - val_loss: 0.5316\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4809 - val_loss: 0.5287\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4787 - val_loss: 0.5262\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4766 - val_loss: 0.5235\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4745 - val_loss: 0.5211\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4725 - val_loss: 0.5187\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4706 - val_loss: 0.5167\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4687 - val_loss: 0.5140\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4669 - val_loss: 0.5119\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4651 - val_loss: 0.5098\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4635 - val_loss: 0.5078\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4618 - val_loss: 0.5057\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4601 - val_loss: 0.5037\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4586 - val_loss: 0.5018\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4569 - val_loss: 0.5003\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4554 - val_loss: 0.4984\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4539 - val_loss: 0.4967\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4524 - val_loss: 0.4953\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4899\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 2.1697 - val_loss: 1.0620\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8475 - val_loss: 0.8164\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7343 - val_loss: 0.7427\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6854 - val_loss: 0.7003\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6491 - val_loss: 0.6667\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6227 - val_loss: 0.6434\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5982 - val_loss: 0.6183\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5795 - val_loss: 0.5967\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5637 - val_loss: 0.5811\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5499 - val_loss: 0.5671\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5372 - val_loss: 0.5523\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5268 - val_loss: 0.5417\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5162 - val_loss: 0.5309\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5078 - val_loss: 0.5219\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5002 - val_loss: 0.5158\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4930 - val_loss: 0.5054\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4882 - val_loss: 0.5008\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4810 - val_loss: 0.4919\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4771 - val_loss: 0.4894\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4716 - val_loss: 0.4824\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4667 - val_loss: 0.4759\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4621 - val_loss: 0.4732\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4587 - val_loss: 0.4672\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4559 - val_loss: 0.4644\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4518 - val_loss: 0.4593\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4492 - val_loss: 0.4559\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4456 - val_loss: 0.4538\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4447 - val_loss: 0.4511\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4403 - val_loss: 0.4462\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4396 - val_loss: 0.4457\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4358 - val_loss: 0.4428\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4338 - val_loss: 0.4392\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4326 - val_loss: 0.4393\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4297 - val_loss: 0.4352\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4282 - val_loss: 0.4337\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4265 - val_loss: 0.4304\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4250 - val_loss: 0.4303\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4232 - val_loss: 0.4286\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4221 - val_loss: 0.4312\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4208 - val_loss: 0.4249\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4189 - val_loss: 0.4248\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3955\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 2.0222 - val_loss: 0.9145\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7094 - val_loss: 0.6803\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6050 - val_loss: 0.6288\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5726 - val_loss: 0.6020\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5524 - val_loss: 0.5814\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5366 - val_loss: 0.5675\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5231 - val_loss: 0.5525\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5113 - val_loss: 0.5390\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5007 - val_loss: 0.5259\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4909 - val_loss: 0.5135\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4825 - val_loss: 0.5038\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4744 - val_loss: 0.4947\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4675 - val_loss: 0.4877\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4602 - val_loss: 0.4804\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4549 - val_loss: 0.4730\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4492 - val_loss: 0.4671\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4447 - val_loss: 0.4621\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4406 - val_loss: 0.4558\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4398 - val_loss: 0.4581\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4367 - val_loss: 0.4543\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4328 - val_loss: 0.4473\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4335 - val_loss: 0.4513\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4311 - val_loss: 0.4479\n",
            "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4284\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 1.7804 - val_loss: 0.9928\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8248 - val_loss: 0.8160\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7274 - val_loss: 0.7612\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6799 - val_loss: 0.7218\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6489 - val_loss: 0.6892\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6201 - val_loss: 0.6641\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5964 - val_loss: 0.6375\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5726 - val_loss: 0.6134\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5545 - val_loss: 0.5902\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5355 - val_loss: 0.5708\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5182 - val_loss: 0.5566\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5040 - val_loss: 0.5464\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4930 - val_loss: 0.5341\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4874 - val_loss: 0.5243\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4835 - val_loss: 0.5156\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4700 - val_loss: 0.5050\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4639 - val_loss: 0.5008\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4587 - val_loss: 0.4980\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4539 - val_loss: 0.4886\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4496 - val_loss: 0.4863\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4451 - val_loss: 0.4817\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4412 - val_loss: 0.4756\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4377 - val_loss: 0.4748\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4342 - val_loss: 0.4678\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4303 - val_loss: 0.4637\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4273 - val_loss: 0.4589\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4238 - val_loss: 0.4570\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4210 - val_loss: 0.4532\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4186 - val_loss: 0.4505\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4162 - val_loss: 0.4485\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4134 - val_loss: 0.4449\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4112 - val_loss: 0.4441\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4090 - val_loss: 0.4387\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4069 - val_loss: 0.4383\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4048 - val_loss: 0.4380\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4029 - val_loss: 0.4375\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4010 - val_loss: 0.4301\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3997 - val_loss: 0.4293\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4363\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9745 - val_loss: 0.6282\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5438 - val_loss: 0.5531\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5393 - val_loss: 0.5288\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4915 - val_loss: 0.4979\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4385 - val_loss: 0.4379\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4144 - val_loss: 0.4218\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4001 - val_loss: 0.4094\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3928 - val_loss: 0.4013\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3847 - val_loss: 0.3931\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3781 - val_loss: 0.3901\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3724 - val_loss: 0.3801\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3663 - val_loss: 0.3835\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3623 - val_loss: 0.3774\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3581 - val_loss: 0.3745\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3535 - val_loss: 0.3722\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3515 - val_loss: 0.3638\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3489 - val_loss: 0.3632\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3463 - val_loss: 0.3629\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3424 - val_loss: 0.3668\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3402 - val_loss: 0.3562\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3389 - val_loss: 0.3525\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3369 - val_loss: 0.3503\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3331 - val_loss: 0.3557\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3309 - val_loss: 0.3457\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3286 - val_loss: 0.3473\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3264 - val_loss: 0.3473\n",
            "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3333\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.9518 - val_loss: 0.5878\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5863 - val_loss: 0.5209\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4653 - val_loss: 0.4633\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4351 - val_loss: 0.4360\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4118 - val_loss: 0.4207\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3998 - val_loss: 0.4128\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3900 - val_loss: 0.4022\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3840 - val_loss: 0.3994\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3844 - val_loss: 0.3930\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3819 - val_loss: 0.3857\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3680 - val_loss: 0.3810\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3647 - val_loss: 0.3916\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3609 - val_loss: 0.3730\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3579 - val_loss: 0.3738\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3551 - val_loss: 0.3655\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3526 - val_loss: 0.3658\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3491 - val_loss: 0.3592\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3464 - val_loss: 0.3638\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3437 - val_loss: 0.3606\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3415 - val_loss: 0.3628\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3394 - val_loss: 0.3592\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3372 - val_loss: 0.3529\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.3361\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 1.4379 - val_loss: 0.6607\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5402 - val_loss: 0.5215\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4453 - val_loss: 0.4608\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4076 - val_loss: 0.4321\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3888 - val_loss: 0.4111\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3772 - val_loss: 0.3976\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3681 - val_loss: 0.3939\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3592 - val_loss: 0.3845\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3539 - val_loss: 0.3822\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3488 - val_loss: 0.3763\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3466 - val_loss: 0.3701\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3401 - val_loss: 0.3651\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3354 - val_loss: 0.3635\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3327 - val_loss: 0.3598\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3296 - val_loss: 0.3570\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3252 - val_loss: 0.3543\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3234 - val_loss: 0.3546\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3207 - val_loss: 0.3484\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3179 - val_loss: 0.3556\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3152 - val_loss: 0.3545\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3130 - val_loss: 0.3431\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3122 - val_loss: 0.3415\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3097 - val_loss: 0.3425\n",
            "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3550\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 6.5462 - val_loss: 5.7889\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 4.9266 - val_loss: 4.4220\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 3.8146 - val_loss: 3.4595\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 3.0168 - val_loss: 2.7611\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 2.4307 - val_loss: 2.2448\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 1.9951 - val_loss: 1.8615\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.6705 - val_loss: 1.5779\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.4306 - val_loss: 1.3696\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.2532 - val_loss: 1.2167\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.1214 - val_loss: 1.1036\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 1.0235 - val_loss: 1.0207\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.9503 - val_loss: 0.9591\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8955 - val_loss: 0.9128\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.8539 - val_loss: 0.8776\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8220 - val_loss: 0.8504\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7971 - val_loss: 0.8289\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7773 - val_loss: 0.8115\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7612 - val_loss: 0.7971\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7479 - val_loss: 0.7849\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7366 - val_loss: 0.7743\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7269 - val_loss: 0.7651\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7184 - val_loss: 0.7568\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7109 - val_loss: 0.7493\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7040 - val_loss: 0.7424\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6977 - val_loss: 0.7360\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6920 - val_loss: 0.7300\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6866 - val_loss: 0.7243\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6816 - val_loss: 0.7189\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6768 - val_loss: 0.7139\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6723 - val_loss: 0.7090\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6680 - val_loss: 0.7042\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6638 - val_loss: 0.6997\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6599 - val_loss: 0.6954\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6560 - val_loss: 0.6912\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6524 - val_loss: 0.6872\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6488 - val_loss: 0.6833\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6453 - val_loss: 0.6795\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6419 - val_loss: 0.6758\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6387 - val_loss: 0.6723\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6355 - val_loss: 0.6687\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6323 - val_loss: 0.6653\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6293 - val_loss: 0.6620\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6263 - val_loss: 0.6588\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6234 - val_loss: 0.6556\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6205 - val_loss: 0.6525\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6177 - val_loss: 0.6494\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6150 - val_loss: 0.6464\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6123 - val_loss: 0.6435\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6097 - val_loss: 0.6406\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6072 - val_loss: 0.6377\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6046 - val_loss: 0.6350\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6022 - val_loss: 0.6323\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5998 - val_loss: 0.6296\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5974 - val_loss: 0.6270\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5951 - val_loss: 0.6244\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5928 - val_loss: 0.6219\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5906 - val_loss: 0.6195\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5884 - val_loss: 0.6170\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5862 - val_loss: 0.6146\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5840 - val_loss: 0.6122\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5819 - val_loss: 0.6099\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5798 - val_loss: 0.6076\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5777 - val_loss: 0.6054\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5757 - val_loss: 0.6032\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5737 - val_loss: 0.6010\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5717 - val_loss: 0.5989\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5697 - val_loss: 0.5968\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5678 - val_loss: 0.5948\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5660 - val_loss: 0.5927\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5642 - val_loss: 0.5908\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5623 - val_loss: 0.5889\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5606 - val_loss: 0.5870\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5588 - val_loss: 0.5851\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5572 - val_loss: 0.5833\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5555 - val_loss: 0.5815\n",
            "Epoch 76/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5538 - val_loss: 0.5797\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5105\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 6.1610 - val_loss: 5.3588\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 4.3103 - val_loss: 3.9223\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 3.2181 - val_loss: 3.0441\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 2.5382 - val_loss: 2.4781\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 2.1016 - val_loss: 2.1039\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.8077 - val_loss: 1.8427\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.5999 - val_loss: 1.6514\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 1.4459 - val_loss: 1.5062\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.3269 - val_loss: 1.3915\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.2316 - val_loss: 1.2985\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 1.1536 - val_loss: 1.2218\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.0883 - val_loss: 1.1570\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 1.0330 - val_loss: 1.1018\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.9858 - val_loss: 1.0548\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.9452 - val_loss: 1.0142\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.9100 - val_loss: 0.9792\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.8794 - val_loss: 0.9488\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8527 - val_loss: 0.9222\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8293 - val_loss: 0.8992\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8087 - val_loss: 0.8788\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7906 - val_loss: 0.8609\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7744 - val_loss: 0.8449\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7601 - val_loss: 0.8307\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7472 - val_loss: 0.8179\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7356 - val_loss: 0.8063\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.7252 - val_loss: 0.7958\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7158 - val_loss: 0.7863\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7072 - val_loss: 0.7776\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6993 - val_loss: 0.7697\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6920 - val_loss: 0.7622\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6853 - val_loss: 0.7553\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6789 - val_loss: 0.7489\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6730 - val_loss: 0.7428\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6675 - val_loss: 0.7370\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6622 - val_loss: 0.7315\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6572 - val_loss: 0.7263\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6525 - val_loss: 0.7214\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6480 - val_loss: 0.7167\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6437 - val_loss: 0.7121\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6396 - val_loss: 0.7078\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6357 - val_loss: 0.7036\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6319 - val_loss: 0.6996\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6283 - val_loss: 0.6957\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6248 - val_loss: 0.6919\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6214 - val_loss: 0.6883\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6180 - val_loss: 0.6847\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6148 - val_loss: 0.6812\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6117 - val_loss: 0.6779\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6087 - val_loss: 0.6746\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6058 - val_loss: 0.6715\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6030 - val_loss: 0.6685\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6003 - val_loss: 0.6655\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5976 - val_loss: 0.6626\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5950 - val_loss: 0.6597\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5925 - val_loss: 0.6570\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5901 - val_loss: 0.6543\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5877 - val_loss: 0.6516\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5854 - val_loss: 0.6491\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5831 - val_loss: 0.6465\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5809 - val_loss: 0.6441\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5787 - val_loss: 0.6417\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5766 - val_loss: 0.6393\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5746 - val_loss: 0.6370\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5725 - val_loss: 0.6348\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5706 - val_loss: 0.6325\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5686 - val_loss: 0.6304\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5667 - val_loss: 0.6283\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5649 - val_loss: 0.6261\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5630 - val_loss: 0.6241\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5613 - val_loss: 0.6220\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5595 - val_loss: 0.6200\n",
            "Epoch 72/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5578 - val_loss: 0.6181\n",
            "Epoch 73/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5561 - val_loss: 0.6161\n",
            "Epoch 74/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5545 - val_loss: 0.6142\n",
            "Epoch 75/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5529 - val_loss: 0.6124\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5766\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 5.7339 - val_loss: 5.2326\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 4.2485 - val_loss: 3.9663\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 3.2952 - val_loss: 3.1296\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 2.6472 - val_loss: 2.5533\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 2.1869 - val_loss: 2.1389\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.8483 - val_loss: 1.8323\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.5936 - val_loss: 1.6047\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 1.3979 - val_loss: 1.4291\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 1.2483 - val_loss: 1.2958\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 1.1311 - val_loss: 1.1920\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 1.0386 - val_loss: 1.1106\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9654 - val_loss: 1.0460\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.9078 - val_loss: 0.9947\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8621 - val_loss: 0.9535\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.8257 - val_loss: 0.9205\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7964 - val_loss: 0.8938\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7729 - val_loss: 0.8718\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7537 - val_loss: 0.8537\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7381 - val_loss: 0.8385\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7252 - val_loss: 0.8257\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7144 - val_loss: 0.8147\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7053 - val_loss: 0.8053\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6975 - val_loss: 0.7971\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6907 - val_loss: 0.7897\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6848 - val_loss: 0.7832\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6795 - val_loss: 0.7773\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6747 - val_loss: 0.7718\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6704 - val_loss: 0.7669\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6664 - val_loss: 0.7623\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6627 - val_loss: 0.7580\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6593 - val_loss: 0.7539\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6560 - val_loss: 0.7501\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6529 - val_loss: 0.7464\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6500 - val_loss: 0.7429\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6472 - val_loss: 0.7395\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6445 - val_loss: 0.7363\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6418 - val_loss: 0.7331\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6393 - val_loss: 0.7301\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6369 - val_loss: 0.7271\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6345 - val_loss: 0.7243\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6322 - val_loss: 0.7215\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6299 - val_loss: 0.7188\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6277 - val_loss: 0.7161\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6255 - val_loss: 0.7135\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6234 - val_loss: 0.7110\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6214 - val_loss: 0.7085\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6193 - val_loss: 0.7061\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6173 - val_loss: 0.7037\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6154 - val_loss: 0.7013\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6134 - val_loss: 0.6990\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6115 - val_loss: 0.6968\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6097 - val_loss: 0.6946\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6079 - val_loss: 0.6924\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6061 - val_loss: 0.6903\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6043 - val_loss: 0.6881\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6026 - val_loss: 0.6860\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6009 - val_loss: 0.6840\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5992 - val_loss: 0.6820\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5976 - val_loss: 0.6800\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5960 - val_loss: 0.6780\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5943 - val_loss: 0.6761\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5927 - val_loss: 0.6742\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5912 - val_loss: 0.6723\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5896 - val_loss: 0.6704\n",
            "3870/3870 [==============================] - 0s 22us/sample - loss: 0.6407\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 1s 76us/sample - loss: 4.7877 - val_loss: 3.7258\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 2.7932 - val_loss: 2.2116\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 1.7309 - val_loss: 1.4506\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 1.2278 - val_loss: 1.1132\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 1.0042 - val_loss: 0.9603\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8951 - val_loss: 0.8819\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.8334 - val_loss: 0.8360\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7944 - val_loss: 0.8055\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7667 - val_loss: 0.7832\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7457 - val_loss: 0.7662\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7291 - val_loss: 0.7526\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7157 - val_loss: 0.7413\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7045 - val_loss: 0.7317\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6948 - val_loss: 0.7232\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6864 - val_loss: 0.7156\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6788 - val_loss: 0.7086\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6718 - val_loss: 0.7020\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6654 - val_loss: 0.6959\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6593 - val_loss: 0.6900\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6536 - val_loss: 0.6842\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6482 - val_loss: 0.6787\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6429 - val_loss: 0.6734\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6379 - val_loss: 0.6684\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6330 - val_loss: 0.6635\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6284 - val_loss: 0.6585\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6238 - val_loss: 0.6538\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6194 - val_loss: 0.6491\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6152 - val_loss: 0.6447\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6111 - val_loss: 0.6403\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6070 - val_loss: 0.6360\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6032 - val_loss: 0.6319\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5994 - val_loss: 0.6279\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5957 - val_loss: 0.6239\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5921 - val_loss: 0.6202\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5886 - val_loss: 0.6165\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5852 - val_loss: 0.6128\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5819 - val_loss: 0.6093\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5788 - val_loss: 0.6058\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5756 - val_loss: 0.6024\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5725 - val_loss: 0.5991\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5696 - val_loss: 0.5959\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5666 - val_loss: 0.5927\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5638 - val_loss: 0.5896\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5610 - val_loss: 0.5867\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5583 - val_loss: 0.5839\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5557 - val_loss: 0.5810\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5531 - val_loss: 0.5783\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5505 - val_loss: 0.5756\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5481 - val_loss: 0.5728\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5457 - val_loss: 0.5702\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5433 - val_loss: 0.5677\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5410 - val_loss: 0.5652\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5388 - val_loss: 0.5628\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5366 - val_loss: 0.5603\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5344 - val_loss: 0.5580\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5323 - val_loss: 0.5556\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5302 - val_loss: 0.5535\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5282 - val_loss: 0.5513\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5262 - val_loss: 0.5491\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5243 - val_loss: 0.5470\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5224 - val_loss: 0.5450\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5205 - val_loss: 0.5429\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5187 - val_loss: 0.5410\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5169 - val_loss: 0.5390\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5151 - val_loss: 0.5372\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5135 - val_loss: 0.5354\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5118 - val_loss: 0.5336\n",
            "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4755\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 4.3149 - val_loss: 3.4739\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 2.7007 - val_loss: 2.2113\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 1.8358 - val_loss: 1.5740\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 1.3800 - val_loss: 1.2315\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 1.1270 - val_loss: 1.0497\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9781 - val_loss: 0.9450\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8808 - val_loss: 0.8790\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8147 - val_loss: 0.8340\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7695 - val_loss: 0.8023\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7369 - val_loss: 0.7798\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7131 - val_loss: 0.7628\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6952 - val_loss: 0.7494\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6810 - val_loss: 0.7383\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6697 - val_loss: 0.7287\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6601 - val_loss: 0.7202\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6519 - val_loss: 0.7126\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6447 - val_loss: 0.7055\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6382 - val_loss: 0.6991\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6323 - val_loss: 0.6928\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6267 - val_loss: 0.6869\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6214 - val_loss: 0.6812\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6165 - val_loss: 0.6757\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6117 - val_loss: 0.6705\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6071 - val_loss: 0.6653\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6027 - val_loss: 0.6603\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5984 - val_loss: 0.6554\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5942 - val_loss: 0.6508\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5902 - val_loss: 0.6461\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5862 - val_loss: 0.6416\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5824 - val_loss: 0.6373\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5787 - val_loss: 0.6329\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5750 - val_loss: 0.6287\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5715 - val_loss: 0.6247\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5681 - val_loss: 0.6206\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5647 - val_loss: 0.6168\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5614 - val_loss: 0.6130\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5582 - val_loss: 0.6091\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5550 - val_loss: 0.6055\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5520 - val_loss: 0.6021\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5490 - val_loss: 0.5985\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5461 - val_loss: 0.5952\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5432 - val_loss: 0.5918\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5404 - val_loss: 0.5887\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5377 - val_loss: 0.5854\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5351 - val_loss: 0.5824\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5325 - val_loss: 0.5794\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5300 - val_loss: 0.5764\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5275 - val_loss: 0.5735\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5251 - val_loss: 0.5706\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5227 - val_loss: 0.5678\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5204 - val_loss: 0.5651\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5182 - val_loss: 0.5624\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5160 - val_loss: 0.5599\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5138 - val_loss: 0.5573\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5117 - val_loss: 0.5549\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5096 - val_loss: 0.5524\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5076 - val_loss: 0.5500\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5057 - val_loss: 0.5477\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5038 - val_loss: 0.5454\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5019 - val_loss: 0.5432\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5001 - val_loss: 0.5410\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4983 - val_loss: 0.5389\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4966 - val_loss: 0.5368\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4948 - val_loss: 0.5348\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4932 - val_loss: 0.5328\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4916 - val_loss: 0.5309\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4899 - val_loss: 0.5289\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4884 - val_loss: 0.5270\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4869 - val_loss: 0.5252\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4854 - val_loss: 0.5235\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4839 - val_loss: 0.5217\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4934\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 64us/sample - loss: 4.0762 - val_loss: 3.2948\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 2.5042 - val_loss: 2.1516\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 1.6961 - val_loss: 1.5840\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 1.2892 - val_loss: 1.2965\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 1.0707 - val_loss: 1.1293\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9404 - val_loss: 1.0221\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8574 - val_loss: 0.9480\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8020 - val_loss: 0.8957\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7637 - val_loss: 0.8572\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7363 - val_loss: 0.8286\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7160 - val_loss: 0.8067\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7003 - val_loss: 0.7893\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6879 - val_loss: 0.7756\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6778 - val_loss: 0.7640\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6691 - val_loss: 0.7540\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6616 - val_loss: 0.7453\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6548 - val_loss: 0.7373\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6485 - val_loss: 0.7300\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6426 - val_loss: 0.7233\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6371 - val_loss: 0.7167\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6319 - val_loss: 0.7105\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6270 - val_loss: 0.7049\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6223 - val_loss: 0.6992\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6177 - val_loss: 0.6940\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6133 - val_loss: 0.6887\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6091 - val_loss: 0.6836\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6050 - val_loss: 0.6788\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6009 - val_loss: 0.6740\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5971 - val_loss: 0.6695\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5933 - val_loss: 0.6649\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5897 - val_loss: 0.6607\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5861 - val_loss: 0.6567\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5827 - val_loss: 0.6525\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5794 - val_loss: 0.6485\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5761 - val_loss: 0.6446\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5730 - val_loss: 0.6408\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5698 - val_loss: 0.6372\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5668 - val_loss: 0.6335\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5639 - val_loss: 0.6300\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5610 - val_loss: 0.6265\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5581 - val_loss: 0.6233\n",
            "Epoch 42/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5554 - val_loss: 0.6199\n",
            "Epoch 43/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5527 - val_loss: 0.6166\n",
            "Epoch 44/100\n",
            "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5501 - val_loss: 0.6135\n",
            "Epoch 45/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5475 - val_loss: 0.6104\n",
            "Epoch 46/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5450 - val_loss: 0.6073\n",
            "Epoch 47/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5424 - val_loss: 0.6043\n",
            "Epoch 48/100\n",
            "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5400 - val_loss: 0.6015\n",
            "Epoch 49/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5377 - val_loss: 0.5986\n",
            "Epoch 50/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5353 - val_loss: 0.5959\n",
            "Epoch 51/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5330 - val_loss: 0.5932\n",
            "Epoch 52/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5308 - val_loss: 0.5905\n",
            "Epoch 53/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5286 - val_loss: 0.5878\n",
            "Epoch 54/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5265 - val_loss: 0.5852\n",
            "Epoch 55/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5244 - val_loss: 0.5827\n",
            "Epoch 56/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5223 - val_loss: 0.5803\n",
            "Epoch 57/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5203 - val_loss: 0.5778\n",
            "Epoch 58/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5183 - val_loss: 0.5754\n",
            "Epoch 59/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5164 - val_loss: 0.5731\n",
            "Epoch 60/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5145 - val_loss: 0.5707\n",
            "Epoch 61/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5126 - val_loss: 0.5685\n",
            "Epoch 62/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5108 - val_loss: 0.5664\n",
            "Epoch 63/100\n",
            "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5090 - val_loss: 0.5643\n",
            "Epoch 64/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5073 - val_loss: 0.5621\n",
            "Epoch 65/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5056 - val_loss: 0.5601\n",
            "Epoch 66/100\n",
            "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5039 - val_loss: 0.5580\n",
            "Epoch 67/100\n",
            "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5022 - val_loss: 0.5561\n",
            "Epoch 68/100\n",
            "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5006 - val_loss: 0.5542\n",
            "Epoch 69/100\n",
            "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4990 - val_loss: 0.5523\n",
            "Epoch 70/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4975 - val_loss: 0.5504\n",
            "Epoch 71/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4959 - val_loss: 0.5486\n",
            "3870/3870 [==============================] - 0s 22us/sample - loss: 0.5373\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 50us/sample - loss: 2.6248 - val_loss: 1.3540\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 1.0127 - val_loss: 0.8989\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7978 - val_loss: 0.7868\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7325 - val_loss: 0.7388\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6942 - val_loss: 0.7074\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6641 - val_loss: 0.6800\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6392 - val_loss: 0.6575\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6186 - val_loss: 0.6390\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6007 - val_loss: 0.6229\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5852 - val_loss: 0.6057\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5718 - val_loss: 0.5939\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5599 - val_loss: 0.5819\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5495 - val_loss: 0.5709\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5404 - val_loss: 0.5617\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5326 - val_loss: 0.5532\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5252 - val_loss: 0.5466\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5193 - val_loss: 0.5399\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5133 - val_loss: 0.5332\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5081 - val_loss: 0.5279\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5036 - val_loss: 0.5233\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4992 - val_loss: 0.5190\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4952 - val_loss: 0.5146\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4917 - val_loss: 0.5101\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4883 - val_loss: 0.5079\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4851 - val_loss: 0.5048\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4823 - val_loss: 0.5012\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4794 - val_loss: 0.4985\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4768 - val_loss: 0.4956\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4743 - val_loss: 0.4933\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4720 - val_loss: 0.4915\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4698 - val_loss: 0.4891\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4677 - val_loss: 0.4866\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4656 - val_loss: 0.4846\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4636 - val_loss: 0.4821\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4618 - val_loss: 0.4803\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4599 - val_loss: 0.4789\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4580 - val_loss: 0.4763\n",
            "Epoch 38/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4565 - val_loss: 0.4753\n",
            "Epoch 39/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4549 - val_loss: 0.4737\n",
            "Epoch 40/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4532 - val_loss: 0.4727\n",
            "Epoch 41/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4518 - val_loss: 0.4712\n",
            "3870/3870 [==============================] - 0s 18us/sample - loss: 0.4277\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 49us/sample - loss: 2.3454 - val_loss: 1.1933\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8702 - val_loss: 0.8136\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7206 - val_loss: 0.7433\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6708 - val_loss: 0.7064\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6390 - val_loss: 0.6786\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6154 - val_loss: 0.6567\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5946 - val_loss: 0.6369\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5771 - val_loss: 0.6196\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5632 - val_loss: 0.6043\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5491 - val_loss: 0.5895\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5373 - val_loss: 0.5777\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5270 - val_loss: 0.5674\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5176 - val_loss: 0.5557\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5101 - val_loss: 0.5475\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5028 - val_loss: 0.5383\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4961 - val_loss: 0.5311\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4901 - val_loss: 0.5253\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4853 - val_loss: 0.5189\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4800 - val_loss: 0.5138\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4761 - val_loss: 0.5093\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4720 - val_loss: 0.5031\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4685 - val_loss: 0.4980\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4655 - val_loss: 0.4961\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4621 - val_loss: 0.4926\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4587 - val_loss: 0.4877\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4573 - val_loss: 0.4847\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4536 - val_loss: 0.4813\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4527 - val_loss: 0.4787\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4497 - val_loss: 0.4754\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4479 - val_loss: 0.4742\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4460 - val_loss: 0.4718\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4434 - val_loss: 0.4689\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4425 - val_loss: 0.4671\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4404 - val_loss: 0.4667\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4389 - val_loss: 0.4629\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4377 - val_loss: 0.4627\n",
            "Epoch 37/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4360 - val_loss: 0.4596\n",
            "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4348\n",
            "Train on 7740 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "7740/7740 [==============================] - 0s 48us/sample - loss: 2.4181 - val_loss: 1.1112\n",
            "Epoch 2/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.8349 - val_loss: 0.7360\n",
            "Epoch 3/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6452 - val_loss: 0.6870\n",
            "Epoch 4/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.6084 - val_loss: 0.6620\n",
            "Epoch 5/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5871 - val_loss: 0.6430\n",
            "Epoch 6/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5696 - val_loss: 0.6243\n",
            "Epoch 7/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5551 - val_loss: 0.6097\n",
            "Epoch 8/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5422 - val_loss: 0.5940\n",
            "Epoch 9/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5314 - val_loss: 0.5811\n",
            "Epoch 10/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5215 - val_loss: 0.5702\n",
            "Epoch 11/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5129 - val_loss: 0.5609\n",
            "Epoch 12/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5051 - val_loss: 0.5509\n",
            "Epoch 13/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4990 - val_loss: 0.5434\n",
            "Epoch 14/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4926 - val_loss: 0.5374\n",
            "Epoch 15/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4869 - val_loss: 0.5315\n",
            "Epoch 16/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4819 - val_loss: 0.5242\n",
            "Epoch 17/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4775 - val_loss: 0.5203\n",
            "Epoch 18/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4733 - val_loss: 0.5161\n",
            "Epoch 19/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4699 - val_loss: 0.5107\n",
            "Epoch 20/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4664 - val_loss: 0.5066\n",
            "Epoch 21/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4632 - val_loss: 0.5031\n",
            "Epoch 22/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4606 - val_loss: 0.4994\n",
            "Epoch 23/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4579 - val_loss: 0.4968\n",
            "Epoch 24/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4552 - val_loss: 0.4937\n",
            "Epoch 25/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4524 - val_loss: 0.4912\n",
            "Epoch 26/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4505 - val_loss: 0.4889\n",
            "Epoch 27/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4483 - val_loss: 0.4855\n",
            "Epoch 28/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4462 - val_loss: 0.4836\n",
            "Epoch 29/100\n",
            "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4441 - val_loss: 0.4812\n",
            "Epoch 30/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4424 - val_loss: 0.4793\n",
            "Epoch 31/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4405 - val_loss: 0.4769\n",
            "Epoch 32/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4388 - val_loss: 0.4749\n",
            "Epoch 33/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4372 - val_loss: 0.4732\n",
            "Epoch 34/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4356 - val_loss: 0.4719\n",
            "Epoch 35/100\n",
            "7740/7740 [==============================] - 0s 34us/sample - loss: 0.4338 - val_loss: 0.4698\n",
            "Epoch 36/100\n",
            "7740/7740 [==============================] - 0s 35us/sample - loss: 0.4327 - val_loss: 0.4684\n",
            "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4745\n",
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 0s 42us/sample - loss: 2.0774 - val_loss: 0.6954\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5356 - val_loss: 0.5636\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.5474 - val_loss: 0.4344\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3981 - val_loss: 0.4028\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3812 - val_loss: 0.3854\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3699 - val_loss: 0.3773\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3605 - val_loss: 0.3687\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3544 - val_loss: 0.3642\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3488 - val_loss: 0.3593\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3428 - val_loss: 0.3523\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3402 - val_loss: 0.3583\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3364 - val_loss: 0.3531\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3326 - val_loss: 0.3464\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3295 - val_loss: 0.3374\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3253 - val_loss: 0.3409\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3232 - val_loss: 0.3352\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3206 - val_loss: 0.3338\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3181 - val_loss: 0.3297\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3154 - val_loss: 0.3311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f2d45a26c18>,\n",
              "                   iid='warn', n_iter=10, n_jobs=1,\n",
              "                   param_distributions={'hidden_layers': [1, 2, 3, 4],\n",
              "                                        'layer_size': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 3...46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2d38b72d68>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfO2ZzzIziHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9c006cf0-1b11-46eb-e2a7-3dd26f29f73f"
      },
      "source": [
        "print(random_search_cv.best_params_)\n",
        "print(random_search_cv.best_score_)\n",
        "print(random_search_cv.best_estimator_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hidden_layers': 2, 'layer_size': 64, 'learning_rate': 0.0074971092331801445}\n",
            "-0.34148263905604886\n",
            "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f2d38b72d30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHvqfgLN2KS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aad194f0-81aa-4eee-b2b6-861044c70918"
      },
      "source": [
        "model = random_search_cv.best_estimator_.model\n",
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 17us/sample - loss: 0.3413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3412971150043399"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUPzUJuN2a2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}