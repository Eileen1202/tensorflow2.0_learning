{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_wide_deep_subclass.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression_wide_deep_subclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUoJrGPpbb-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "outputId": "6a79c9cc-3744-4805-a584-85c9a439bac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.1\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "83228c26-3375-41cc-e919-f9ab85d41407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "a9e1f168-bd6a-4b7b-c68f-65248d79150a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "outputId": "d3791ae4-ba69-416b-fa1d-15a4be134b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# 子类API\n",
        "class WideDeepModel(keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(WideDeepModel, self).__init__()\n",
        "        # 定义模型的层次\n",
        "        self.hidden1_layer = keras.layers.Dense(30, activation='relu')\n",
        "        self.hidden2_layer = keras.layers.Dense(30, activation='relu')\n",
        "        self.output_layer = keras.layers.Dense(1)\n",
        "    def call(self, input):\n",
        "        # 完成模型的正向运算\n",
        "        hidden1 = self.hidden1_layer(input)\n",
        "        hidden2 = self.hidden2_layer(hidden1)\n",
        "        concat = keras.layers.concatenate([input, hidden2])\n",
        "        output = self.output_layer(concat)\n",
        "        return output\n",
        "    \n",
        "# model = WideDeepModel()\n",
        "model = keras.models.Sequential([\n",
        "    WideDeepModel(),\n",
        "])\n",
        "model.build(input_shape=(None, 8))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer = \"sgd\")\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "wide_deep_model_1 (WideDeepM multiple                  1239      \n",
            "=================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g9RQd287SJ",
        "colab_type": "code",
        "outputId": "c0e91a15-0d0c-4e7d-87d5-68c93bf89c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        }
      },
      "source": [
        "history = model.fit(x_train_scaled, y_train,\n",
        "                   validation_data = (x_valid_scaled, y_valid),\n",
        "                   epochs = 100,\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 47us/sample - loss: 1.9411 - val_loss: 0.8021\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6738 - val_loss: 0.6910\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6212 - val_loss: 0.6513\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5782 - val_loss: 0.6127\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5489 - val_loss: 0.5873\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5257 - val_loss: 0.5575\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5097 - val_loss: 0.5424\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4954 - val_loss: 0.5248\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4874 - val_loss: 0.5176\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4770 - val_loss: 0.5074\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4687 - val_loss: 0.4982\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4608 - val_loss: 0.4945\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4558 - val_loss: 0.4838\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4526 - val_loss: 0.4784\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4464 - val_loss: 0.4743\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4406 - val_loss: 0.4691\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4395 - val_loss: 0.4658\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4343 - val_loss: 0.4614\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4333 - val_loss: 0.4572\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4296 - val_loss: 0.4537\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4261 - val_loss: 0.4510\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4233 - val_loss: 0.4493\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4208 - val_loss: 0.4459\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4189 - val_loss: 0.4444\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4162 - val_loss: 0.4400\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4142 - val_loss: 0.4373\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4123 - val_loss: 0.4348\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4103 - val_loss: 0.4328\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4085 - val_loss: 0.4303\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4065 - val_loss: 0.4329\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4046 - val_loss: 0.4273\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4028 - val_loss: 0.4254\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4012 - val_loss: 0.4240\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3995 - val_loss: 0.4218\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3979 - val_loss: 0.4197\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3965 - val_loss: 0.4169\n",
            "Epoch 37/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3954 - val_loss: 0.4163\n",
            "Epoch 38/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3931 - val_loss: 0.4142\n",
            "Epoch 39/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3918 - val_loss: 0.4127\n",
            "Epoch 40/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3906 - val_loss: 0.4109\n",
            "Epoch 41/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3892 - val_loss: 0.4091\n",
            "Epoch 42/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3879 - val_loss: 0.4080\n",
            "Epoch 43/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3865 - val_loss: 0.4058\n",
            "Epoch 44/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3846 - val_loss: 0.4062\n",
            "Epoch 45/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3838 - val_loss: 0.4035\n",
            "Epoch 46/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3822 - val_loss: 0.4039\n",
            "Epoch 47/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3827 - val_loss: 0.3997\n",
            "Epoch 48/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3805 - val_loss: 0.3990\n",
            "Epoch 49/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3788 - val_loss: 0.3973\n",
            "Epoch 50/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3801 - val_loss: 0.3974\n",
            "Epoch 51/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3784 - val_loss: 0.3966\n",
            "Epoch 52/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3762 - val_loss: 0.3941\n",
            "Epoch 53/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3748 - val_loss: 0.3927\n",
            "Epoch 54/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3738 - val_loss: 0.3938\n",
            "Epoch 55/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3726 - val_loss: 0.3915\n",
            "Epoch 56/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3718 - val_loss: 0.3898\n",
            "Epoch 57/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3709 - val_loss: 0.3890\n",
            "Epoch 58/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3697 - val_loss: 0.3881\n",
            "Epoch 59/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3691 - val_loss: 0.3861\n",
            "Epoch 60/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3681 - val_loss: 0.3866\n",
            "Epoch 61/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3670 - val_loss: 0.3848\n",
            "Epoch 62/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3674 - val_loss: 0.3840\n",
            "Epoch 63/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3665 - val_loss: 0.3842\n",
            "Epoch 64/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3647 - val_loss: 0.3818\n",
            "Epoch 65/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3644 - val_loss: 0.3815\n",
            "Epoch 66/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3629 - val_loss: 0.3807\n",
            "Epoch 67/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3628 - val_loss: 0.3808\n",
            "Epoch 68/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3614 - val_loss: 0.3778\n",
            "Epoch 69/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3611 - val_loss: 0.3776\n",
            "Epoch 70/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3603 - val_loss: 0.3776\n",
            "Epoch 71/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3597 - val_loss: 0.3782\n",
            "Epoch 72/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3585 - val_loss: 0.3761\n",
            "Epoch 73/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3577 - val_loss: 0.3741\n",
            "Epoch 74/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3563 - val_loss: 0.3750\n",
            "Epoch 75/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3557 - val_loss: 0.3731\n",
            "Epoch 76/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3557 - val_loss: 0.3712\n",
            "Epoch 77/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3542 - val_loss: 0.3714\n",
            "Epoch 78/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3538 - val_loss: 0.3697\n",
            "Epoch 79/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3536 - val_loss: 0.3693\n",
            "Epoch 80/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3533 - val_loss: 0.3700\n",
            "Epoch 81/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3514 - val_loss: 0.3673\n",
            "Epoch 82/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3512 - val_loss: 0.3672\n",
            "Epoch 83/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3507 - val_loss: 0.3654\n",
            "Epoch 84/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3503 - val_loss: 0.3667\n",
            "Epoch 85/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3494 - val_loss: 0.3643\n",
            "Epoch 86/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3490 - val_loss: 0.3674\n",
            "Epoch 87/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3487 - val_loss: 0.3666\n",
            "Epoch 88/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3470 - val_loss: 0.3622\n",
            "Epoch 89/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3470 - val_loss: 0.3606\n",
            "Epoch 90/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3452 - val_loss: 0.3654\n",
            "Epoch 91/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3464 - val_loss: 0.3625\n",
            "Epoch 92/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3470 - val_loss: 0.3632\n",
            "Epoch 93/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3445 - val_loss: 0.3613\n",
            "Epoch 94/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3434 - val_loss: 0.3585\n",
            "Epoch 95/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3456 - val_loss: 0.3601\n",
            "Epoch 96/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3416 - val_loss: 0.3574\n",
            "Epoch 97/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3413 - val_loss: 0.3560\n",
            "Epoch 98/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3407 - val_loss: 0.3572\n",
            "Epoch 99/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3429 - val_loss: 0.3572\n",
            "Epoch 100/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3424 - val_loss: 0.3566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "outputId": "33b4344d-bfde-45e9-975a-77a0a0536aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8oi2X30iWrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7LY8Sa9iX4",
        "colab_type": "code",
        "outputId": "57236ea6-3239-4afc-adf2-6081e09791a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 19us/sample - loss: 0.3731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3731427321138308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}