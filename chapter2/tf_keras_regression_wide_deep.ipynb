{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_keras_regression_wide_deep.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvshyer/tensorflow2.0_learning/blob/master/tf_keras_regression_wide_deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUoJrGPpbb-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "bff54715-6a35-4be2-b1d2-44a8c75a1d5b"
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0 "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Collecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 25.6MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\n",
            "Installing collected packages: tb-nightly, google-pasta, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezK57pS6ZSF",
        "colab_type": "code",
        "outputId": "a3b8a2ab-fb22-4c33-d48b-8770ef8db0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(sys.version_info)\n",
        "for module in mpl, np, pd, sklearn, tf, keras:\n",
        "    print(module.__name__, module.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n",
            "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
            "matplotlib 3.0.3\n",
            "numpy 1.16.3\n",
            "pandas 0.24.2\n",
            "sklearn 0.21.1\n",
            "tensorflow 2.0.0-alpha0\n",
            "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd13Iimm6j7Q",
        "colab_type": "code",
        "outputId": "1b670240-4d5c-4792-b0b2-98873e97b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(housing.DESCR)\n",
        "print(housing.data.shape)\n",
        "print(housing.target.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block\n",
            "        - HouseAge      median house age in block\n",
            "        - AveRooms      average number of rooms\n",
            "        - AveBedrms     average number of bedrooms\n",
            "        - Population    block population\n",
            "        - AveOccup      average house occupancy\n",
            "        - Latitude      house block latitude\n",
            "        - Longitude     house block longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "http://lib.stat.cmu.edu/datasets/\n",
            "\n",
            "The target variable is the median house value for California districts.\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n",
            "(20640, 8)\n",
            "(20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2zeFXF7O6V",
        "colab_type": "code",
        "outputId": "19ada0ee-1ffd-4e3a-abad-85b0e4d33683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# test_size默认为0.25\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state = 7, test_size = 0.25)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x_train_all, y_train_all, random_state = 11)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_valid.shape, y_valid.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 8) (11610,)\n",
            "(3870, 8) (3870,)\n",
            "(5160, 8) (5160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvaW64pQ7418",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IkL0UAt8Qzo",
        "colab_type": "code",
        "outputId": "83ad76da-c1e9-4477-bc31-6f52ee5539c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# 函数式API\n",
        "input = keras.layers.Input(shape=x_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "#复合函数: f(x) = h(g(x))\n",
        "\n",
        "concat = keras.layers.concatenate([input, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "\n",
        "model = keras.models.Model(inputs = [input],\n",
        "                           outputs = [output])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss=\"mean_squared_error\", optimizer = \"sgd\")\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 38)           0           input_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3g9RQd287SJ",
        "colab_type": "code",
        "outputId": "99f68065-ba7a-414a-827c-0931fbe629e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3318
        }
      },
      "source": [
        "history = model.fit(x_train_scaled, y_train,\n",
        "                   validation_data = (x_valid_scaled, y_valid),\n",
        "                   epochs = 100,\n",
        "                   callbacks = callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 1.8928 - val_loss: 0.8464\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.7162 - val_loss: 0.7472\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 0s 36us/sample - loss: 0.6652 - val_loss: 0.7025\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6290 - val_loss: 0.6670\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.6007 - val_loss: 0.6358\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5769 - val_loss: 0.6120\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5569 - val_loss: 0.5934\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5402 - val_loss: 0.5743\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5249 - val_loss: 0.5580\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5118 - val_loss: 0.5414\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5016 - val_loss: 0.5303\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4918 - val_loss: 0.5192\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4832 - val_loss: 0.5148\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4761 - val_loss: 0.5015\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4709 - val_loss: 0.4954\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4645 - val_loss: 0.4883\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4598 - val_loss: 0.4855\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4541 - val_loss: 0.4779\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4501 - val_loss: 0.4722\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4463 - val_loss: 0.4672\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4417 - val_loss: 0.4616\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4388 - val_loss: 0.4610\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4355 - val_loss: 0.4573\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4309 - val_loss: 0.4516\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4292 - val_loss: 0.4466\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4259 - val_loss: 0.4470\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4238 - val_loss: 0.4567\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4207 - val_loss: 0.4396\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4178 - val_loss: 0.4356\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4159 - val_loss: 0.4318\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4132 - val_loss: 0.4305\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4115 - val_loss: 0.4283\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4097 - val_loss: 0.4505\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4080 - val_loss: 0.4247\n",
            "Epoch 35/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4051 - val_loss: 0.4217\n",
            "Epoch 36/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4031 - val_loss: 0.4224\n",
            "Epoch 37/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4011 - val_loss: 0.4164\n",
            "Epoch 38/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4002 - val_loss: 0.4180\n",
            "Epoch 39/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3976 - val_loss: 0.4152\n",
            "Epoch 40/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3960 - val_loss: 0.4205\n",
            "Epoch 41/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3944 - val_loss: 0.4105\n",
            "Epoch 42/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3931 - val_loss: 0.4097\n",
            "Epoch 43/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3911 - val_loss: 0.4088\n",
            "Epoch 44/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3898 - val_loss: 0.4066\n",
            "Epoch 45/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3884 - val_loss: 0.4068\n",
            "Epoch 46/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3863 - val_loss: 0.4016\n",
            "Epoch 47/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3856 - val_loss: 0.4025\n",
            "Epoch 48/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3839 - val_loss: 0.3994\n",
            "Epoch 49/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3826 - val_loss: 0.3991\n",
            "Epoch 50/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3814 - val_loss: 0.3959\n",
            "Epoch 51/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3793 - val_loss: 0.3985\n",
            "Epoch 52/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3789 - val_loss: 0.3943\n",
            "Epoch 53/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3774 - val_loss: 0.3929\n",
            "Epoch 54/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3763 - val_loss: 0.3924\n",
            "Epoch 55/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3757 - val_loss: 0.3909\n",
            "Epoch 56/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3737 - val_loss: 0.3905\n",
            "Epoch 57/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3726 - val_loss: 0.3887\n",
            "Epoch 58/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3724 - val_loss: 0.3866\n",
            "Epoch 59/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3712 - val_loss: 0.3879\n",
            "Epoch 60/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3700 - val_loss: 0.3850\n",
            "Epoch 61/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3685 - val_loss: 0.3852\n",
            "Epoch 62/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3686 - val_loss: 0.3843\n",
            "Epoch 63/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3671 - val_loss: 0.3834\n",
            "Epoch 64/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3658 - val_loss: 0.3826\n",
            "Epoch 65/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3656 - val_loss: 0.3827\n",
            "Epoch 66/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3645 - val_loss: 0.3789\n",
            "Epoch 67/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3640 - val_loss: 0.3808\n",
            "Epoch 68/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3628 - val_loss: 0.3786\n",
            "Epoch 69/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3623 - val_loss: 0.3782\n",
            "Epoch 70/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3608 - val_loss: 0.3768\n",
            "Epoch 71/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3605 - val_loss: 0.3758\n",
            "Epoch 72/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3596 - val_loss: 0.3778\n",
            "Epoch 73/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3600 - val_loss: 0.3755\n",
            "Epoch 74/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3585 - val_loss: 0.3755\n",
            "Epoch 75/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3578 - val_loss: 0.3743\n",
            "Epoch 76/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3572 - val_loss: 0.3732\n",
            "Epoch 77/100\n",
            "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3564 - val_loss: 0.3719\n",
            "Epoch 78/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3559 - val_loss: 0.3729\n",
            "Epoch 79/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3556 - val_loss: 0.3720\n",
            "Epoch 80/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3540 - val_loss: 0.3696\n",
            "Epoch 81/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3541 - val_loss: 0.3724\n",
            "Epoch 82/100\n",
            "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3541 - val_loss: 0.3707\n",
            "Epoch 83/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3531 - val_loss: 0.3696\n",
            "Epoch 84/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3520 - val_loss: 0.3692\n",
            "Epoch 85/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3508 - val_loss: 0.3676\n",
            "Epoch 86/100\n",
            "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3507 - val_loss: 0.3679\n",
            "Epoch 87/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3511 - val_loss: 0.3680\n",
            "Epoch 88/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3496 - val_loss: 0.3649\n",
            "Epoch 89/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3490 - val_loss: 0.3674\n",
            "Epoch 90/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3490 - val_loss: 0.3644\n",
            "Epoch 91/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3487 - val_loss: 0.3638\n",
            "Epoch 92/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3470 - val_loss: 0.3634\n",
            "Epoch 93/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3471 - val_loss: 0.3637\n",
            "Epoch 94/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3471 - val_loss: 0.3628\n",
            "Epoch 95/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3457 - val_loss: 0.3633\n",
            "Epoch 96/100\n",
            "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3459 - val_loss: 0.3637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlYp_ol9Qmz",
        "colab_type": "code",
        "outputId": "a5a355f0-1712-45da-e74d-072aacccefcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0,1)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEzCAYAAAALosttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMRjFM4iIiIeo3AWERHxGIWziIiIx/x/DqQEhYt820cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7LY8Sa9iX4",
        "colab_type": "code",
        "outputId": "a2d07bba-04ff-474b-fcee-b97c441eddf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 24us/sample - loss: 0.3717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3716965292775354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIxnZqD9o3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}